=== Segmentation faults and core dumps

https://en.wikipedia.org/wiki/Segmentation_fault[Segmentation faults] are caused when *LSDTopoTools* attempts to access some data in your computer's https://en.wikipedia.org/wiki/Computer_memory[memory] (think of it as the computer's brain) that is not there. Sometimes when this happens you might also get a https://en.wikipedia.org/wiki/Core_dump[core dump]. These sorts of faults are the bane of our existence. 

There are three typical reasons for these faults, which always crash the program, to occur:

. *LSDTopoTools* is looking for a file that is not there. You solve this by checking filenames. 
. *LSDTopoTools* developers have got a bug in the code that wasn't uncovered in testing. 
. *LSDTopoTools* runs out of memory.

IMPORTANT: The most persistent and common problem is the memory problem. There is not much we can do about this without totally rewriting the code (which is several hundred thousand lines long at this point). If you get a *segmentation fault* or a *core dump* there is a high probability that this is the problem. 

==== The missing file problem

In recent years we have added error checking capabilities so that if *LSDTopoTools* looks for a file and doesn't find it, it will tell you before exiting. However we have not comprehensively done this with every single component of the code so it still can happen that if you use the wrong path or filename in one of your parameter files *LSDTopoTools* will crash. To fix this you need to check all your file names and directory paths. 

==== The naughty developer problem

Sometimes the *LSDTopoTools* developers release code that has a bug. Bad developers, bad!! To fix this you need to tell us the problem and we will try to find the problem. Unless you are a proficient pass:[C++] hacker there is not much you can do about this other than to wait for us to address the problem. However, in most cases the crashing software is caused by the memory problem rather than a bug. 

==== The *LSDTopoTools* memory problem

Let me start by saying that the developers of *LSDTopoTools* are geoscientists and not professional software developers. When we built *LSDTopoTools* we were aiming for speed and we don't know how to do data streaming, so the way *LSDTopoTools* works is to dump everything into your computer's https://en.wikipedia.org/wiki/Computer_memory[memory] and work with the data there. This was not a problem for us because we use Linux servers that have may hundreds of gigabytes of memory. 

However, topographic datasets are getting bigger and bigger, and we have also tried to distribute *LSDTopoTools* to people who don't have a fancy and fast rack workstation, so memory has become an issue. 

For most of our applications the following things happen:

* The DEM is loaded. 
* A filled raster is created. 
* An object containing all the information about the flow network (how all the pixels are connected) is created. This is called the *Flow Info* object. 
* An object containing how all the river networks and junctions are connected is created. 

In addition to these quite standard operations, any additional computation is done in yet more data structures that are in your computer's memory. The *Flow Info* object alone is *very* memory intensive. It takes up 10-20 times the memory of your DEM. What does this mean? Everything together means that you will need something like 30 times the amount of memory as the size of your DEM to do operations involving any sort of flow routing or channel networks. 

.Memory rule of thumb
****************************
If you do anything that requires knowing something about how pixels are connected, for example any drainage or river network calculations, you will need between *20-30x* the amount of memory as the size of the DEM. 
****************************

===== The memory problem and vagrant machines

For people without a Linux workstation, we recommend our <<Installing LSDTopoTools using VirtualBox and Vagrant,Vagrant setup>>. *This setup gives you limited memory*.

The *default* https://github.com/LSDtopotools/LSDTT_vagrantfiles[vagrantfile] setting is to give your server 3GB of memory. This is the line of the vagrant file where it does that:

.Location of the memory setting in our vagrantfiles
[source,vagrantfile]
----
    # Customize the amount of memory on the VM:
    # You should adjust this based on your computer's memory
    # 32 bit machines generally cannot exceed 3GB of memory
    vb.memory = "3000"
----

*With this amount of memory you are limited to operations that involve channel networks on DEM of ~100MB.* We have not done extensive testing of this but our anecdotal evidence suggests this is the limit with 3GB of memory. If you want to process a 1 GB DEM then you will probably need around 30GB of memory. 

If you want to process bigger DEMs you need to give your machine more memory by changing the `vb.memory` setting in your vagrantfile. 

===== The memory problem and 32-bit vagrant machines

There is one more wrinkle to this. Most Windows machines have a default setting that they cannot have 64-bit guest operating systems. If you try to start up a 64-bit vagrant machine on a windows computer it usually simply will not work. Our testing on MacOS suggests that most of these systems will allow a 64-bit operating system. 

There is a limit to the amount of memory a 32-bit system can have; https://en.wikipedia.org/wiki/3_GB_barrier[it is around 3GB]. So unless you https://forums.virtualbox.org/viewtopic.php?f=1&t=62339[are willing to change your Windows computer's default settings], you are limited to "small" DEMs. Sorry about that. 





