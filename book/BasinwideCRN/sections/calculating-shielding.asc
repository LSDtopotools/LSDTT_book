
=== Calculating Topographic Shielding

Cosmogenic nuclides are produced at or near the Earth's surface by cosmic rays,
and these rays can be blocked by topography (i.e., big mountains cast "shadows" for cosmic rays).

In most cases, you will not have topographic shielding rasters available, and will need to calculate these.

Shielding calculation are computationally intensive, much more so than the actual erosion rate computations.
Because of the computational expense of shielding calculations, we have prepared a series of tools for speeding this computation.

The topographic shielding routines take the rasters from the `_CRNRasters.csv` file and the `_CRNData.csv` file and computes the location of all CRN basins.
They then clips a DEM around the basins (with a pixel buffer set by the user).
These clipped basins are then used to make the shielding calculations and the erosion rate calculations.

This process of clipping out each basin spans a large number of new DEM that require a new directory structure.
A python script is provided to set up this directory structure in order to organize the new rasters.

WARNING: *This process uses a large amount of storage on the hard disk because a new DEM will be written for each CRN basin.*

==== Steps for preparing the rasters for shielding calculations

===== Creation of subfolders for your topographic datasets

The first step is to create some subfolders to store topographic data.
We do this using a python script

. First, place the `_CRNRasters.csv` and `_CRNData.csv` file into the same folder,
and make sure the `_CRNRasters.csv` file points to the directories that contain the topographic data.
If you are working with the example data (see section <<Getting example data: The San Bernardino Mountains>>),
you should navigate to the folder with the data (for this example, the folder is in `/home/ExampleDatasets/SanBernardino/`):
+
[source,console]
----
$ pwd
/home/ExampleDatasets/SanBernardino/
$ ls
Binnie_CRNData.csv  SanBern_data_analysis.CRNfiles  SanBern.hdr
SanBern.bil         SanBern_data_analysis.CRNparam
----
+
You will then need to modify `SanBern_data_analysis.CRNfiles` to reflect your directory:
+
[source,paramfile]
----
/home/ExampleDatasets/SanBernardino/Binnie_CRNdata.csv
/home/ExampleDatasets/SanBernardino/SanBern
----
+
The first line points to the CRNdata.csv file, and the second points to the DEM that will be analyzed.
Note that if you are doing this on your own data you can have multiple lines for different DEMs.
+
In addition in this case we are not supplying and shielding rasters.
For more details about the format of this file see the section: <<The raster names file>>.
+
. Second, run the python script `PrepareDirectoriesForBasinSpawn.py`.
+
* You can clone this script from GitHub; find it here: https://github.com/LSDtopotools/LSDAutomation
You will also need the file `LSDOSystemTools.py` from this repository.
The `LSDOSystemTools.py` file contains some scripts for making sure directories are in the correct format,
and for changing filenames if you happen to be switching between Linux and Windows.
It is unlikely that you will need to concern yourself with its contents, as long as
it is present in the same folder as the `PrepareDirectoriesForBasinSpawn.py` file.
+
The scripts can be downloaded directly using:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareDirectoriesForBasinSpawn.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py
----
+
* You will need to scroll to the bottom of the script and change the `path`
(which is simply the directory path of the `_CRNRasters.csv` file.
* You will need to scroll to the bottom of the script and change the `prefix`
(which is simply prefix of the ``_CRNRasters.csv`` file; that is the filename before `_CRNRasters.csv`
so if the filename is `YoYoMa_CRNRasters.csv` then `prefix` is `YoYoMa`. Note this is case sensitive.
+
In this example, scroll to the bottom of the file and change it to:
+
[source,python]
----
if __name__ == "__main__":
    path = "/home/ExampleDatasets/SanBernardino"
    prefix = "SanBern"
    PrepareDirectoriesForBasinSpawn(path,prefix)
----
+
* This python script does several subtle things like checking directory paths and then makes a new folder for each DEM.
The folders will contain all the CRN basins located on the source DEM.
+
If you are using the example data, the rather trivial result will be a directory called `SanBern`.

===== Spawning the basins

Now you will run a pass:[C++] program that spawns small rasters that will be used for shielding calculations.
First you have to compile this program.


. To compile, navigate to the folder `/home/LSDTT_repositories/LSDTopoTools_CRNBasinwide/driver_functions_CRNBasinwide/`.
If you put the code somewhere else, navigate to that folder.
Once you are in the folder with the driver functions, type:
+
[source,console]
----
$ make -f Spawn_DEMs_for_CRN.make
----
+
. The program will then compile (you may get some warnings--ignore them.)

. In the `/driver_functions_CRNTools/` folder, you will now have a program `Spawn_DEMs_for_CRN.exe`.
You need to give this program two arguments.

. You need to give `Spawn_DEMs_for_CRN.exe`, the path to the data files (i.e., `_CRNRasters.csv` and `_CRNData.csv`),
and the prefix, so if they are called  `YoMa_CRNRaster.csv` the prefix is `YoMa`).
Run this with:
+
[source,console]
----
PS> Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX
----
+
in windows or:
+
[source,console]
----
$ ./Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX
----
+
in Linux.
+
In our example, you should run:
+
[source,console]
----
$ ./Spawn_DEMs_for_CRN.exe /home/ExampleDatasets/SanBernardino/ SanBern
----
+
WARNING: The PATHNAME **MUST** have a frontslash at the end.
`/home/ExampleDatasets/SanBernardino/` will work whereas `/home/ExampleDatasets/SanBernardino` will lead to an error.
+
. Once this program has run, you should have subfolders containing small DEMs that contain the basins to be analyzed.
There will be one for every cosmogenic sample that lies within the DEM.
+
. You will also have files that contain the same `PATHNAME` and `PREFIX` but have `_Spawned` added to the prefix.
For example, if your original prefix was  `CRN_test`, the new prefix will be `CRN_test_Spawned`.
+
. In the file `PREFIX_Spawned_CRNRasters.csv` you will find the paths and prefixes of all the spawned basins.

==== The shielding computation

The shielding computation is the most computationally expensive step of the CRN data analysis.
Once you have spawned the basins (see above section,
<<Steps for preparing the rasters for shielding calculations>>), you will need to run the shielding calculations.

. You will first need to compile the program that calculates shielding. This can be compiled with:
+
[source,console]
----
$ make -f Shielding_for_CRN.make
----
+
. The compiled program (`Shielding_for_CRN.exe`) takes two arguments: the `PATHNAME` and the `PREFIX`.

. You could simply run this on a single CPU after spawning the basins;
for example if the original data had the prefix `CRN_test` before spawning, you could run the program with:
+
[source,console]
----
$ ./Shielding_for_CRN.exe PATHNAME CRN_test_Spawned
----
+
where `PATHNAME` is the path to your `_CRNRasters.csv`, `_CRNData.csv`, and `.CRNParam` (*these files need to be in the same path*).
+
NOTE: If you only wanted to do a subset of the basins, you can just delete rows from the `*_Spawned_CRNRasters.csv` file as needed.

==== Embarrassingly parallel shielding

We provide a python script for running multiple basins using an https://en.wikipedia.org/wiki/Embarrassingly_parallel[embarrassingly parallel] approach.
It is written for our cluster:
if your cluster uses qsub or equivalent, you will need to write your own script.
However, this will work on systems where you can send jobs directly.

. To set the system up for embarrassingly parallel runs, you need to run the python script ``ManageShieldingComputation.py``,
which can be found here: https://github.com/LSDtopotools/LSDAutomation.
You can download it with:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/ManageShieldingComputation.py
----
+
. In `ManageShieldingComputation.py`, navigate to the bottom of the script, and enter the `path`, `prefix`, and `NJobs`.
`NJobs` is the number of jobs into which you want to break up the shielding computation.
+
. Once you run this computation, you will get files with the extension `_bkNN` where `NN` is a job number.
+
. In addition a text file is generated, with the extension `_ShieldCommandPrompt.txt`,
and from this you can copy and paste job commands into a Linux terminal.
+
WARNING: **These commands are designed for the GeoSciences cluster at the University of Edinburgh:
if you use qsub you will need to write your own script**.
+
. Note that the parameters for the shielding calculation are in the `.CRNParam` files. We recommend:
+
[source,paramfile]
----
theta_step:8
phi_step: 5
----
+
These are based on extensive sensitivity analyses and balance computational speed with accuracy.
Errors will be << 1% even in landscapes with extremely high relief. Our forthcoming paper has details on this.
+
. Again, these computations take a long time. *Don't start them a few days before your conference presentation!!*

. Once the computations are finished, there will be a shielding raster for every spawned basin raster.
In addition, the `_CRNRasters.csv` file will be updated to reflect the new
shielding rasters so that the updated parameter files can be fed directly into the erosion rate calculators.
