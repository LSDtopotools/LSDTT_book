:numbered:

== Basin averaged cosmogenic analysis

We have developed a toolkit to automate calculation of basin (or catchement) averaged denudation rates estimated from the concentration of in situ cosmogenic nuclides in stream sediment. This toolkit is called the http://www.earth-surf-dynam.net/4/655/2016/[CAIRN method]. 
Currently ^10^Be and ^26^Al are supported.

If you use this to calculate denudation rates that are later published, please cite this paper:

Mudd, S. M., Harel, M.-A., Hurst, M. D., Grieve, S. W. D., and Marrero, S. M.: The CAIRN method: automated, reproducible calculation of catchment-averaged denudation rates from cosmogenic nuclide concentrations, _Earth Surf. Dynam._, 4, 655-674, doi:10.5194/esurf-4-655-2016, 2016.

The toolkit requires:

  * Data on cosmogenic samples.
  * A file containing filenames of the topographic data, and optional filenames for shielding rasters.
  * A parameter file.

The toolkit then produces:

  * A csv file that contains results of the analysis.
  * A text file that can be copied into the http://hess.ess.washington.edu/math/al_be_v22/al_be_erosion_multiple_v22.php>[CRONUS online calculator] for data comparison.

.Quick guide if you already know what you are doing
*****************************************************************************
If you already know what you are doing, here is a quick guide to walk you through the process.
If one of these steps doesn't make sense see the full documentation.

. You will want a directory for both the source code and the data. Make these directories. Our https://github.com/LSDtopotools/LSDTT_vagrantfiles[Vagrantfiles] automate this process meaning if they use them all the work setting up the system is done for you.  
. Get the latest version of the source code from https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide
If you don't have it (i.e., if you haven't used our vagrantfiles), use
+
[source,console]
----
$ git clone https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide.git
----
+
or if you have it use
+
[source,console]
----
$ git pull -u origin master
----
+
in your source code directory. In our vagrant machine, the source code is located in the directory `/LSDTopoTools/Git_projects/LSDTopoTools_CRNBasinwide`. You can also update the source code by using the `vagrant provision` command after you run `vagrant up`. 
. If you have just downloaded the source code, or if it has updates, you need to compile the code.
Go into the directory *driver_functions_CRNBasinwide*. If you use our vagrantfiles you can jump straight to the correct driectory using the the command `cd /LSDTopoTools/Git_projects/LSDTopoTools_CRNBasinwide/driver_functions_CRNBasinwide`  and use `make`:
+
[source,console]
----
$ make -f Spawn_DEMS_for_CRN.make
$ make -f Shielding_for_CRN.make
$ make -f Basinwide_CRN.make
----
+
After each call to `make` there will be a bunch of warnings that you can ignore.
. In your data folder you will need a `*_CRNRasters.csv` file, a `*_CRNData.csv` file,
and a `*.CRNParams` file. If you don't know what these are read the relevent parts of the full documentation
. In your data folder you will also need some python scripts, which you can download individually:
+
[source,console]
----
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/JoinSnowShielding.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/EliminateUnderscoreFromCRNDataSampleNames.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareDirectoriesForBasinSpawn.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareCRNRastersFileFromDirectory.py
----
. If you have some rasters (elevation, shielding, etc.) and you don't have a `_CRNRasters.csv` file, update the path name in `PrepareCRNRastersFileFromDirectory.py` and run that script.  
+
. In your data folder, run `PrepareDirectoriesForBasinSpawn.py`.
You will need to update the path and the prefix at the bottom of this file.
. In addition, sample names with the underscore character (pass:[_]) are not allowed. The script
`EliminateUnderscoreFromCRNDataSampleNames.py` will replace all pass:[_] characters with `-` characters.
You need to open this file and change the target directory before running. It will modify all `*_CRNData.csv` files it finds in that directory.
. Next up, spawn the basins. Go into the source code directory and run:
+
[source,console]
----
$ ./Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX
----
+
. Now, you are ready to calculate topographic shielding. You should run:
+
[source,console]
----
$ ./Shielding_for_CRN.exe PATHNAME DATAPREFIX
----
+
NOTE: If you ran the spawning the data prefix will now have a `*_spawned` in it.
+
WARNING: This is the most computationally expensive component of the process. It could take a while. In the full documentation there is some instructions as to how to do this computation using an embarrassingly parallel approach.
+
. If you decide to use previously reported snow shielding values, run the `JoinSnowShielding.py` function.
This will result in data files with the text `*_SS` in it.
+


*****************************************************************************

include::sections/get-the-code.asc[]

include::sections/calculating-shielding.asc[]

include::sections/snow-shielding.asc[]

include::sections/calculating-erosion-rates.asc[]


=== Summary

You should now be able to take concentrations from detrital cosmogenics and convert these into basin averaged denudation rates.
