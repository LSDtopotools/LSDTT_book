<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.0">
<meta name="author" content="Simon Marius Mudd, David Milodowski, Stuart Grieve, Fiona Clubb, Martin Hurst, Declan Valters, Marie-Alice Harel">
<title>LSDTopoTools for Geomorphology, Hydrology, Ecology and Environmental Sciences</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic|Noto+Serif:400,400italic,700,700italic|Droid+Sans+Mono:400">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove the comments around the @import statement below when using this as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic|Noto+Serif:400,400italic,700,700italic|Droid+Sans+Mono:400";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
#map_canvas img,#map_canvas embed,#map_canvas object,.map_canvas img,.map_canvas embed,.map_canvas object{max-width:none!important}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
.antialiased,body{-webkit-font-smoothing:antialiased}
img{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{display:inline-block;color:rgba(0,0,0,.8);font-size:.75em;line-height:1.4;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:-.15em .15em 0 .15em;padding:.2em .6em .2em .5em;vertical-align:middle;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.05em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.spread{width:100%}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-check-square-o:first-child,ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1{padding-right:.75em;font-weight:bold}
td.hdlist1,td.hdlist2{vertical-align:top}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none}
span.footnote,span.footnoteref{vertical-align:super;font-size:.875em}
span.footnote a,span.footnoteref a{text-decoration:none}
span.footnote a:active,span.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em;line-height:1.3;font-size:.875em;margin-left:1.2em;text-indent:-1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
h1,h2{letter-spacing:-.01em}
dt,th.tableblock,td.content{text-rendering:optimizeLegibility}
p,td.content{letter-spacing:-.01em}
p strong,td.content strong{letter-spacing:-.005em}
p,blockquote,dt,td.content{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after,a[href^="mailto:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img{page-break-inside:avoid}
thead{display:table-header-group}
img{max-width:100%!important}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.4.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>LSDTopoTools for Geomorphology, Hydrology, Ecology and Environmental Sciences</h1>
<div class="details">
<span id="author" class="author">Simon Marius Mudd</span><br>
<span id="author2" class="author">David Milodowski</span><br>
<span id="author3" class="author">Stuart Grieve</span><br>
<span id="author4" class="author">Fiona Clubb</span><br>
<span id="author5" class="author">Martin Hurst</span><br>
<span id="author6" class="author">Declan Valters</span><br>
<span id="author7" class="author">Marie-Alice Harel</span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_preface_by_simon_m_mudd">Preface by Simon M. Mudd</a></li>
<li><a href="#_overview_of_the_book">Overview of the book</a></li>
<li><a href="#_introduction">1. Introduction</a>
<ul class="sectlevel2">
<li><a href="#_what_is_this_software">1.1. What is this software?</a></li>
<li><a href="#_why_don_t_we_just_use_arcmap_qgis_it_has_topographic_analysis_tools">1.2. Why don&#8217;t we just use ArcMap/QGIS? It has topographic analysis tools.</a></li>
<li><a href="#_quickstart_for_those_who_don_t_want_to_read_the_first_4_chapters">1.3. Quickstart for those who don&#8217;t want to read the first 4 chapters</a></li>
</ul>
</li>
<li><a href="#_required_and_useful_software">2. Required and useful software</a>
<ul class="sectlevel2">
<li><a href="#_essential_software">2.1. Essential software</a>
<ul class="sectlevel3">
<li><a href="#_git">2.1.1. Git</a></li>
<li><a href="#_a_compiler_and_other_tools_associated_with_the_source_code">2.1.2. A compiler and other tools associated with the source code</a></li>
<li><a href="#_gdal">2.1.3. GDAL</a></li>
<li><a href="#_python">2.1.4. Python</a></li>
</ul>
</li>
<li><a href="#_nonessential_software">2.2. Nonessential software</a>
<ul class="sectlevel3">
<li><a href="#_an_open_source_gis_qgis">2.2.1. An open source GIS: QGIS</a></li>
<li><a href="#_documentation_using_asciidoctor">2.2.2. Documentation using asciidoctor</a></li>
</ul>
</li>
<li><a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">2.3. Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a>
<ul class="sectlevel3">
<li><a href="#_first_steps_starting_a_vagrant_box">2.3.1. First steps: Starting a Vagrant box</a></li>
<li><a href="#_logging_on_to_your_vagrant_box">2.3.2. Logging on to your Vagrant box</a></li>
<li><a href="#_your_vagrant_box_and_file_synching">2.3.3. Your Vagrant box and file synching</a></li>
<li><a href="#_shutting_things_down">2.3.4. Shutting things down</a></li>
<li><a href="#_brief_notes_for_setting_up_your_own_vagrant_server">2.3.5. Brief notes for setting up your own Vagrant server</a></li>
</ul>
</li>
<li><a href="#_getting_python_running">2.4. Getting python running</a>
<ul class="sectlevel3">
<li><a href="#_getting_python_running_on_linux_and_this_should_also_work_for_osx">2.4.1. Getting python running on Linux (and this should also work for OSX)</a></li>
<li><a href="#_installing_python_on_windows">2.4.2. Installing python on Windows</a></li>
<li><a href="#_using_miniconda_to_install_the_relevant_python_packages_in_windows">2.4.3. Using Miniconda to install the relevant python packages in Windows</a></li>
</ul>
</li>
<li><a href="#_summary">2.5. Summary</a></li>
</ul>
</li>
<li><a href="#_preliminary_steps">3. Preliminary steps</a>
<ul class="sectlevel2">
<li><a href="#_the_terminal_and_powershells">3.1. The terminal and powershells</a></li>
<li><a href="#_topographic_data">3.2. Topographic data</a></li>
<li><a href="#_data_sources">3.3. Data sources</a>
<ul class="sectlevel3">
<li><a href="#_what_data_does_lsdtopotoolbox_take">3.3.1. What data does LSDTopoToolbox take?</a></li>
<li><a href="#_downloading_data">3.3.2. Downloading data</a></li>
</ul>
</li>
<li><a href="#_projections_and_transformations">3.4. Projections and transformations</a></li>
<li><a href="#_gdal_2">3.5. GDAL</a>
<ul class="sectlevel3">
<li><a href="#finding-out-what-sort-of-data-youve-got">3.5.1. Finding out what sort of data you&#8217;ve got</a></li>
<li><a href="#translating-your-raster-into-something-that-can-be-used-by-lsdtopotoolbox">3.5.2. Translating your raster into something that can be used by LSDTopoToolbox</a></li>
<li><a href="#clipping-rasters-with-gdal">3.5.3. Clipping rasters with gdal</a></li>
</ul>
</li>
<li><a href="#_looking_at_your_data_before_you_do_anything_with_it">3.6. Looking at your data (before you do anything with it).</a>
<ul class="sectlevel3">
<li><a href="#_our_lightweight_python_mapping_tools">3.6.1. Our lightweight python mapping tools</a></li>
</ul>
</li>
<li><a href="#_summary_2">3.7. Summary</a></li>
</ul>
</li>
<li><a href="#_getting_lsdtopotools">4. Getting LSDTopoTools</a>
<ul class="sectlevel2">
<li><a href="#_how_the_code_is_structured">4.1. How the code is structured</a>
<ul class="sectlevel3">
<li><a href="#_compiling_the_code">4.1.1. Compiling the code</a></li>
<li><a href="#_driver_functions_objects_and_libraries">4.1.2. Driver functions, objects and libraries</a></li>
<li><a href="#_the_typical_directory_layout">4.1.3. The typical directory layout</a></li>
</ul>
</li>
<li><a href="#_getting_the_code_using_git">4.2. Getting the code using Git</a>
<ul class="sectlevel3">
<li><a href="#_getting_started_with_git">4.2.1. Getting started with Git</a></li>
<li><a href="#_pulling_a_repository_from_github">4.2.2. Pulling a repository from Github</a></li>
<li><a href="#_making_your_own_repository">4.2.3. Making your own repository</a></li>
</ul>
</li>
<li><a href="#_where_to_get_the_code">4.3. Where to get the code</a>
<ul class="sectlevel3">
<li><a href="#_latest_release_versions_on_github">4.3.1. Latest release versions on GitHub</a></li>
<li><a href="#_csdms">4.3.2. CSDMS</a></li>
</ul>
</li>
<li><a href="#_summary_3">4.4. Summary</a></li>
</ul>
</li>
<li><a href="#_first_analysis">5. First Analysis</a>
<ul class="sectlevel2">
<li><a href="#_preparing_your_data_and_folders">5.1. Preparing your data and folders</a></li>
<li><a href="#_get_and_compile_your_first_lsdtopotools_program">5.2. Get and compile your first LSDTopoTools program</a>
<ul class="sectlevel3">
<li><a href="#_clone_the_code_from_git">5.2.1. Clone the code from Git</a></li>
<li><a href="#_if_you_would_rather_not_use_code_git_code">5.2.2. If you would rather not use <code>git</code></a></li>
<li><a href="#_compile_the_code">5.2.3. Compile the code</a></li>
</ul>
</li>
<li><a href="#_running_your_first_analysis">5.3. Running your first analysis</a>
<ul class="sectlevel3">
<li><a href="#_first_analysis_example_data">5.3.1. First analysis: example data</a></li>
<li><a href="#_placing_the_paramfile">5.3.2. Placing the paramfile</a></li>
<li><a href="#_modifying_the_parameter_file">5.3.3. Modifying the parameter file</a></li>
<li><a href="#_running_the_analyses_in_this_case_writing_fill_and_hillshade_rasters">5.3.4. Running the analyses (in this case, writing fill and hillshade rasters)</a></li>
<li><a href="#_look_at_the_output">5.3.5. Look at the output</a></li>
</ul>
</li>
<li><a href="#_summary_4">5.4. Summary</a></li>
</ul>
</li>
<li><a href="#_simple_surface_metrics_slope_curvature_aspect_etc">6. Simple surface metrics (slope, curvature, aspect, etc)</a>
<ul class="sectlevel2">
<li><a href="#_modifying_the_parameter_file_2">6.1. Modifying the parameter file</a></li>
<li><a href="#_running_the_analyses_in_this_case_writing_fill_and_hillshade_rasters_2">6.2. Running the analyses (in this case, writing fill and hillshade rasters)</a></li>
<li><a href="#_summary_5">6.3. Summary</a></li>
</ul>
</li>
<li><a href="#_channel_extraction">7. Channel extraction</a>
<ul class="sectlevel2">
<li><a href="#_get_the_code_for_channel_extraction">7.1. Get the code for channel extraction</a>
<ul class="sectlevel3">
<li><a href="#_clone_the_github_repository">7.1.1. Clone the GitHub repository</a></li>
<li><a href="#_alternatively_get_the_zipped_code">7.1.2. Alternatively, get the zipped code</a></li>
<li><a href="#_get_the_example_datasets">7.1.3. Get the example datasets</a></li>
<li><a href="#_get_the_example_parameter_files">7.1.4. Get the example parameter files</a></li>
</ul>
</li>
<li><a href="#_basic_channel_extraction_using_thresholds">7.2. Basic channel extraction using thresholds</a>
<ul class="sectlevel3">
<li><a href="#_compile_the_code_2">7.2.1. Compile the code</a></li>
<li><a href="#_run_the_analysis">7.2.2. Run the analysis</a></li>
</ul>
</li>
<li><a href="#_geometric_channel_extraction_methods">7.3. Geometric channel extraction methods</a>
<ul class="sectlevel3">
<li><a href="#_geonet_external_software">7.3.1. Geonet (external software)</a></li>
<li><a href="#_pelletier">7.3.2. Pelletier</a></li>
<li><a href="#_the_lsdtopotools_geometric_method">7.3.3. The LSDTopoTools geometric method</a></li>
</ul>
</li>
<li><a href="#_channel_extraction_using_the_dreich_method">7.4. Channel extraction using the Dreich method</a>
<ul class="sectlevel3">
<li><a href="#_run_the_chi_analysis">7.4.1. Run the chi analysis</a></li>
<li><a href="#_compile_the_code_5">7.4.2. Compile the code</a></li>
<li><a href="#_run_the_analysis_4">7.4.3. Run the analysis</a></li>
</ul>
</li>
<li><a href="#_summary_6">7.5. Summary</a></li>
</ul>
</li>
<li><a href="#_selecting_a_window_size">8. Selecting A Window Size</a>
<ul class="sectlevel2">
<li><a href="#_overview">8.1. Overview</a></li>
<li><a href="#_input_data">8.2. Input Data</a></li>
<li><a href="#_compile_the_driver">8.3. Compile The Driver</a></li>
<li><a href="#_run_the_code">8.4. Run The Code</a></li>
<li><a href="#_the_output_data">8.5. The Output Data</a></li>
<li><a href="#_using_python_to_select_a_window_size">8.6. Using Python To Select A Window Size</a></li>
</ul>
</li>
<li><a href="#_extracting_hillslope_lengths">9. Extracting Hillslope Lengths</a>
<ul class="sectlevel2">
<li><a href="#_overview_2">9.1. Overview</a></li>
<li><a href="#_input_data_2">9.2. Input Data</a></li>
<li><a href="#_compile_the_driver_2">9.3. Compile The Driver</a></li>
<li><a href="#_run_the_hillslope_length_driver">9.4. Run The Hillslope Length Driver</a></li>
<li><a href="#_analysing_the_results">9.5. Analysing The Results</a>
<ul class="sectlevel3">
<li><a href="#__prefix_paper_data_txt">9.5.1. &lt;Prefix&gt;_Paper_Data.txt</a></li>
<li><a href="#__prefix_hilltopdata_csv">9.5.2. &lt;Prefix&gt;_HilltopData.csv</a></li>
<li><a href="#_trace_files">9.5.3. Trace Files</a></li>
</ul>
</li>
<li><a href="#_worked_example">9.6. Worked Example</a>
<ul class="sectlevel3">
<li><a href="#_getting_the_data">9.6.1. Getting the data</a></li>
<li><a href="#_getting_the_code">9.6.2. Getting The Code</a></li>
<li><a href="#_running_the_code">9.6.3. Running The Code</a></li>
<li><a href="#_plotting_data">9.6.4. Plotting Data</a></li>
</ul>
</li>
<li><a href="#_summary_7">9.7. Summary</a></li>
</ul>
</li>
<li><a href="#_dimensionless_erosion_and_relief">10. Dimensionless Erosion and Relief</a>
<ul class="sectlevel2">
<li><a href="#_get_the_code_for_dimensionless_erosion_and_relief_analysis">10.1. Get the code for dimensionless erosion and relief analysis</a>
<ul class="sectlevel3">
<li><a href="#_clone_the_github_repository_2">10.1.1. Clone the GitHub repository</a></li>
<li><a href="#_alternatively_get_the_zipped_code_2">10.1.2. Alternatively, get the zipped code</a></li>
<li><a href="#_get_the_python_code">10.1.3. Get the Python code</a></li>
<li><a href="#_checking_your_python_package_versions">10.1.4. Checking your Python package versions</a></li>
<li><a href="#_get_the_example_datasets_2">10.1.5. Get the example datasets</a></li>
</ul>
</li>
<li><a href="#_processing_high_resolution_topography">10.2. Processing High Resolution Topography</a></li>
<li><a href="#_input_data_3">10.3. Input Data</a></li>
<li><a href="#_compile_the_driver_3">10.4. Compile The Driver</a></li>
<li><a href="#_run_the_code_2">10.5. Run the code</a></li>
<li><a href="#_analyzing_dimensionless_relationships">10.6. Analyzing Dimensionless Relationships</a>
<ul class="sectlevel3">
<li><a href="#_density_plot">10.6.1. Density Plot</a></li>
<li><a href="#_hilltop_patch_plot">10.6.2. Hilltop Patch Plot</a></li>
<li><a href="#_binned_plot">10.6.3. Binned Plot</a></li>
<li><a href="#_fitting_the_critical_gradient">10.6.4. Fitting The Critical Gradient</a></li>
</ul>
</li>
<li><a href="#_summary_8">10.7. Summary</a></li>
</ul>
</li>
<li><a href="#_chi_analysis">11. Chi analysis</a>
<ul class="sectlevel2">
<li><a href="#_background_to_chi_analysis">11.1. Background to chi analysis</a>
<ul class="sectlevel3">
<li><a href="#_topographic_expression_of_climate_tectonics_and_lithology">11.1.1. Topographic expression of climate, tectonics, and lithology</a></li>
</ul>
</li>
<li><a href="#_get_the_chi_analysis_tools">11.2. Get the chi analysis tools</a>
<ul class="sectlevel3">
<li><a href="#_clone_the_code_from_git_2">11.2.1. Clone the code from Git</a></li>
<li><a href="#_compile_the_code_6">11.2.2. Compile the code</a></li>
<li><a href="#_get_some_example_data">11.2.3. Get some example data</a></li>
</ul>
</li>
<li><a href="#_chi_analysis_part_1_getting_the_channel_profiles">11.3. Chi analysis, part 1: getting the channel profiles</a>
<ul class="sectlevel3">
<li><a href="#_overview_3">11.3.1. Overview</a></li>
<li><a href="#_running_the_channel_network_extraction">11.3.2. Running the channel network extraction</a></li>
</ul>
</li>
<li><a href="#_chi_profile_analysis_part_2_constraining_m_n_and_transforming_profiles">11.4. Chi profile analysis, part 2: constraining m/n and transforming profiles</a>
<ul class="sectlevel3">
<li><a href="#_steps_involved_to_perform_channel_analysis">11.4.1. Steps involved to perform channel analysis</a></li>
<li><a href="#_performing_a_statistical_analysis_to_constrain_the_best_fit_m_n_ratio">11.4.2. Performing a statistical analysis to constrain the best fit m/n ratio</a></li>
<li><a href="#_the_code_tree_code_file">11.4.3. The <code>.tree</code> file</a></li>
<li><a href="#_visualizing_the_analysis">11.4.4. Visualizing the analysis</a></li>
<li><a href="#_a_sample_chi_analysis_workflow">11.4.5. A Sample Chi Analysis Workflow</a></li>
</ul>
</li>
<li><a href="#_chi_analysis_part_3_getting_chi_gradients_for_the_entire_landscape">11.5. Chi analysis part 3: Getting chi gradients for the entire landscape</a>
<ul class="sectlevel3">
<li><a href="#_compile_the_code_7">11.5.1. Compile the code</a></li>
<li><a href="#_run_the_map_chi_gradient_tool">11.5.2. Run the map chi gradient tool</a></li>
</ul>
</li>
<li><a href="#_summary_9">11.6. Summary</a></li>
</ul>
</li>
<li><a href="#_basin_averaged_cosmogenic_analysis">12. Basin averaged cosmogenic analysis</a>
<ul class="sectlevel2">
<li><a href="#_get_the_code_and_data_basin_averaged_cosmogenic_analysis">12.1. Get the code and data basin-averaged cosmogenic analysis</a>
<ul class="sectlevel3">
<li><a href="#_get_the_source_code_for_basin_averaged_cosmogenics">12.1.1. Get the source code for basin-averaged cosmogenics</a></li>
<li><a href="#_getting_example_data_the_san_bernardino_mountains">12.1.2. Getting example data: The San Bernardino Mountains</a></li>
<li><a href="#_setting_up_your_data_directories_and_parameter_files">12.1.3. Setting up your data directories and parameter files</a></li>
<li><a href="#_modifying_your_crnrasters_file_the_python_way">12.1.4. Modifying your CRNRasters file the python way</a></li>
</ul>
</li>
<li><a href="#_calculating_topographic_shielding">12.2. Calculating Topographic Shielding</a>
<ul class="sectlevel3">
<li><a href="#_steps_for_preparing_the_rasters_for_shielding_calculations">12.2.1. Steps for preparing the rasters for shielding calculations</a></li>
<li><a href="#_the_shielding_computation">12.2.2. The shielding computation</a></li>
<li><a href="#_embarrassingly_parallel_shielding">12.2.3. Embarrassingly parallel shielding</a></li>
<li><a href="#_once_you_have_finished_with_spawning_and_topographic_shielding_calculations">12.2.4. Once you have finished with spawning and topographic shielding calculations</a></li>
<li><a href="#_stand_alone_topographic_shielding_calculations">12.2.5. Stand alone topographic shielding calculations</a></li>
</ul>
</li>
<li><a href="#_snow_shielding_calculations">12.3. Snow shielding calculations</a>
<ul class="sectlevel3">
<li><a href="#_using_previously_reported_snow_shielding">12.3.1. Using previously reported snow shielding</a></li>
<li><a href="#_assign_a_single_effective_average_depth">12.3.2. Assign a single effective average depth</a></li>
<li><a href="#_pass_a_raster_of_effective_average_depth_of_snow_over_a_catchment">12.3.3. Pass a raster of effective average depth of snow over a catchment</a></li>
</ul>
</li>
<li><a href="#_calculating_denudation_rates">12.4. Calculating denudation rates</a>
<ul class="sectlevel3">
<li><a href="#_compiling_the_code_3">12.4.1. Compiling the code</a></li>
<li><a href="#_running_the_basin_averaged_denudation_rate_calculator">12.4.2. Running the basin averaged denudation rate calculator</a></li>
<li><a href="#_the_output_files">12.4.3. The output files</a></li>
</ul>
</li>
<li><a href="#_summary_10">12.5. Summary</a></li>
</ul>
</li>
<li><a href="#_swath_profiling_tools">13. Swath Profiling Tools</a>
<ul class="sectlevel2">
<li><a href="#_generalised_swath_profile">13.1. Generalised Swath Profile</a>
<ul class="sectlevel3">
<li><a href="#_preprocessing_step_1_getting_your_raster_into_the_correct_format">13.1.1. Preprocessing step 1: Getting your raster into the correct format</a></li>
<li><a href="#_preprocessing_step_2_creating_the_baseline">13.1.2. Preprocessing step 2: Creating the baseline</a></li>
<li><a href="#_compiling_the_driver_function">13.1.3. Compiling the driver function</a></li>
<li><a href="#_running_the_driver_function">13.1.4. Running the driver function</a></li>
<li><a href="#_program_outputs">13.1.5. Program outputs</a></li>
</ul>
</li>
<li><a href="#_channel_long_profile_swaths">13.2. Channel Long Profile Swaths</a>
<ul class="sectlevel3">
<li><a href="#_example_applications">13.2.1. Example Applications</a></li>
<li><a href="#_example_usage">13.2.2. Example Usage</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_hydrological_and_erosion_modelling">14. Hydrological and Erosion Modelling</a>
<ul class="sectlevel2">
<li><a href="#_origins_relation_to_caesar_lisflood">14.1. Origins: relation to CAESAR-Lisflood</a></li>
<li><a href="#_compilation">14.2. Compilation</a>
<ul class="sectlevel3">
<li><a href="#_dependencies">14.2.1. Dependencies</a></li>
</ul>
</li>
<li><a href="#_running_the_model">14.3. Running the Model</a>
<ul class="sectlevel3">
<li><a href="#_dem_preparation">14.3.1. DEM preparation</a></li>
<li><a href="#_model_run_time_controls">14.3.2. Model run time controls</a></li>
<li><a href="#_parameter_file_overview">14.3.3. Parameter File Overview</a></li>
<li><a href="#_input_files">14.3.4. Input files</a></li>
</ul>
</li>
<li><a href="#_parameter_guide">14.4. Parameter Guide</a>
<ul class="sectlevel3">
<li><a href="#_file_information">14.4.1. File Information</a></li>
<li><a href="#_supplementary_files">14.4.2. Supplementary Files</a></li>
<li><a href="#_numerical">14.4.3. Numerical</a></li>
<li><a href="#_sediment">14.4.4. Sediment</a></li>
<li><a href="#_hydrology">14.4.5. Hydrology</a></li>
<li><a href="#_vegetation">14.4.6. Vegetation</a></li>
<li><a href="#_hillslope">14.4.7. Hillslope</a></li>
<li><a href="#_write_output_rasters">14.4.8. Write Output Rasters</a></li>
</ul>
</li>
<li><a href="#_running_the_code_in_parallel">14.5. Running the code in Parallel</a></li>
<li><a href="#_notes_for_hpc_use">14.6. Notes for HPC use</a></li>
</ul>
</li>
<li><a href="#_landscape_evolution_modelling_with_lsdtopotools">15. Landscape Evolution Modelling with LSDTopoTools</a>
<ul class="sectlevel2">
<li><a href="#_model_parameters_and_components">15.1. Model Parameters and Components</a>
<ul class="sectlevel3">
<li><a href="#_model_domain">15.1.1. Model Domain</a></li>
<li><a href="#_fluvial_component">15.1.2. Fluvial Component</a></li>
<li><a href="#_hillslope_component">15.1.3. Hillslope Component</a></li>
</ul>
</li>
<li><a href="#_running_the_model_2">15.2. Running the Model</a></li>
<li><a href="#_model_output">15.3. Model Output</a></li>
</ul>
</li>
<li><a href="#_software">Appendix A: Software</a>
<ul class="sectlevel2">
<li><a href="#_essentials">A.1. Essentials</a>
<ul class="sectlevel3">
<li><a href="#_git_2">A.1.1. Git</a></li>
<li><a href="#_c_tools">A.1.2. C++ tools</a></li>
<li><a href="#_python_2">A.1.3. Python</a></li>
<li><a href="#_gdal_3">A.1.4. GDAL</a></li>
</ul>
</li>
<li><a href="#_useful_extras">A.2. Useful extras</a>
<ul class="sectlevel3">
<li><a href="#_a_virtual_machine">A.2.1. A virtual machine</a></li>
<li><a href="#_geographic_information_software">A.2.2. Geographic Information Software</a></li>
<li><a href="#_ruby">A.2.3. Ruby</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_setting_up_on_windows">Appendix B: Setting up on Windows</a>
<ul class="sectlevel2">
<li><a href="#_working_with_the_powershell">B.1. Working with the powershell</a>
<ul class="sectlevel3">
<li><a href="#_starting_a_powershell_session">B.1.1. Starting a powershell session</a></li>
</ul>
</li>
<li><a href="#_windows_installation_programs">B.2. Windows installation programs</a>
<ul class="sectlevel3">
<li><a href="#_package_management">B.2.1. Package management</a></li>
<li><a href="#_git_3">B.2.2. Git</a></li>
</ul>
</li>
<li><a href="#_tools_for_c">B.3. Tools for C++</a>
<ul class="sectlevel3">
<li><a href="#_cygwin">B.3.1. Cygwin</a></li>
<li><a href="#_c_libraries">B.3.2. C++ libraries</a></li>
</ul>
</li>
<li><a href="#_python_3">B.4. Python</a></li>
<li><a href="#_gdal_windows_installation">B.5. GDAL windows installation</a></li>
<li><a href="#_ruby_2">B.6. Ruby</a>
<ul class="sectlevel3">
<li><a href="#_install_ruby_version_1">B.6.1. Install Ruby (version 1)</a></li>
<li><a href="#_install_ruby_using_choco">B.6.2. Install Ruby using choco</a></li>
<li><a href="#_fix_rubygems_on_windows">B.6.3. Fix rubygems on Windows</a></li>
<li><a href="#_fix_rubydevkit_on_windows">B.6.4. Fix RubyDevKit on Windows</a></li>
<li><a href="#_install_some_gems">B.6.5. Install some gems</a></li>
<li><a href="#_if_you_use_ruby_with_java_you_will_probably_not_need_this">B.6.6. If you use Ruby with Java (you will probably not need this)</a></li>
</ul>
</li>
<li><a href="#_windows_installation_summary">B.7. Windows installation summary</a></li>
<li><a href="#_turning_your_windows_machine_into_a_linux_machine">B.8. Turning your windows machine into a Linux machine</a></li>
<li><a href="#_summary_11">B.9. Summary</a></li>
</ul>
</li>
<li><a href="#_setting_up_on_linux">Appendix C: Setting up on Linux</a>
<ul class="sectlevel2">
<li><a href="#_git_4">C.1. Git</a></li>
<li><a href="#_c_tools_2">C.2. C++ tools</a>
<ul class="sectlevel3">
<li><a href="#_c_libraries_2">C.2.1. C++ libraries</a></li>
</ul>
</li>
<li><a href="#_the_swath_and_point_cloud_tools">C.3. The Swath and Point Cloud tools</a>
<ul class="sectlevel3">
<li><a href="#_pcl">C.3.1. PCL</a></li>
<li><a href="#_liblas">C.3.2. libLAS</a></li>
</ul>
</li>
<li><a href="#_python_4">C.4. Python</a>
<ul class="sectlevel3">
<li><a href="#_installing_python">C.4.1. Installing python</a></li>
<li><a href="#_installing_python_packages">C.4.2. Installing python packages</a></li>
</ul>
</li>
<li><a href="#_ruby_3">C.5. Ruby</a>
<ul class="sectlevel3">
<li><a href="#_installing_the_asciidoctor_documentation_software">C.5.1. Installing the asciidoctor documentation software</a></li>
</ul>
</li>
<li><a href="#_cloning_or_forking_the_documentation">C.6. Cloning or forking the documentation</a></li>
<li><a href="#_summary_12">C.7. Summary</a></li>
</ul>
</li>
<li><a href="#_code_structure">Appendix D: Code Structure</a>
<ul class="sectlevel2">
<li><a href="#_source_files_drivers_headers_and_implementaions">D.1. Source Files: Drivers, Headers, and Implementaions.</a></li>
<li><a href="#_a_closer_look_at_the_source_files">D.2. A closer look at the source files</a>
<ul class="sectlevel3">
<li><a href="#_lsdraster">D.2.1. LSDRaster</a></li>
<li><a href="#_lsdindexraster">D.2.2. LSDIndexRaster</a></li>
<li><a href="#_lsdflowinfo">D.2.3. LSDFlowInfo</a></li>
<li><a href="#_lsdindexchannel">D.2.4. LSDIndexChannel</a></li>
<li><a href="#_lsdchannel">D.2.5. LSDChannel</a></li>
<li><a href="#_lsdjunctionnetwork">D.2.6. LSDJunctionNetwork</a></li>
<li><a href="#_lsdindexchanneltree">D.2.7. LSDIndexChannelTree</a></li>
<li><a href="#_lsdchinetwork">D.2.8. LSDChiNetwork</a></li>
<li><a href="#_lsdmostlikelypartitionsfinder">D.2.9. LSDMostLikelyPartitionsFinder</a></li>
<li><a href="#_lsdstatstools">D.2.10. LSDStatsTools</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_analysis_driver_options">Appendix E: Analysis Driver Options</a>
<ul class="sectlevel2">
<li><a href="#_analysisdriver_file_input_and_output_options">E.1. AnalysisDriver file input and output options</a></li>
<li><a href="#_analysisdriver_files_to_write">E.2. AnalysisDriver files to write</a></li>
<li><a href="#_analysisdriver_parameter_values">E.3. AnalysisDriver parameter values</a>
<ul class="sectlevel3">
<li><a href="#_parameters_for_the_fill_function">E.3.1. Parameters for the fill function</a></li>
<li><a href="#_parameters_for_hillshading">E.3.2. Parameters for hillshading</a></li>
<li><a href="#_parameters_for_flow_info_calculations">E.3.3. Parameters for flow info calculations</a></li>
<li><a href="#_parameters_for_chi_calculations">E.3.4. Parameters for chi calculations</a></li>
<li><a href="#_parameters_for_polyfit_and_slope_calculations">E.3.5. Parameters for polyfit and slope calculations</a></li>
<li><a href="#_parameters_for_drainage_area_extraction">E.3.6. Parameters for drainage area extraction</a></li>
<li><a href="#_parameters_for_single_thread_channel_extraction">E.3.7. Parameters for single thread channel extraction</a></li>
<li><a href="#_parameters_for_area_threshold_channel_extraction">E.3.8. Parameters for area threshold channel extraction</a></li>
<li><a href="#_parameters_for_hydrology_and_slope_stability">E.3.9. Parameters for hydrology and slope stability</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_appendix_f_tools_for_viewing_data">Appendix F: Appendix F: Tools for viewing data</a>
<ul class="sectlevel2">
<li><a href="#_arcmap">F.1. ArcMap</a></li>
<li><a href="#_qgis">F.2. QGIS</a></li>
<li><a href="#_lsdtopotools_python_mapping_functions">F.3. LSDTopoTools python mapping functions</a></li>
<li><a href="#_summary_13">F.4. Summary</a></li>
</ul>
</li>
<li><a href="#_appendix_g_automation_and_supercomputing_for_lsdtopotools">Appendix G: Appendix G: Automation and Supercomputing for LSDTopoTools</a>
<ul class="sectlevel2">
<li><a href="#_embarassingly_parallel_topographic_analysis">G.1. Embarassingly Parallel Topographic Analysis</a>
<ul class="sectlevel3">
<li><a href="#_the_simple_case_a_single_cpu_multi_core_laptop">G.1.1. The Simple Case - A single cpu, multi-core laptop</a></li>
</ul>
</li>
<li><a href="#_topographic_analysis_on_a_supercomputer">G.2. Topographic Analysis on a Supercomputer</a>
<ul class="sectlevel3">
<li><a href="#_launching_jobs_with_the_batch_system">G.2.1. Launching jobs with the batch system</a></li>
<li><a href="#_checking_your_jobs">G.2.2. Checking your jobs</a></li>
</ul>
</li>
<li><a href="#_module_issues">G.3. Module issues</a></li>
<li><a href="#_compilation_and_library_issues">G.4. Compilation and library issues</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="imageblock">
<div class="content">
<img src="images/LSD-logo.png" alt="LSD logo" width="400">
</div>
<div class="title">Figure 1. LSD logo</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_preface_by_simon_m_mudd">Preface by Simon M. Mudd</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Welcome to the documentation of the <a href="https://lsdtopotools.github.io/">LSDTopoTools</a>.
This is, I am sure, obvious, but LSD stands for Land Surface Dynamics,
and is named after the <a href="http://www.geos.ed.ac.uk/research/globalchange/group3/">Land Surface Dynamics research cluster</a>
in the <a href="http://www.ed.ac.uk/schools-departments/geosciences/">School of GeoSciences</a> at the <a href="http://www.ed.ac.uk/home">University of Edinburgh</a>.</p>
</div>
<div class="paragraph">
<p>The project started around 2010 due to my increasing frustration with my inability to reproduce topographic analyses that I found in papers and saw at conferences.
Some of the papers that had irreproducible analyses were my own!
Like many scientists working with topographic data, I was using a geographic information system (GIS) to prepare figures and analyze topography,
and after a long session of clicking on commercial software to get just that right figure,
I did not have a record of the steps I took to get there. <strong>Mea culpa</strong>.
However, I do not think I am the only person guilty of doing this!
I wanted a way of doing topographic analysis that did not involve a sequence of mouse clicks.</p>
</div>
<div class="paragraph">
<p>A second motivation came when my PhD student, <a href="http://www.bgs.ac.uk/staff/profiles/41289.html">Martin Hurst</a>,
finished his PhD and left Edinburgh for warmer pastures in England.
His PhD included several novel analyses that were
<a href="http://onlinelibrary.wiley.com/doi/10.1029/2011JF002057/full">clearly</a>
<a href="http://onlinelibrary.wiley.com/doi/10.1002/jgrf.20049/full">very</a>
<a href="http://www.sciencemag.org/content/341/6148/868.short">useful</a>,
but also built using the python functionality in a certain commercial GIS and not very portable.
I and my other PhD students wanted to run Martin&#8217;s analyses on other landscapes,
but this proved to be a painful process that required numerous emails and telephone calls between Martin and our group.</p>
</div>
<div class="paragraph">
<p>This motivated me to start writing my own software for dealing with topographic data.
This seemed crazy at the time. Why were we trying to reinvent a GIS?
The answer is that the resulting software, <a href="https://lsdtopotools.github.io/">LSDTopoTools</a>,
<strong>IS NOT A GIS</strong>! It is a series of algorithms that are open-source and can be used to analyze topography,
and the programs that run these analyses, which we call driver programs,
are intended to be redistributed such that if you have the same topographic data as was used in the original analysis,
you should be able to reproduce the analysis <strong>exactly</strong>.
In addition the philosophy of my research group is that each of our publications will coincide with the release of the software used to generate the figures: we made the (often frightening) decision that there would be no hiding behind cherry-picked figures.
(Of course, our figures in our papers are chosen to be good illustrations of some landscape property,
but other researchers can always use our code to fide the ugly examples as well).</p>
</div>
<div class="paragraph">
<p>We hope that others outside our group will find our tools useful, and this document will help users get our tools working on their systems.
I do plead for patience: we have yet to involve anyone in the project that has any formal computer science of software engineering training!
But we do hope to distribute beyond the walls of the <a href="http://www.ed.ac.uk/schools-departments/geosciences/">School of GeoScience at the University of Edinburgh</a>,
so please contact us for help, questions or suggestions.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_overview_of_the_book">Overview of the book</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The purpose of this book is both to get you started using <a href="https://lsdtopotools.github.io/">LSDTopoTools</a>,
and thus the early chapters contain both pre-requisite material and tutorials.
The latter stages of the book are dedicated to using our driver functions (these are programs that are used to perform specific analyses).
This latter part of the book focuses on research applications;
we tend to write a series of driver functions for our publications which aim to each give some new
geophysical, hydrological or ecological insight into the functioning of landscapes.
Thus the latter half of the book is both long an not really structured like a textbook, and will expand as we conduct research.
However, for those simply interested in learning how to get the code working and to perform some "routine" analyses the initial chapters are structured more like a book.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
By routine I mean something that is accepted by most professionals such as basin extraction or gradient calculations, and is not likely to be controversial.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><strong>Chapter 1</strong> goes into some more detail about the motivation behind the software,
and involves a bit of commentary about open science.
You are probably safe to skip that chapter if you do not like opinions.</p>
</div>
<div class="paragraph">
<p><strong>Chapter 2</strong> is a brief overview of the software you will need to get our software working on your computer,
although the details about how to install things is mainly relegated to the appendices.</p>
</div>
<div class="paragraph">
<p><strong>Chapter 3</strong> describes the preliminary steps you need to take with your topographic data
in order to get it into our software. If you have read about or taken a course on GIS, this will be vaguely familiar.
It will introduce <a href="http://www.gdal.org/">GDAL</a>, which we find to be much better than commercial software for common tasks such as projections,
coordinate transformations and merging of data.</p>
</div>
<div class="paragraph">
<p><strong>Chapter 4</strong> explains how to get our software from its various <a href="https://github.com/">Github</a> repositories,
and has some basic details about the structure of the software.</p>
</div>
<div class="paragraph">
<p><strong>Chapters 5-6</strong> are the tutorial component of the book, and have been used in courses at the University of Edinburgh.</p>
</div>
<div class="paragraph">
<p>*The chapters thereafter consist of documentation of our driver functions that have been used for research, many of which feature in published papers.</p>
</div>
<div class="paragraph">
<p><strong>Appendix A</strong> gives more detail about required software to get our package running.</p>
</div>
<div class="paragraph">
<p><strong>Appendix B</strong> explains how to get LSDTopoTools running on Windows.
It contains a quite a bit of text about why you don&#8217;t really want to install our software on Windows,
since installation is much more reliable, functional, and easy on Linux. Don&#8217;t worry if you don&#8217;t have a Linux computer!
We will explain how to create a "virtual" Linux computer on your Windows computer.
This description of creating a virtual Linux machine should also work for users of OS X.</p>
</div>
<div class="paragraph">
<p><strong>Appendix C</strong> explains how to get LSDTopoTools running on Linux.</p>
</div>
<div class="paragraph">
<p><strong>Appendix D</strong> has some more details on how the code is structured. If you are obsessive you could go one step further and look at the
<a href="http://www.geos.ed.ac.uk/~s0675405/LSD_Docs/index.html">documentation of the source code</a>.</p>
</div>
<div class="paragraph">
<p><strong>Appendix E</strong> explains the different options in the analysis driver functions, which allow simple analyses driven by a single program.</p>
</div>
<div class="paragraph">
<p><strong>Appendix F</strong> gives an overview of some of the open source visualistion tools and scripts we have developed for viewing the output of the topographic analyses, as well as other commonly used software.</p>
</div>
<div class="paragraph">
<p><strong>Appendix G</strong> explains how to get the software running in parallel computing environments, such as on your multicore laptop, a cluster computer, or supercomputing facility. It also has tips on how generate scripts to run multiple analyses.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction">1. Introduction</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_what_is_this_software">1.1. What is this software?</h3>
<div class="paragraph">
<p><a href="http://lsdtopotools.github.io/">LSDTopoTools</a> is a software package designed to analyze landscapes for applications in geomorphology, hydrology, ecology and allied fields.
It is not intended as a substitute for a GIS, but rather is designed to be a research and analysis tool that produces <strong>reproducible</strong> data.
The motivations behind its development were:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>To serve as a framework for implementing the latest developments in topographic analysis.</p>
</li>
<li>
<p>To serve as a framework for developing new topographic analysis techniques.</p>
</li>
<li>
<p>To serve as a framework for numerical modelling of landscapes (for hydrology, geomorphology and hydrology).</p>
</li>
<li>
<p>To improve the <strong>speed</strong> and <strong>performance</strong> of topographic analysis versus other tools (e.g., commercial GIS software).</p>
</li>
<li>
<p>To enable <strong>reproducible</strong> topographic analysis in the research context.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The toolbox is organized around objects, which are used to store and manipulate specific kinds of data,
and driver functions, which users write to interface with the objects.</p>
</div>
<div class="paragraph">
<p>The <a href="http://www.geos.ed.ac.uk/~s0675405/LSD_Docs/index.html">Source code documentation site</a>
tells you all about the objects: these pages get into the nitty gritty of the computational algorithms
and I only recommend looking at them if you plan on developing the code.</p>
</div>
<div class="paragraph">
<p>For most readers of this documentation,
you can exist in blissful ignorance of the implementation and simply stay on these pages to learn how to
use the software for your topographic analysis needs.</p>
</div>
</div>
<div class="sect2">
<h3 id="_why_don_t_we_just_use_arcmap_qgis_it_has_topographic_analysis_tools">1.2. Why don&#8217;t we just use ArcMap/QGIS? It has topographic analysis tools.</h3>
<div class="paragraph">
<p>One of the things our group does as geomorphologists is try to understand the physics and evolution of the Earth&#8217;s surface by analyzing topography.
Many geomorphologists will take some topographic data and perform a large number of steps to produce and original analysis.
Our code is designed to automate such steps as well as make these steps reproducible.
If you send another geomorphologist your code and data they should be able to exactly reproduce your analysis.
This is not true of work done in ArcMap or other GIS systems. ArcMap and QGIS are good at many things!
But they are not that great for analysis that can easily be reproduced by other groups.
Our software was built to do the following:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>LSDTopoTools automates things that would be slow in ArcMap.</p>
</li>
<li>
<p>LSDTopoTools is designed to be <strong>reproducible</strong>: it does not depend on one individuals mouse clicks.</p>
</li>
<li>
<p>LSDTopoTools uses the latest fast algorithms so it is much faster than ArcMap.</p>
</li>
<li>
<p>LSDTopoTools has topographic analysis algorithms designed and coded by us or designed by someone else but
coded by us soon after publication that are not available in ArcMap.</p>
</li>
<li>
<p>LSDTopoTools contains some elements of landscape evolution models which cannot be done in ArcMap.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_quickstart_for_those_who_don_t_want_to_read_the_first_4_chapters">1.3. Quickstart for those who don&#8217;t want to read the first 4 chapters</h3>
<div class="paragraph">
<p>We have prepared LSDTopoTools to be used in a <a href="https://en.wikipedia.org/wiki/Virtual_machine">Virtual Machine</a> so that you should just have to install two bits of software,
<a href="https://www.virtualbox.org/">VirtualBox</a> and <a href="https://www.vagrantup.com/">Vagrant</a>.
After that, you get a small file from one of our repositories that manages all the installation for you. More details are available in the section
<a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a>.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">The most painless way to get LSDTopoTools working (this works on any operating system!!)</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Make sure you can open a <strong>terminal or powershell window</strong>.</p>
</li>
<li>
<p>You should have around 10-20Gb of storage on your computer available.</p>
</li>
<li>
<p>Install <a href="https://www.virtualbox.org/">VirtualBox</a>.</p>
</li>
<li>
<p>Install <a href="https://www.vagrantup.com/">Vagrant</a>.</p>
</li>
<li>
<p>Make a directory to hold your vagrant boxes. I call this directory <code>VagrantBoxes</code></p>
</li>
<li>
<p>In this directory, make a directory called <code>LSDTopoTools</code>.</p>
</li>
<li>
<p>Make another directory where you will put some information about your vagrant machine.
We have used an <a href="http://www.ubuntu.com/">Ubuntu</a> operating system. Call this something sensible, like <code>Ubuntu32</code> or <code>MyLinuxBox</code> or <code>UbuntuBox</code> or something.
I will assume you have called it <code>UbuntuBox</code> for now.</p>
</li>
<li>
<p>Go into the folder <code>UbuntuBox</code>. Download one of the files from <a href="https://github.com/LSDtopotools/LSDTT_vagrantfiles" class="bare">https://github.com/LSDtopotools/LSDTT_vagrantfiles</a>. The files with <strong>32</strong> are 32-bit systems,
whereas the ones with <strong>64</strong> are 64-bit operating systems. If your computer is Linux or OSX, choose a 64 bit system.
If you are in Windows choose a 32-bit system unless you <a href="http://superuser.com/questions/866962/why-does-virtualbox-only-have-32-bit-option-no-64-bit-option-on-windows-7">know how to enable 64 bit guest operating systems</a>.
If that last sentence was confusing and you use Windows, choose 32-bit.</p>
</li>
<li>
<p>The files with <strong>FFTW</strong> in the filename allow you to do spectral analysis. They take longer to install (installation is all automated but it takes longer).</p>
</li>
<li>
<p>When you have downloaded the file, rename it <code>vagrantfile</code>.</p>
</li>
<li>
<p>In a terminal window or powershell, go to the folder with the <code>vagrantfile</code> (here in the folder <code>UbuntuBox</code>) and type <code>vagrant up</code>.</p>
</li>
<li>
<p>Go and read <a href="https://en.wikipedia.org/wiki/The_Bridge_(novel)">a book</a> or www.bbc.co.uk/sport/football/teams/hibernian[browse the internet] because this will take some time.
The first time you do this <a href="https://www.vagrantup.com/">Vagrant</a> will need to download ~0.5Gb of stuff. Hopefully you have a fast internet connection!!</p>
</li>
<li>
<p>When it finishes, you can log on to your server, which is a fully function Linux operating system, with all the necessary software installed, sitting in your host computer. Yay!</p>
</li>
<li>
<p>You need to log on to the server so you can do some LSDTopoTools analysis. If your host machine is Linux or OSX, just type <code>vagrant ssh</code>.
If your host machine is Windows, you need to download <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html">putty.exe</a> and log in with a host name of <strong>127.0.0.1</strong> and a port of <strong>2222</strong>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="paragraph">
<p>If you have your own Linux server and you like doing things by hand, here is succinct overview of what you need to do to prepare for your first analysis:</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick Instructions for if you don&#8217;t want to use Vagrant</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Make sure you can open a <strong>terminal or powershell window</strong>.</p>
</li>
<li>
<p>Make sure you have a <strong>C++ compiler</strong> (we use g++) and the <strong>make tool</strong> installed.</p>
</li>
<li>
<p>Make sure you have <strong>git</strong> installed.</p>
</li>
<li>
<p>Make sure you have the <strong>GDAL utilities</strong> installed and working.</p>
</li>
<li>
<p>Get some topographic data and convert it to <strong>projected coordinates</strong> (we prefer WGS1984 UTM projections).</p>
</li>
<li>
<p>Make sure you have <strong>python</strong> with <strong>scipy</strong> including <strong>numpy</strong> and <strong>matplotlib</strong> working on your computer.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="paragraph">
<p>If all of the above steps make sense, you can probably just implement them and move on to the <a href="#First analysis">[First analysis]</a> chapter.
Otherwise, you should continue reading from here.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_required_and_useful_software">2. Required and useful software</h2>
<div class="sectionbody">
<div class="paragraph">
<p>LSDTopoTools is a collection of programs written in C++ that crunch topographic data.
To run LSDTopoTools all that is really required is a functioning C++ <a href="https://en.wikipedia.org/wiki/Compiler">compiler</a>
(which is a program that translates C++ code into 1s and 0s that your computer can understand),
the <a href="https://www.gnu.org/software/make/">make utility</a>,
and for specific components a few extra libraries. Most analyses will not need libraries.</p>
</div>
<div class="paragraph">
<p>As a standalone bit of software, LSDTopoTools does not require vast effort in installing the required software.
However, if you want to look at the data produced by the software, or use some of our automation scripts,
you will need to install additional packages on your system.</p>
</div>
<div class="sect2">
<h3 id="_essential_software">2.1. Essential software</h3>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
This isn&#8217;t our actual software! It is all the extra bits of software that you need to get working before you can use LSDTopoTools!
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This list goes slightly beyond getting the tools alone to run;
it includes the software you need to get recent versions of the software and to visualize the output.</p>
</div>
<div class="paragraph">
<p>Instructions for installing all of these software packages are in the appendices.
There you will find instructions for <a href="#_setting_up_on_windows">installing the software on a windows operating system</a>
and for <a href="#_setting_up_on_linux">installing the software on a Linux operating system</a>.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 1. A list of the essential software</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 80%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Software</th>
<th class="tableblock halign-left valign-top">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://git-scm.com/">Git</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Version control software that you can use to grab working versions of our code from <a href="https://github.com/">Github</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">A C++ <a href="https://en.wikipedia.org/wiki/Compiler">compiler</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">For compiling our software. We use <a href="https://gcc.gnu.org/">GNU compiler</a> g++. Note that we don&#8217;t call this directly, but rather call it via the <a href="https://www.gnu.org/software/make/">make utility</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://www.gnu.org/software/make/">make</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The make utility: used to compile the code from <a href="https://en.wikipedia.org/wiki/Makefile">makefiles</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Various C++ libraries</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">For basic analysis, no libraries are needed.
For more specialized analysis, the libraries <a href="http://www.fftw.org/">FFTW</a>, <a href="http://www.boost.org/">Boost</a>, MTL and PCL are required.
See below for more information.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Python</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">We use python for both automation and vizualisation (via matplotlib).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://www.gdal.org/">GDAL</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">We use the <a href="http://www.gdal.org/gdal_utilities.html">GDAL utilities</a> to prepare our datasets,
e.g. to transform them into appropriate coordinate systems and into the correct formats.</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_git">2.1.1. Git</h4>
<div class="paragraph">
<p><a href="https://git-scm.com/">Git</a> is version control software. Version control software helps you keep track of changes to your scripts, notes, papers, etc.
It also facilitates communication and collaboration through the online communities <a href="https://github.com/">github</a> and <a href="https://bitbucket.org/">bitbucket</a>.</p>
</div>
<div class="paragraph">
<p>We post updated versions of our software to the Github site <a href="https://github.com/LSDtopotools" class="bare">https://github.com/LSDtopotools</a>.
We also post version of the software used in publications on the CSDMS github site:
<a href="https://github.com/csdms" class="bare">https://github.com/csdms</a>.</p>
</div>
<div class="paragraph">
<p>It is possible to simply download the software from these sites but if you want to keep track of our updates or modify the software it will be better if you have git installed on your computer.</p>
</div>
</div>
<div class="sect3">
<h4 id="_a_compiler_and_other_tools_associated_with_the_source_code">2.1.2. A compiler and other tools associated with the source code</h4>
<div class="paragraph">
<p>You will need a compiler to build the software, as it is written in <a href="https://en.wikipedia.org/wiki/C%2B%2B">c++</a>.
In addition you will need a few tools to go along with the compiler. The things you <strong>really</strong> need are:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>A C++ compiler. We use the <a href="https://gcc.gnu.org/">GNU compiler</a> g++.</p>
</li>
<li>
<p>The <code>make</code> utility. Most of the code is compiled by calling g++ from this utility.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>In addition the <a href="http://math.nist.gov/tnt/overview.html">TNT</a> library is required,
but this doesn&#8217;t require installation and we package it with our software releases.
If you are wondering what it is when you download our software, it is used to do linear algebra and handle matrices.</p>
</div>
<div class="paragraph">
<p>In addition, there are a few isolated bits of the code that need these other components.
Most users will not need them, but for complete functionality they are required.
First, some of our makefiles include flags for profiling and debugging.
We try to remove these before we release the code on Github,
but every now and then one sneaks through and the code won&#8217;t compile if you don&#8217;t have a debugger or profiler. It might save you some confusion down the line if you install:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The <code>gdb</code> utility. This is the gnu debugger.</p>
</li>
<li>
<p>The <code>gprof</code> utility. This allows you to see what parts of the code are taking up the most computational time.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Next, there are a few specialized tools that are only required by some of our more advanced components.</p>
</div>
<div class="sect4">
<h5 id="_requirements_for_lsdrasterspectral">Requirements for LSDRasterSpectral</h5>
<div class="paragraph">
<p>Some of our tools include spectral analysis,
and to do spectral analysis you need the <a href="http://www.fftw.org/">Fast Fourier Transform Library</a>.</p>
</div>
<div class="paragraph">
<p>In the source code, you will find <code>#include</code> statements for these libraries,
and corresponding library flags in the makefile: <code>-lfftw3</code>.
In the <code>RasterSpectral</code> source files,
we assume that you will have a fast fourier transform folder in your top level LSDTopoTools directory.
If that paragraph doesn&#8217;t make any sense to you, don&#8217;t worry.
We will go into more detail about the spectral tools within the specific chapters dedicated to those tools.
You can download FFTWv3 here: <a href="http://www.fftw.org/download.html" class="bare">http://www.fftw.org/download.html</a>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_requirements_for_lsdrastermodel">Requirements for LSDRasterModel</h5>
<div class="paragraph">
<p>Embedded within LSDTopoTools is a <a href="https://en.wikipedia.org/wiki/Landscape_evolution_model">landscape evolution model</a>.
The model requires the <a href="http://www.fftw.org/">Fast Fourier Transform Library</a> (see above).</p>
</div>
<div class="paragraph">
<p>In addition it requires some numerical libraries:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="http://www.boost.org/">Boost</a>, a popular c++ library.</p>
</li>
<li>
<p><a href="http://www.simunova.com/node/145">MTL</a> is a library for working with sparse matrices, which are required for solving some of the equations in the landscape evolution model.
You will need MTL 4. You don&#8217;t have to install anything for this, but <code>Boost</code> needs to be installed and this library goes in the <code>boost/numeric/mtl</code> subdirectory.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_requirements_for_swaths_and_point_clouds">Requirements for swaths and point clouds</h5>
<div class="paragraph">
<p>Okay, now things get a little more complicated because you want to use the Swath Profile tools or the LSDCloudBase object (which handles point clouds).
These objects are dependent on a set of libraries used for analyzing point cloud data,
namely:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The <code>cmake</code> utility. This is like <code>make</code> but is required for our tools that examine point clouds,
since it is required by something called the <a href="http://pointclouds.org/">point cloud library</a>.</p>
</li>
<li>
<p><a href="http://pointclouds.org/">pcl</a>: The Point Cloud Library.</p>
</li>
<li>
<p><a href="http://www.liblas.org/">libLAS</a>: a library for working with LAS format data.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Unfortunately these are a bit time consuming to install, because they depend on all sorts of other bits of software that must be installed first.
You should see the <a href="#_the_swath_and_point_cloud_tools">appendeces</a> for details on how to install this software.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gdal">2.1.3. GDAL</h4>
<div class="paragraph">
<p>The <a href="http://www.gdal.org/">Geospatial Data Abstraction Library</a> has fantastic tools for preparing your data.
It performs operations like clipping data, patching data together, resampling data, reprojecting data and doing coordinate transformations.
If you don&#8217;t know what those things are, don&#8217;t worry, we explain these things in the <a href="#_preliminary_steps">preliminary steps chapter</a>.</p>
</div>
<div class="paragraph">
<p>You can install all of GDAL if you want, but really you will only need their <a href="http://www.gdal.org/gdal_utilities.html">utilities</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_python">2.1.4. Python</h4>
<div class="paragraph">
<p>Python is a programming language used by many scientists to visualize data and crunch numbers.
We use it for visualization, and also for automating a number of tasks associated with topographic analysis.</p>
</div>
<div class="paragraph">
<p>You will need:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The <a href="https://www.python.org/">python programming language</a></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><a href="http://www.scipy.org/">Scipy</a>, for scientific python. It includes lots of useful packages like</p>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p><a href="http://www.numpy.org/">Numpy</a> for fast numerics.</p>
</li>
<li>
<p><a href="http://matplotlib.org/">Matplotlib</a> for plotting.</p>
</li>
<li>
<p><a href="http://pandas.pydata.org/">Pandas</a> for data analysis.</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>In addition, some of our python tools require GDAL, so you will have to install GDAL for these to work.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_nonessential_software">2.2. Nonessential software</h3>
<div class="paragraph">
<p>There are a number of software packages that are not required to run LSDTopoTools, but that you might find useful.</p>
</div>
<div class="paragraph">
<p>First, many people use geographic information software (GIS) to visualize data.
If you work at a university or a private company, you might have a license to <a href="https://www.arcgis.com/features/">ArcGIS</a>,
a popular commercial GIS.
However, if you are not part of a large institution or your institutional license does not allow home use, it can be convenient to have an open source alternative.
In addition, if you want to edit our documentation or make your own fork for notes,
you might consider using the same tools we do, which require the Ruby programming language.</p>
</div>
<div class="sect3">
<h4 id="_an_open_source_gis_qgis">2.2.1. An open source GIS: QGIS</h4>
<div class="paragraph">
<p>The industry standard GIS is <a href="http://www.esri.com/software/arcgis">ArcGIS</a>, and if you are at a university you might have a site license for this software.
It is not so easy to get on a personal computer, however, so there are a number of open source options that can be used as an alternative.</p>
</div>
<div class="paragraph">
<p>One alternative, and the one that will be used in these tutorials, is <a href="http://www.qgis.org/en/site/">QGIS</a>.</p>
</div>
<div class="paragraph">
<p>If you are familiar with ArcMap, you should be able to become proficient at QGIS in a few days. In my experience,
it also has the advantage of being more stable (i.e., it crashes less) than ArcMap.</p>
</div>
<div class="paragraph">
<p>One thing that is quite nice about QGIS is the number of plugins that are available.</p>
</div>
<div class="paragraph">
<p>You should download and install QGIS from their website, and click on the `Plugins tab to get some plugins.
the <code>OpenLayers</code> plugin, which allows you to quickly load
satellite and map information from all sorts of vendors.</p>
</div>
</div>
<div class="sect3">
<h4 id="_documentation_using_asciidoctor">2.2.2. Documentation using asciidoctor</h4>
<div class="paragraph">
<p>This book, and various other notes and websites associated with the LSDTopoTools project,
have been built using something called <a href="http://asciidoctor.org/docs/user-manual/">asciidoctor</a>.
Asciidoctor is used to produce cross-linked documents and documentation,
and has been designed to simplify the tool chain that takes one from writing technical documentation to producing a book rather simple.
You can read about its rationale here: <a href="http://asciidoctor.org/docs/what-is-asciidoc/" class="bare">http://asciidoctor.org/docs/what-is-asciidoc/</a>.
The software has worked well for us.</p>
</div>
<div class="paragraph">
<p>If you want to get asciidoctor working, you will need to get some packages working in <a href="https://www.ruby-lang.org/en/">Ruby</a>.
The instructions can be found in the appendices.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">2.3. Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</h3>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick Instructions for using Vagrant for LSDTopoTools</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Download and install <a href="https://www.virtualbox.org/">virtualbox</a>.</p>
</li>
<li>
<p>Download and install <a href="https://www.virtualbox.org/">vagrant</a>. You might have to restart your computer after this.</p>
</li>
<li>
<p>If you are on Windows, download <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html">putty.exe</a>.</p>
</li>
<li>
<p>Make a folder for your vagrant box and download one of our vagrantfiles: <a href="https://github.com/LSDtopotools/LSDTT_vagrantfiles" class="bare">https://github.com/LSDtopotools/LSDTT_vagrantfiles</a></p>
</li>
<li>
<p>One directory level down from the directory for your vagrantfile, make a directory <code>LSDTopoTools</code>.</p>
</li>
<li>
<p>Rename the vagrantfile from the repo (either <code>Vagrantfile_32bit</code> or <code>Vagrantfile_64bit</code>) simply <code>vagrantfile</code>.</p>
</li>
<li>
<p>Open a terminal or powershell window and navigate to the directory with the vagrantfile.</p>
</li>
<li>
<p>Run <code>vagrant up</code> from the command line.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
If you are running <code>vagrant up</code> for the first time it can take some time to download the <a href="https://www.vagrantup.com/docs/getting-started/boxes.html">base box</a>. They are several hundred Mb each!
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Run <code>vagrant provision</code> after the box has started.</p>
</li>
<li>
<p>You should now be able to use <code>putty.exe</code> to ssh into your LSDTopoTools server. The host name is almost always <code>127.0.0.1</code> and the port is almost always <code>2222</code>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="paragraph">
<p>There are a number of ways to get LSDTopoTools working on your computer, of varying difficulty.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Get LSDTopoTools working natively in Windows. This is possible, but very painful.</p>
</li>
<li>
<p>Get it working in a full Linux operating system via virtual machine software, such as <a href="https://www.virtualbox.org/">virtualbox</a>. Note that you can do this in Windows, Linux or Apple operating systems.</p>
</li>
<li>
<p>Get it working on a locally hosted Linux server using <a href="https://www.virtualbox.org/">virtualbox</a> and <a href="https://www.vagrantup.com/">vagrant</a>. Again, you can do this on any common operating system.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Be afraid of option #1. Be very afraid. Option #2 is reliable (you can see how to do it in the appendix) but it means you will need to install all the necessary software yourself, which can take several hours.
Option #3, involving Vagrant, is a bit more automated. It will still take some time the first time you boot your vagrant virtual machine, since a bunch of software will be installed, but we do automate this process for you.</p>
</div>
<div class="sect3">
<h4 id="_first_steps_starting_a_vagrant_box">2.3.1. First steps: Starting a Vagrant box</h4>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You will need sufficient space on your hard disk to host a guest operating system. You also need room for the LSDTopoTools dependencies. You will struggle if you have less than <strong>10Gb</strong> free.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><a href="https://www.vagrantup.com/">Vagrant</a> is software that automates the creation and provisioning of virtual machines. What does that mean? It means that you will create a Linux server that runs inside of your day-to-day computer. This server will run even if you are using a different operating system (e.g., Windows). Vagrant machines can be configured using a vagrantfile, so you download our vagrantfile and you simply point vagrant to it and should get a working server that can run LSDTopoTools.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You need software for running virtual machines. We recommend <a href="https://www.virtualbox.org/">virtualbox</a> since it is both well supported and free. Download and install. Our instructions assume you are using virtual box.</p>
</li>
<li>
<p>Download and install <a href="https://www.vagrantup.com/">Vagrant</a>.</p>
</li>
<li>
<p>Vagrant works via command line, so you will need to know how to open a terminal on <a href="http://www.macworld.co.uk/feature/mac-software/get-more-out-of-os-x-terminal-3608274/">OS X</a>, Linux (usually you can open one using <code>ctrl-alt-T</code>, but if you use Linux that means you were born knowing how to open a terminal), or a <a href="http://www.tenforums.com/tutorials/25581-windows-powershell-open-windows-10-a.html">Windows powershell</a>.</p>
</li>
<li>
<p>If you are working on Windows, you will probably have to restart after installing Vagrant so that Windows can register the path to Vagrant.</p>
</li>
<li>
<p>Okay, we now assume you have installed everything and are in a terminal or powershell. You need to make a directory where you keep information about your vagrant boxes. I made a folder names <code>vagrantboxes</code> and then subfolders for different boxes.</p>
</li>
<li>
<p>If you are in Windows, you will need an <a href="https://en.wikipedia.org/wiki/Secure_Shell">ssh</a> utility to communicate with your vagrant box. You should download <code>putty.exe</code> from the <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html">putty website</a>. In  Linux and OSX ssh utilities are already installed.</p>
</li>
<li>
<p>Now you should fetch one of our vagrantfiles from our git repo: <a href="https://github.com/LSDtopotools/LSDTT_vagrantfiles" class="bare">https://github.com/LSDtopotools/LSDTT_vagrantfiles</a></p>
<div class="sidebarblock">
<div class="content">
<div class="title">Get the Vagrant Files</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The 32 bit file is here: <a href="https://raw.githubusercontent.com/LSDtopotools/LSDTT_vagrantfiles/master/Vagrantfile_32bit" class="bare">https://raw.githubusercontent.com/LSDtopotools/LSDTT_vagrantfiles/master/Vagrantfile_32bit</a></p>
</li>
<li>
<p>The 64 bit file is here: <a href="https://raw.githubusercontent.com/LSDtopotools/LSDTT_vagrantfiles/master/Vagrantfile_64bit" class="bare">https://raw.githubusercontent.com/LSDtopotools/LSDTT_vagrantfiles/master/Vagrantfile_64bit</a></p>
</li>
<li>
<p>Save one of these files into the directory for your vagrant files. See below for the appropriate directory structure.</p>
</li>
</ol>
</div>
</div>
</div>
</li>
<li>
<p>Rename the vagrantfile from the repo (either <code>Vagrantfile_32bit</code> or <code>Vagrantfile_64bit</code>) simply <code>vagrantfile</code></p>
</li>
<li>
<p>If you use our vagrant files, you will need to make a directory <code>LSDTopoTools</code> in the same directory as your folders for different vagrant boxes.
For example, you might make a directory <code>C:\vagrantboxes\</code>, and in that directory you can put both <code>LSDTopoTools</code> and <code>Ubuntu32</code> (or some such name) directories. You will put the vagrant file in the <code>Ubuntu32</code> directory.
Your tree might look a bit like this:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-directory_struct" data-lang="directory_struct">C:\vagrantboxes\
|--Ubuntu32
   |-- vagrantfile
|--Ubuntu64
   |-- vagrantfile
|--LSDTopoTools</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
It is <strong>ESSENTIAL</strong> that the LSDTopoTools folder is present and is one directory level lower than the vagrant file. If this is not true, the vagrant machine will <strong>NOT WORK</strong>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In the above file structures the vagrantfiles have been renamed from the vagrant files in our repository.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Go into the folder with the operating system you want (e.g. <code>Ubuntu32</code>):</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS: &gt; cd C:\vagrantboxes
PS: &gt; cd C:\Ubuntu32</code></pre>
</div>
</div>
</li>
<li>
<p>Now start your vagrant box (this might take some time since it has to fetch stuff from the internet):</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS: &gt; vagrant up</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You do not need to download a "base box" (that is a Linux operating system, in this case 32 bit Ubuntu) before you run <code>vagrant up</code>: Vagrant does this for you.
However if you are running <code>vagrant up</code> for the first time Vagrant will download the box for you which will take some time (it is ~400Mb).
You will only need to download the base box once.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Congratulations! You now have a functioning Vagrant box!! Now you need to log on to the box.</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you want to update the base box you can use <code>vagrant box update</code> command from the powershell or terminal windows.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_logging_on_to_your_vagrant_box">2.3.2. Logging on to your Vagrant box</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>All right! Your Vagrant box is running. Other than a sense of vague accomplishment, this doesn&#8217;t really help you run LSDTopoTools. You need to log on to the box.
You will operate your vagrant box as a server: you log into the machine and run code on it, but you won&#8217;t have pretty windows to look at.
You will run everything through an ssh terminal, using a command line interface.</p>
</li>
<li>
<p>We do this using <a href="https://en.wikipedia.org/wiki/Secure_Shell">ssh</a>.</p>
<div class="sidebarblock">
<div class="content">
<div class="title">A note on your vagrant ssh server</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://en.wikipedia.org/wiki/Secure_Shell">ssh</a> allows you to communicate securely with a server on an unsecured connection (it encrypts communication between you and the server).</p>
</li>
<li>
<p>You will use ssh to communicate with your Vagrant server. This server is <strong>not on the internet</strong> but rather is living <strong>on your computer</strong>.</p>
</li>
<li>
<p>Vagrant is clever in that it sets up an <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> for your vagrant server (in other words your Linux machine living on your host computer, which could be Windows, Liunux or OSX), and as such ssh can establish a connection to this machine via ssh.</p>
</li>
<li>
<p>Vagrant&#8217;s default settings are to set your server up to sit on host <strong>127.0.0.1</strong> and port <strong>2222</strong>. You will need to use these settings in putty.exe</p>
</li>
<li>
<p>When you first log in, putty or other ssh clients will ask you to cache a new host key.</p>
</li>
</ul>
</div>
</div>
</div>
</li>
<li>
<p>If you are starting from a Linux or OSX machine, an ssh client is built into your command prompt and you can just type <code>vagrant ssh</code> into the command prompt.</p>
</li>
<li>
<p>If you are on Windows, you need to download [<a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html" class="bare">http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html</a>]putty.exe and run it.</p>
</li>
<li>
<p>In putty, set the host to <strong>127.0.0.1</strong> and the port to <strong>2222</strong>. These are vagrant&#8217;s default settings.</p>
</li>
<li>
<p>You will need to add the RSA key to your cache (just say yes: remember you are not connecting to the internet where baddies can spy on you but rather a server running on your own computer).</p>
</li>
<li>
<p>Now you need to <strong>log in</strong>. Your vagrant box has a <strong>username</strong> of <strong>vagrant</strong> and a password of <strong>vagrant</strong>.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_your_vagrant_box_and_file_synching">2.3.3. Your Vagrant box and file synching</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>So you are logged in. Now what? It turns out Vagrant has done some clever things with your files.</p>
</li>
<li>
<p>Vagrant can <a href="https://www.vagrantup.com/docs/getting-started/synced_folders.html">synch folders</a> across your Vagrant box and your host computer (that is, the computer you started vagrant from).</p>
</li>
<li>
<p>When you log in to your vagrant box, you will not be in the same folder where I have built the <strong>LSDTopoTools</strong> file structures. You need to navigate down to this:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/STUFF
$ cd ..
$ cd ..
$ pwd
/STUFF
$ cd LSDTopoTools
$ ls
STUFF</code></pre>
</div>
</div>
</li>
<li>
<p>As you can see above, the LSDTopoTools folder contains folders for different LSDTopoTools packages, for topographic datasets, and for something called FFTW,
which is a package used by LSDTopoTools for spectral analysis.</p>
</li>
<li>
<p>Here is the amazing thing: the files that are in LSDTopoTools folder in your vagrant box <strong>ARE ALSO</strong> visible, and synched, in your howst computer.
So if you use LSDTopoTools to do some analysis within your vagrant box, you will be able to see the files within your host computer as well.
This means that you can, for example, do a Linux based LSDTopoTools analysis and than plot that analysis in a GIS on your host windows box without having to transfer files.
Not only that, but you can modify the code, update python scripts, change parameter files, etc., with your favourite text editor in Windows (or OSX, or whatever) and those files will be visible to your Vagrant box. Fantastic!</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_shutting_things_down">2.3.4. Shutting things down</h4>
<div class="paragraph">
<p>When you are finished with your session, you just need to go into the powershell or a terminal and type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS: &gt; vagrant halt</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_brief_notes_for_setting_up_your_own_vagrant_server">2.3.5. Brief notes for setting up your own Vagrant server</h4>
<div class="paragraph">
<p>We have written Vagrant files for you so you don&#8217;t have to do any of this, but if you want to set up your own Vagrant boxes with your own software here are some notes.</p>
</div>
<div class="sect4">
<h5 id="_initiating_a_vagrant_box">Initiating a Vagrant box</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Go into an empty folder to start a new Vagrant box.</p>
</li>
<li>
<p>Initiate Vagrant with:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; C:\&gt; vagrant init</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively you can initiate with a <code>base box</code>. In this example we use the Ubuntu precise 32 base box:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; C:\vagrant init ubuntu/precise32</code></pre>
</div>
</div>
</li>
<li>
<p>This command (<code>init</code>) will simply make a vagrant file. To get the server up and running you need to <code>up</code> it. Before you do that you probably want to modify the vagrant file.</p>
</li>
<li>
<p>One of the things you probably need to modify is the memory assigned to your guest vagrant box. In the vagrant file you should have:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-vagrantfile" data-lang="vagrantfile">  config.vm.provider "virtualbox" do |vb|
    # Customize the amount of memory on the VM:
    vb.memory = "3000"
  end</code></pre>
</div>
</div>
<div class="paragraph">
<p>The default memory is something small, and the problem with it is that it will take the guest operating system too long to boot, and vagrant will time out. I would give the vagrant box 3-4 Gb of memory.</p>
</div>
</li>
<li>
<p>Now you can <code>up</code> your vagrant box. In the folder with the vagrant file, type:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; vagrant up</code></pre>
</div>
</div>
</li>
<li>
<p>If this is the first time booting the linux machine, this will take a while.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_notes_on_the_base_box">Notes on the base box</h5>
<div class="paragraph">
<p>Vagrant sets up a linux server Living in your computer (it is called the <strong>Host</strong> computer). The server will run a linux operating system, and you need to choose a functioning base system
<a href="https://atlas.hashicorp.com/boxes/search">vagrant base boxes</a>. Here we have started with <code>ubuntu/precise32</code>. You might want to try other base boxes, they can be found at the <a href="https://atlas.hashicorp.com/boxes/search">atlas website</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you choose a base box that you do not already have (and you start with none), vagrant will download it. They are big!! Usually over 500Mb (each is a fully operational linux operating system). You will either need a fast internet connection or a lot of time. Make sure you also have enough room on your hard disk.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><strong>You do need to be careful with base boxes!</strong></p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Not all base boxes work! On many windows machines, you can only run a 32 bit version of linux, even though you are almost certainly running 64 bit windows. You can change this by going into your BIOS and changing the settings, but that is dangerous and if you do not know what your BIOS is do not even think about attempting to change these settings.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In testing, I found many bases boxes did not work at all. The one that worked well for me was the <code>ubuntu/precise32</code> box. You can get this started with:</p>
</div>
<div class="paragraph">
<p>Alternatively you can just <code>vagrant init</code> and empty vagrant instance and change the box in the vagrantfile with <code>config.vm.box = "ubuntu/precise32"</code>.</p>
</div>
<div class="paragraph">
<p>You can update your base box with the command <code>vagrant box update</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_details_of_provisioning">Details of provisioning</h5>
<div class="paragraph">
<p>If you change your vagrantfile with the box still running, you can run the new provisioning with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; vagrant provision</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you have downloaded our vagrant files, the provisioning of your virtual server should be automatic. However, you may wish to know what is happening during the provisioning, so here are some notes.</p>
</div>
<div class="paragraph">
<p>To install software, we use the shell provisioning system of vagrant. This should go into the vagrantfile and will look a bit like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-vagrantfile" data-lang="vagrantfile">  config.vm.provision "shell", inline: &lt;&lt;-SHELL
    sudo apt-get update
    sudo apt-get install -y git
  SHELL</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above shell command, we are installing git. The <code>-y</code> flag is important since apt-get will ask if you actually want to download the software and if you do not tell it <code>-y</code> from the shell script it will just abort the installation.</p>
</div>
<div class="paragraph">
<p>You sync folders like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-vagrantfile" data-lang="vagrantfile">  config.vm.synced_folder "../LSDTopoTools", "/LSDTopoTools"</code></pre>
</div>
</div>
<div class="paragraph">
<p>Were the first folder is the folder on the host machine and the second is the folder on the Vagrant box.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_getting_python_running">2.4. Getting python running</h3>
<div class="paragraph">
<p>A number of our extensions and visualisation scripts are written in <a href="https://www.python.org/">Python</a>.
To get these working you need to install various packages in <a href="https://www.python.org/">Python</a>.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If you are using <a href="https://www.vagrantup.com/">Vagrant</a> to set up LSDTopoTools in a Virtual Machine within Windows, we recommend installing Python using <a href="http://conda.pydata.org/miniconda.html">Miniconda</a> in your Windows machine, rather than installing within your Virtual Linux box.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_getting_python_running_on_linux_and_this_should_also_work_for_osx">2.4.1. Getting python running on Linux (and this should also work for OSX)</h4>
<div class="paragraph">
<p>It is quite straightforward to install these on a Linux or OSX system:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get install python2.7
$ sudo apt-get install python-pip</code></pre>
</div>
</div>
<div class="paragraph">
<p>or</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ yum install python2.7
$ yum install python-pip</code></pre>
</div>
</div>
<div class="paragraph">
<p>In OSX, you need a package manager such as <a href="http://brew.sh/">Homebrew</a>, and you can follow similar steps.</p>
</div>
<div class="paragraph">
<p>After that, you need:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://www.scipy.org/">Scipy</a> for numerics.</p>
</li>
<li>
<p><a href="http://www.numpy.org/">Numpy</a> for numerics.</p>
</li>
<li>
<p><a href="http://matplotlib.org/">Matplotlib</a> for visualisation.</p>
</li>
<li>
<p><a href="http://pandas.pydata.org/">Pandas</a> for working with data.</p>
</li>
<li>
<p><a href="https://pypi.python.org/pypi/GDAL/">GDAL python tools</a> for working with geographic data.</p>
</li>
<li>
<p><a href="https://pythonhosted.org/spyder/">Spyder</a> for having a working environment. This last one is not required but useful if you are used to Matlab.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>You can get all this with a combination of <code>pip</code> and <code>sudo</code>, <code>yum</code> or <code>homebrew</code>, depending on your operating system.</p>
</div>
<div class="paragraph">
<p>For example, with and [Ubuntu] system, you can use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get install python-numpy python-scipy python-matplotlib python-pandas
$ sudo apt-get install spyder</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <a href="http://www.gdal.org/index.html">GDAL</a> python tools are a bit harder to install; see here: <a href="https://pypi.python.org/pypi/GDAL/" class="bare">https://pypi.python.org/pypi/GDAL/</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_installing_python_on_windows">2.4.2. Installing python on Windows</h4>
<div class="paragraph">
<p>In Windows, there are more options. One way to get <a href="https://www.python.org/">Python</a> set up is to use <a href="http://python-xy.github.io/">Python(x,y)</a>.
The problem with <a href="http://python-xy.github.io/">Python(x,y)</a> is it installs everything that a scientists could ever conceivably use
(so this includes a vast amount of stuff you will never use) and in addition it is not so easy to update. It does offer update packages but these have dependencies that often lead to a dead-end, so that you have to uninstall and reinstall everything to get back on the update track.</p>
</div>
<div class="paragraph">
<p><a href="http://conda.pydata.org/docs/index.html">Conda</a> is a simple installation environment that can work on your Windows machine and we find them easier to update than <a href="http://python-xy.github.io/">Python(x,y)</a>. If you want to install everything all at once (much like in Pythn(x,y), you should go for <a href="https://www.continuum.io/downloads">Anaconda</a>.</p>
</div>
<div class="paragraph">
<p>However, we have used <a href="http://conda.pydata.org/miniconda.html">Miniconda</a> since we don&#8217;t need every scientific extension to python.</p>
</div>
</div>
<div class="sect3">
<h4 id="_using_miniconda_to_install_the_relevant_python_packages_in_windows">2.4.3. Using Miniconda to install the relevant python packages in Windows</h4>
<div class="paragraph">
<p>If you have a Windows machine, the recommended setup is first follow the instructions for <a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a> and then set up python using <a href="http://conda.pydata.org/miniconda.html">Miniconda</a>. Miniconda is a package</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Download and install <a href="http://conda.pydata.org/miniconda.html">Miniconda</a>.</p>
</li>
<li>
<p>Open a <a href="https://en.wikipedia.org/wiki/Windows_PowerShell">powershell window</a>.</p>
</li>
<li>
<p>Install scipy, pandas, matplotlib and :</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS C:\ conda install scipy
PS C:\ conda install matplotlib
PS C:\ conda install pandas
PS C:\ conda install gdal
PS C:\ conda install spyder</code></pre>
</div>
</div>
</li>
<li>
<p>After ech of these you will need to say "yes" to the packages, and then wait a while as things download and install.</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Installing the above packages will install a bunch of dependent packages that you can use as well, such as Sphinx and iPython.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Congratulations! You should now have everything you need for LSDTopoTools visualisation and automation on you Windows computer!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary">2.5. Summary</h3>
<div class="paragraph">
<p>This chapter has given an overview of what software is necessary to use LSDTopoTools.
The appendices contain information about installing this software on both
<a href="#_setting_up_on_windows">Windows</a> and <a href="#_setting_up_on_linux">Linux</a> operating systems, but these are only for stubborn people who like to do everything by hand.
If you want to just get things working, use our <a href="https://www.vagrantup.com/">Vagrant</a> files.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_preliminary_steps">3. Preliminary steps</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this section we go over some of the steps required before you use the LSDTopoTools software package.
The most basic step is to get some topographic data!
Topographic data comes in a number of formats, so it is often necessary to manipulate the data a bit to get it into a form LSDTopoTools will understand.
The main ways in which you will need to manipulate the data are changing the projection of the data and changing its format.
We explain raster formats and projections first, and then move on to the tool that is best suited for projecting and transforming rasters: <a href="http://www.gdal.org/">GDAL</a>.
Finally we describe some tools that you can use to lave a look at your raster data before you send it to LSDTopoTools.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick Instructions for preliminary data processing</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Get some data.</p>
</li>
<li>
<p>Use GDAL to see if the data is in a <strong>projected coordinate system</strong>.</p>
</li>
<li>
<p>If the data is not in a <strong>projected coordinate system</strong>, use GDAL to make it so.</p>
</li>
<li>
<p>Convert the data to a format that LSDTopoTools can read: the preferred format is the <strong>ENVI .bil</strong> format.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_the_terminal_and_powershells">3.1. The terminal and powershells</h3>
<div class="paragraph">
<p>Our software works primarily through a terminal (in Linux) or poweshell (in Windows) window.
We don&#8217;t have installation notes for OSX but if you manage to get it working there you will also use a terminal window.
A terminal or powershell window is an interface through which you can issue text-based commands to your computer.</p>
</div>
<div class="paragraph">
<p>In Windows, you can get powershell by searching for programs. If you are on Windows 8 (why are you on Windows 8??), use the internet to figure out how to get a powershell open.</p>
</div>
<div class="paragraph">
<p>Different flavors of Linux have different methods in which to open a terminal,
but if you are using Ubuntu you can type <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>T</kbd> or you can find it in the application menu.</p>
</div>
<div class="paragraph">
<p>On other flavors of Linux (for example, those using a Gnome or KDE desktop) you can often get the terminal window by right-clicking anywhere on the desktop and selecting <code>terminal</code> option.
In KDE a terminal is also called a "Konsole".</p>
</div>
<div class="paragraph">
<p>Once you have opened a terminal window you will see a command prompt. In linux the command prompt will look a bit like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">user@server $</code></pre>
</div>
</div>
<div class="paragraph">
<p>or just:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$</code></pre>
</div>
</div>
<div class="paragraph">
<p>whereas the powershell will look a bit like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS C:\Home &gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once you start working with our tools you will quickly be able to open a terminal window (or powershell) in your sleep.</p>
</div>
</div>
<div class="sect2">
<h3 id="_topographic_data">3.2. Topographic data</h3>
<div class="paragraph">
<p>Topographic data comes in a number of formats, but at a basic level most topographic data is in the form of a <a href="https://en.wikipedia.org/wiki/Raster_graphics"><strong>raster</strong></a>.
A raster is just a grid of data, where each cell in the grid has some value (or values).
The cells are sometimes also called pixels. With image data, each pixel in the raster might have several values, such as the value of red, green and blue hues.
Image data thus has <strong>bands</strong>: each band is the information pertaining to the different colors.</p>
</div>
<div class="paragraph">
<p>Topographic data, on the other hand, is almost always <strong>single band</strong>: each pixel or cell only has one data value: the elevation.
Derivative topographic data, such a slope or aspect, also tends to be in single band rasters.</p>
</div>
<div class="paragraph">
<p>It is possible to get topographic data that is not in raster format (that is, the data is not based on a grid).
Occasionally you find topographic data built on unstructured grids, or point clouds, where each elevation data point has a location in space associated with it.
This data format takes up more space than raster data,
since on a aster you only need to supply the elevation data:
the horizontal positions are determined by where the data sits in the grid.
Frequently <a href="https://en.wikipedia.org/wiki/Lidar">LiDAR</a> data
(LiDAR stands for Light Detection and Ranging, and is a method for obtaining very high resolution topographic data)
is delivered as a point cloud and you need software to convert the point cloud to a raster.</p>
</div>
<div class="paragraph">
<p>For most of this book, we will assume that your data is in raster format.</p>
</div>
</div>
<div class="sect2">
<h3 id="_data_sources">3.3. Data sources</h3>
<div class="paragraph">
<p>Before you can start analyzing topography and working with topographic data,
you will need to get data and then get it into the correct format.
This page explains how to do so.</p>
</div>
<div class="sect3">
<h4 id="_what_data_does_lsdtopotoolbox_take">3.3.1. What data does LSDTopoToolbox take?</h4>
<div class="paragraph">
<p>The LSDTopoToolbox works predominantly with raster data;
if you don&#8217;t know what that is you can read about it here:  <a href="http://en.wikipedia.org/wiki/Raster_data" class="bare">http://en.wikipedia.org/wiki/Raster_data</a>.
In most cases, the raster data you will start with is a digital elevation model (DEM).
Digital elevation models (and rasters in general) come in all sorts of formats. LSDTopoToolbox works with three formats:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 2. File input and output options</caption>
<colgroup>
<col style="width: 16%;">
<col style="width: 16%;">
<col style="width: 66%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Data type</th>
<th class="tableblock halign-left valign-top">file extension</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://docs.codehaus.org/display/GEOTOOLS/ArcInfo+ASCII+Grid+format#ASCIIGrid">Ascii</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>.asc</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This format is in plain text and can be read by a text editor.
The advantage of this format is that you can easily look at the data,
but the disadvantage is that the file size is extremely large (compared to the other formats, .flt).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>.flt</code> with a header file with extension <code>.hdr</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is a binary file format meaning that you can&#8217;t use a text editor to look at the data.
The file size is greatly reduced compared to <code>.asc</code> data, however. This format does not retain georeferencing information.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://www.exelisvis.com/docs/ENVIImageFiles.html">ENVI bil format</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>.bil</code> with a header file with extension <code>.hdr</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><strong>This is the recommended format</strong>, because it works best with GDAL (see  the section <a href="#_gdal">GDAL</a>),
and because it retains georeferencing information.</p></td>
</tr>
</tbody>
</table>
<div class="sidebarblock">
<div class="content">
<div class="title">Why don&#8217;t we use GeoTiff?</div>
<div class="paragraph">
<p><a href="https://trac.osgeo.org/geotiff/">GeoTIFF</a> is a widely used raster format that has the advantage of containing georeferencing and the raster data in a single file.
The disadvantage is that for C++ code you need to have two libraries (<code>libtiff</code> and <code>libgeotiff</code>) installed before you can read GeoTIFF files.
Because there are many open source, easily installed tools for converting GeoTIFF files
(for example, the <a href="http://www.gdal.org/gdal_utilities.html">GDAL utilities</a> and the <a href="https://pypi.python.org/pypi/GDAL/">python GDAL bindings</a>)
we have opted for portability and not included the GeoTIFF libraries in our software. If you have GeoTIFF files, you
will need to convert them to a supported format before using LSDTopoTools.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Below you will find instructions on how to get data into the correct format:
data is delivered in a wide array of formats (e.g., ESRI bil, DEM, GeoTiff)
and you must convert this data before it can be used by LSDTopoTools.</p>
</div>
</div>
<div class="sect3">
<h4 id="_downloading_data">3.3.2. Downloading data</h4>
<div class="paragraph">
<p>If you want to analyze topography, you should get some topographic data!
The last decade has seen incredible gains in the availability and resolution of topographic data.
Today, you can get topographic data from a number of sources. The best way to find this data is through search engines,
but below are some common sources:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 3. Sources of topographic data</caption>
<colgroup>
<col style="width: 16%;">
<col style="width: 16%;">
<col style="width: 66%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Source</th>
<th class="tableblock halign-left valign-top">Data type</th>
<th class="tableblock halign-left valign-top">Description and link</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://www.opentopography.org/">opentopography</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lidar raster and point cloud data, funded by the National Science foundation. <a href="http://www.opentopography.org/" class="bare">http://www.opentopography.org/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://www.csc.noaa.gov/inventory/#"> U.S. Interagency Elevation Inventory</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR and IfSAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lidar raster and point cloud data, and IFSAR (5 m resolution or better), collated by NOAA. <a href="http://www.csc.noaa.gov/inventory/#" class="bare">http://www.csc.noaa.gov/inventory/#</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://viewer.nationalmap.gov/basic/">USGS national map viewer</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Various (including IfSAR and LiDAR, and satellite imagery)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">United States elevation data hosted by the United States Geological Survey. Mostly data from the United States. <a href="http://viewer.nationalmap.gov/basic/" class="bare">http://viewer.nationalmap.gov/basic/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://earthexplorer.usgs.gov/">EarthExplorer</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Various (including LiDAR, IfSAR, ASTER and SRTM data)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Another USGS data page. THis has more global coverage and is a good place to download SRTM 30 mdata. <a href="http://earthexplorer.usgs.gov/" class="bare">http://earthexplorer.usgs.gov/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://centrodedescargas.cnig.es/CentroDescargas/buscadorCatalogo.do?codFamilia=LIDAR">Spanish LiDAR</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This site has lidar data from Spain: <a href="http://centrodedescargas.cnig.es/CentroDescargas/buscadorCatalogo.do?codFamilia=LIDAR" class="bare">http://centrodedescargas.cnig.es/CentroDescargas/buscadorCatalogo.do?codFamilia=LIDAR</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="https://tiedostopalvelu.maanmittauslaitos.fi/tp/kartta?lang=en">Finland LiDAR</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Finland&#8217;s national LiDAR dataset: <a href="https://tiedostopalvelu.maanmittauslaitos.fi/tp/kartta?lang=en" class="bare">https://tiedostopalvelu.maanmittauslaitos.fi/tp/kartta?lang=en</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://download.kortforsyningen.dk/">Denmark LiDAR</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Denmark&#8217;s national LiDAR dataset: <a href="http://download.kortforsyningen.dk/" class="bare">http://download.kortforsyningen.dk/</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://www.geostore.com/environment-agency/WebStore?xml=environment-agency/xml/application.xml">Environment Agency (UK) LiDAR</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR holdings of the Environment Agency (UK): <a href="http://www.geostore.com/environment-agency/WebStore?xml=environment-agency/xml/application.xml" class="bare">http://www.geostore.com/environment-agency/WebStore?xml=environment-agency/xml/application.xml</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://www.territorio.provincia.tn.it/portal/server.pt/community/lidar/847/lidar/23954">Trentino (Italy) LiDAR</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">LiDAR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lidar from the Trentio, a province in the Italian Alps: <a href="http://www.lidar.provincia.tn.it:8081/WebGisIT/pages/webgis.faces" class="bare">http://www.lidar.provincia.tn.it:8081/WebGisIT/pages/webgis.faces</a></p></td>
</tr>
</tbody>
</table>
<div class="sidebarblock">
<div class="content">
<div class="title">Global datasets</div>
<div class="paragraph">
<p>There are several global topographic datasets. The oldest of these is <a href="https://lta.cr.usgs.gov/GTOPO30">gtopo30</a>,
which was completed in 1996 and contains ~1 km resolution global data.
This was followed by the <a href="https://en.wikipedia.org/wiki/Shuttle_Radar_Topography_Mission">Shuttle Radar Topography Mission (SRTM)</a>
that produced a 90 meter resolution DEM in 2003; followed by the
<a href="https://asterweb.jpl.nasa.gov/gdem.asp">Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER)</a>
30 meter resolution global DEM in 2009. In 2014
<a href="http://www.cgiar-csi.org/data/srtm-90m-digital-elevation-database-v4-1">SRTM released a global 30 meter dataset</a>.
2015 has seen the release of the <a href="http://www.geo-airbusds.com/worlddem/">WorldDEM</a>, a 12 meter resolution topographic dataset.</p>
</div>
<div class="paragraph">
<p>GTOPO30, SRTM and ASTER data are all freely available for download. The WorldDEM is a commercial product.
If you are looking for a global dataset at reasonable resolution that is not commercial, you will most likely choose between ASTER and SRTM.
You can download ASTER and SRTM data at the same site and make your own comparisons,
but ASTER has widely publicised <a href="http://www.digital-geography.com/dem-comparison-srtm-3-vs-aster-gdem-v2/#.ViS2wX6rRaQ">data quality issues</a>
so we recommend the SRTM 30 meter data.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_projections_and_transformations">3.4. Projections and transformations</h3>
<div class="paragraph">
<p>Many of our readers will be aware that our planet is well approximated as a sphere.
Most maps and computer screens, however, are flat. This causes some problems.</p>
</div>
<div class="paragraph">
<p>To locate oneself on the surface of the Earth, many navigational tools use a coordinate system based on a sphere,
first introduced by the "father or geography" <a href="https://en.wikipedia.org/wiki/Eratosthenes">Eratosthenes of Cyrene</a>.
Readers will be familiar with this system through latitude and longitude.</p>
</div>
<div class="paragraph">
<p>A coordinate system based on a sphere is called a <strong>geographic coordinate system</strong>.
For most of our topographic analysis routines,
a geographic coordinate system is a bit of a problem because the distance between
points is measured in angular units and these vary as a function of position on the surface of the planet.
For example, a degree of longitude is equal to 111.320 kilometers at the equator, but only 28.902 kilometers at a latitude of 75 degrees!
For our topographic analyses tools we prefer to measure distances in length rather than in angular units.</p>
</div>
<div class="paragraph">
<p>To convert locations on a the surface of a sphere to locations on a plane (e.g., a paper map or your computer screen),
a <a href="https://en.wikipedia.org/wiki/Map_projection">map projection</a> is required.
All of the LSDTopoTools analysis routines work on a <strong>projected coordinate system</strong>.</p>
</div>
<div class="paragraph">
<p>There are many projected coordinate systems out there, but we recommend the
<a href="https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">Universal Transverse Mercator (UTM)</a> system,
since it is a widely used projection system with units of meters.</p>
</div>
<div class="paragraph">
<p>So, before you do anything with topographic data you will need to:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Check to see if the data is in a <strong>projected coordinate system</strong></p>
</li>
<li>
<p>Convert any data in a <strong>geographic coordinate systems</strong> to a <strong>projected coordinate system</strong>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Both of these tasks can be done quickly an easily with <a href="http://www.gdal.org/">GDAL</a> software tools.</p>
</div>
</div>
<div class="sect2">
<h3 id="_gdal_2">3.5. GDAL</h3>
<div class="paragraph">
<p>Now that you know something about data formats, projections and transformations (since you read very carefully the preceding sections),
you are probably hoping that there is a simple tool with which you can manipulate your data. Good news: there is!
If you are reading this book you have almost certainly heard of GIS software,
which is inviting since many GIS software packages have a nice, friendly and shiny user interface that you can use to reassuringly click on buttons.
However, we do not recommend that you use GIS software to transform or project your data.
Instead we recommend you use <a href="http://www.gdal.org/">GDAL</a>.</p>
</div>
<div class="paragraph">
<p><a href="http://www.gdal.org/">GDAL (the Geospatial Data Abstraction Library)</a>
is a popular software package for manipulating geospatial data. GDAL
allows for manipulation of geospatial data in the Linux operating
system, and for most operations is much faster than GUI-based GIS
systems (e.g., ArcMap).</p>
</div>
<div class="paragraph">
<p>Here we give some notes on common operations in
GDAL that one might use when working with LSDTopoTools. Much of these
operations are carried out using GDAL&#8217;s utility programs, which can be downloaded from <a href="http://www.gdal.org/gdal_utilities.html" class="bare">http://www.gdal.org/gdal_utilities.html</a>.
The appendices have instructions on how to get the GDAL utilities working.
You will also have to be able to open a terminal or powershell.
Instructions on how to do this are in the appendices.</p>
</div>
<div class="sect3">
<h4 id="finding-out-what-sort-of-data-youve-got">3.5.1. Finding out what sort of data you&#8217;ve got</h4>
<div class="paragraph">
<p>One of the most frequent operations in GDAL is just to see what sort of
data you have. The tool for doing this is <code>gdalinfo</code> which is run with
the command line:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalinfo filename.ext</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>filename.ext</code> is the name of your raster.</p>
</div>
<div class="paragraph">
<p>This is used mostly to:</p>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>See what projection your raster is in.</p>
</li>
<li>
<p>Check the extent of the raster.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>This utility can read Arc formatted rasters but you need to navigate
into the folder of the raster and use the <code>.adf</code> file as the filename.
There are sometimes more than one <code>.adf</code> files so you&#8217;ll just need to
use <code>ls -l</code> to find the biggest one.</p>
</div>
</div>
<div class="sect3">
<h4 id="translating-your-raster-into-something-that-can-be-used-by-lsdtopotoolbox">3.5.2. Translating your raster into something that can be used by LSDTopoToolbox</h4>
<div class="paragraph">
<p>Say you have a raster but it is in the wrong format (LSDTopoToolbox at
the moment only takes <code>.bil</code>, <code>.flt</code> and <code>.asc</code> files) and in the wrong
projection.</p>
</div>
<div class="paragraph">
<p>Note: <strong>LDSTopoToolbox performs many of its analyses on the
basis of projected coordinates.</strong></p>
</div>
<div class="paragraph">
<p>You will need to be able to both change the projection of your rasters
and change the format of your raster. The two utilities for this are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.gdal.org/gdalwarp.html">gdalwarp</a></p>
</li>
<li>
<p><a href="http://www.gdal.org/gdal_translate.html">gdaltranslate</a></p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="changing-raster-projections-with-gdalwarp">Changing raster projections with gdalwarp</h5>
<div class="paragraph">
<p>The preferred coordinate system is WGS84 UTM coordinates. For convert to
this coordinate system you use <code>gdalwarp</code>. The coordinate system of the
source raster can be detected by gdal, so you use the flag <code>-t_srs</code> to
assign the target coordinate system. Details about the target coordinate
system are in quotes, you want:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">+proj=utm +zone=XX +datum=WGS84'</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>XX</code> is the UTM zone.
You can find a map of UTM zones here: <a href="http://www.dmap.co.uk/utmworld.htm" class="bare">http://www.dmap.co.uk/utmworld.htm</a>. For
example, if you want zone 44 (where the headwaters of the Ganges are),
you would use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">'+proj=utm +zone=XX +datum=WGS84'</code></pre>
</div>
</div>
<div class="paragraph">
<p>Put this together with a source and target filename:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -t_srs '+proj=utm +zone=XX +datum=WGS84' source.ext target.ext</code></pre>
</div>
</div>
<div class="paragraph">
<p>so one example would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -t_srs '+proj=utm +zone=44 +datum=WGS84' diff0715_0612_clip.tif diff0715_0612_clip_UTM44.tif</code></pre>
</div>
</div>
<div class="paragraph">
<p>note that if you are using UTM and you are in the southern hemisphere,
you should use the <code>+south</code> flag:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -t_srs '+proj=utm +zone=19 +south +datum=WGS84' 20131228_tsx_20131228_tdx.height.gc.tif Chile_small.tif</code></pre>
</div>
</div>
<div class="paragraph">
<p>There are several other flags that could be quite handy (for a complete
list see <a href="http://www.gdal.org/gdalwarp.html">the GDAL website</a>).</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>-of</code> <code>format</code>: This sets the format to the selected format. This
means you can skip the step of changing formats with <code>gdal_translate</code>.
We will repeat this later but the formats for <code>LSDTopoTools</code> are:</p>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 4. Format of outputs for GDAL</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Flag</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ASCGrid</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ASCII files. These files are huge so try not to use
them.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>EHdr</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ESRI float files. This used to be the only binary option
but GDAL seems to struggle with it and it doesn&#8217;t retain georeferencing.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ENVI</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ENVI rasters. <strong>This is the preferred format</strong>. GDAL deals
with these files well and they retain georeferencing. We use the
extension <code>bil</code> with these files.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>So, for example, you could output the file as:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">  $ gdalwarp -t_srs '+proj=utm +zone=44 +datum=WGS84' -of ENVI diff0715_0612_clip.tif diff0715_0612_clip_UTM44.bil</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or for the southern hemisphere:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">  $ gdalwarp -t_srs '+proj=utm +zone=19 +south +datum=WGS84' -of ENVI 20131228_tsx_20131228_tdx.height.gc.tif Chile_small.bil</code></pre>
</div>
</div>
</li>
<li>
<p><code>-tr</code> <code>xres yres</code>: This sets the x and y resolution of the output DEM.
It uses nearest neighbour resampling by default. So say you wanted to resample to 4 metres:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">  $ gdalwarp -t_srs '+proj=utm +zone=44 +datum=WGS84' -tr 4 4 diff0715_0612_clip.tif diff0715_0612_clip_UTM44_rs4.tif</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
LSDRasters assume square cells so you need both x any y
distances to be the same
</td>
</tr>
</table>
</div>
</li>
<li>
<p><code>-r</code> <code>resampling_method</code>: This allows you to select the resampling
method. The options are:</p>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 5. Resampling methods for GDAL</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Method</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>near</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nearest neighbour resampling (default, fastest algorithm,
worst interpolation quality).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>bilinear</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Bilinear resampling.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>cubic</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cubic resampling.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>cubicspline</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cubic spline resampling.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>lanczos</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Lanczos windowed sinc resampling.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>average</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Average resampling, computes the average of all non-NODATA
contributing pixels. (GDAL versions &gt;= 1.10.0).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>mode</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mode resampling, selects the value which appears most often
of all the sampled points. (GDAL versions &gt;= 1.10.0).</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>So for example you could do a cubic resampling with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -t_srs '+proj=utm +zone=44 +datum=WGS84' -tr 4 4 -r cubic
diff0715_0612_clip.tif diff0715_0612_clip_UTM44_rs4.tif</code></pre>
</div>
</div>
</li>
<li>
<p><code>-te</code> <code>&lt;x_min&gt; &lt;y_min&gt; &lt;x_max&gt; &lt;y_max&gt;</code>: this clips the raster. You
can see more about this below in under the header <a href="#clipping-rasters-with-gdal">Clipping rasters with gdal</a>.</p>
<div class="ulist">
<ul>
<li>
<p><strong>UTM South</strong>: If you are looking at maps in the southern hemisphere,
you need to use the <code>+south</code> flag:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -t_srs '+proj=utm +zone=44 +south +datum=WGS84' -of ENVI
diff0715_0612_clip.tif diff0715_0612_clip_UTM44.bil</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_changing_nodata_with_gdalwarp">Changing Nodata with gdalwarp</h5>
<div class="paragraph">
<p>Sometimes your source data has nodata values that are weird, like 3.08x10^36 or something.
You might want to change these values in your output DEM. You can do this with gdalwarp:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -of ENVI -dstnodata -9999 harring_dem1.tif Harring_DEM.bil</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above case I&#8217;ve just changed a DEM from a tif to an ENVI bil but used -9999 as the nodata value.</p>
</div>
</div>
<div class="sect4">
<h5 id="changing-raster-format-with-gdal_translate">Changing raster format with gdal_translate</h5>
<div class="paragraph">
<p>Suppose you have a raster in UTM coordinates
(zones can be found here: <a href="http://www.dmap.co.uk/utmworld.htm" class="bare">http://www.dmap.co.uk/utmworld.htm</a>) but
it is not in <code>.flt</code> format. You can change the format using
<code>gdal_translate</code> (note the underscore).</p>
</div>
<div class="paragraph">
<p><a href="http://www.gdal.org/gdal_translate.html">gdal_translate</a> recognizes
<a href="http://gdal.org/formats_list.html">many file formats</a>, but for
LSDTopoTools you want either:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The <strong>ESRI .hdr labelled</strong> format, which is denoted with <code>EHdr</code>.</p>
</li>
<li>
<p>The <strong>ENVI .hdr labelled</strong> format, which is denoted with <code>ENVI</code>.
ENVI files are preferred since they work better with GDAL and retain georeferencing.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>To set the file format you use the <code>-of</code> flag, an example would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdal_translate -of ENVI diff0715_0612_clip_UTM44.tif diff0715_0612_clip_UTM44.bil</code></pre>
</div>
</div>
<div class="paragraph">
<p>Where the first <code>filename.ext</code> is the source file and the second is the
output file.</p>
</div>
</div>
<div class="sect4">
<h5 id="_nodata_doesn_t_register">Nodata doesn&#8217;t register</h5>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
In older versions of GDAL, the NoDATA value doesn&#8217;t translate when you use <strong>gdalwarp</strong> and <strong>gdal_traslate</strong>.
If this happens to you, the simple solution is to go into the 'hdr' file and add the no data vale.
You will need to use <strong>gdalinfo</strong> to get the nodata value from the source raster, and then in the header of the destination raster,
add the line: <code>data ignore value = -9999</code> (or whatever the nodata value in the source code is).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you want to change the actual nodata value on an output DEM, you will need to use gdalwarp with the <code>-dstnodata</code> flag.</p>
</div>
</div>
<div class="sect4">
<h5 id="potential-filename-errors">Potential filename errors</h5>
<div class="paragraph">
<p>It appears that GDAL considers filenames to be case-insensitive, which
can cause data management problems in some cases. The following files
are both considered the same:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">Feather_DEM.bil feather_dem.bil</code></pre>
</div>
</div>
<div class="paragraph">
<p>This can result in an ESRI <code><strong>.hdr</code> file overwriting an ENVI <code></strong>.hdr</code> file
and causing the code to fail to load the data. To avoid this ensure that
input and output filenames from GDAL processes are unique.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="clipping-rasters-with-gdal">3.5.3. Clipping rasters with gdal</h4>
<div class="paragraph">
<p>You might also want to clip your raster to a smaller area. This can
sometimes take ages on GUI-based GISs. An alternative is to use
<code>gdalwarp</code> for clipping:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -te &lt;x_min&gt; &lt;y_min&gt; &lt;x_max&gt; &lt;y_max&gt; input.tif clipped_output.tif</code></pre>
</div>
</div>
<div class="paragraph">
<p>or you can change the output format:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">$ gdalwarp -te &lt;x_min&gt; &lt;y_min&gt; &lt;x_max&gt; &lt;y_max&gt; -of ENVI input.tif clipped_output.bil</code></pre>
</div>
</div>
<div class="paragraph">
<p>Since this is a <code>gdalwarp</code> operation, you can add all the bells and
whistles to this, such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>changing the coordinate system,</p>
</li>
<li>
<p>resampling the DEM,</p>
</li>
<li>
<p>changing the file format.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The main thing to note about the <code>-te</code> operation is that the clip will
be in the coordinates of the source raster (<code>input.tif</code>). You can look
at the extent of the raster using <code>gdalinfo</code>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_looking_at_your_data_before_you_do_anything_with_it">3.6. Looking at your data (before you do anything with it).</h3>
<div class="paragraph">
<p>You might want to have a look at your data before you do some number crunching.
To look at the data, there are a number of options.
The most common way of looking at topographic data is by using a Geographic Information System (or GIS).
The most popular commercial GIS is <a href="https://www.arcgis.com/features/">ArcGIS</a>.
Viable open source alternatives are [QGIS] is you want something similar to ArcGIS,
and <a href="http://www.uoguelph.ca/~hydrogeo/Whitebox/index.html">Whitebox</a> if you want something quite lightweight.</p>
</div>
<div class="sect3">
<h4 id="_our_lightweight_python_mapping_tools">3.6.1. Our lightweight python mapping tools</h4>
<div class="paragraph">
<p>If you would like something <strong>really</strong> lightweight, you can use our python mapping tools,
available here: <a href="https://github.com/LSDtopotools/LSDMappingTools" class="bare">https://github.com/LSDtopotools/LSDMappingTools</a>.
These have been designed for internal use for our group, so at this point they aren&#8217;t well documented.
However if you know a bit of python you should be able to get them running.
You will need python with <code>numpy</code> and <code>matplotlib</code>.</p>
</div>
<div class="paragraph">
<p>To look at a DEM,
you will need to download <code>LSDMappingTools.py</code> and <code>TestMappingTools.py</code> from the <a href="https://github.com/LSDtopotools/LSDMappingTools">Gitub repository</a>.
The latter program just gives some examples of usage.
At this point all the plotting functions do are plot the DEM and plot a hillshade,
but if you have python working properly you can plot something in a minute or two rather than having to set up a GIS.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_2">3.7. Summary</h3>
<div class="paragraph">
<p>You should now have some idea as to how to get your hands on some topographic data,
and how to use GDAL to transform it into something that LSDTopoTools can use.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_getting_lsdtopotools">4. Getting LSDTopoTools</h2>
<div class="sectionbody">
<div class="paragraph">
<p>There are several ways to get our tools, but before you start downloading code,
you should be aware of how the code is structured.
Much of this chapter covers the details about what you will find when you download the code and how to download it with git,
but if you just want to get started you can always skip to the <a href="#_where_to_get_the_code">final section</a>.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick Instructions for preliminary data processing</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Make sure you have a C++ compiler on your computer.</p>
</li>
<li>
<p>Use <code>git</code> to download one of the LSDTopoTools packages. You can find some of them here: <a href="https://github.com/LSDtopotools" class="bare">https://github.com/LSDtopotools</a>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_how_the_code_is_structured">4.1. How the code is structured</h3>
<div class="paragraph">
<p>Okay, if you are getting the LSDTopoTools for the first time, it will be useful to understand how the code is structured.
Knowing the structure of the code will help you compile it (that is, turn the source code into a program).
If you just want to grab the code, skip ahead to the section <a href="#_getting_the_code_using_git">Getting the code using Git</a>.
If, on the other hand, you want to know the intimate details of the code structured, see the appendix: <a href="#_code_structure">Code Structure</a>.</p>
</div>
<div class="sect3">
<h4 id="_compiling_the_code">4.1.1. Compiling the code</h4>
<div class="paragraph">
<p>The software is delivered as C++ source code. Before you can run any analyses,
you need to compile it, using something called a <a href="https://en.wikipedia.org/wiki/Compiler">compiler</a>.
You can think of a compiler as a translator, that translates the source code (which looks very vaguely like English)
into something your computer can understand, that is in the form of <a href="https://en.wikipedia.org/wiki/Assembly_language">1s and 0s</a>.</p>
</div>
<div class="paragraph">
<p>The C++ source code has the extensions <code>.cpp</code> and <code>.hpp</code>.
In addition, there are files with the extension <code>.make</code>,
which give instructions to the compiler through the utility <a href="http://tldp.org/HOWTO/Software-Building-HOWTO-3.html">make</a>.</p>
</div>
<div class="paragraph">
<p><strong>Don&#8217;t worry</strong> if this all sounds a bit complex. In practice you just need to run <code>make</code> (we will explain how to do that)
and the code will compile, leaving you with a program that you can run on your computer.</p>
</div>
</div>
<div class="sect3">
<h4 id="_driver_functions_objects_and_libraries">4.1.2. Driver functions, objects and libraries</h4>
<div class="paragraph">
<p>LSDTopoTools consists of three distinct components:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Driver functions: These are programs that are used to run the analyses. They take in topographic data and spit out derivative data sets.</p>
</li>
<li>
<p>Objects: The actual number crunching goes on inside objects. Unless you are interested in creating new analyses or are part of the development team, you won&#8217;t need to worry about objects.</p>
</li>
<li>
<p>Libraries: Some of the software need separate libraries to work. The main one is the <a href="http://math.nist.gov/tnt/">TNT</a> library that handles some of the computational tasks.
Unless otherwise stated, these are downloaded with the software and you should not need to do anything special to get them to work.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When you download the code, the objects will sit in a root directory.
Within this directory there will be <code>driver_function_*</code> directories as well as a <code>TNT</code> directory.</p>
</div>
<div class="sect4">
<h5 id="_driver_functions">Driver functions</h5>
<div class="paragraph">
<p>If you are using LSDTopoTools simply to produce derivative datasets from your topographic data,
the programs you will use are <strong>driver functions</strong>. When compiled  these form self enclosed analysis tools.
Usually they are run by calling parameter files that point to the dataset you want to analyze, and the parameters you want to use in the analysis.</p>
</div>
<div class="paragraph">
<p>The <code>.make</code> files, which have the instructions for how the code should compile, are located in the <code>driver_functions_*</code> folders.</p>
</div>
<div class="paragraph">
<p>For example, you might have a driver function folder called <code>/home/LSDTopoTools/driver_functions_chi</code>,
and it contains the following files:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTopoTools/driver_functions_chi
$ ls
chi_get_profiles_driver.cpp       chi_step1_write_junctions_driver.cpp
chi_get_profiles.make             chi_step1_write_junctions.make
chi_m_over_n_analysis_driver.cpp  chi_step2_write_channel_file_driver.cpp
chi_m_over_n_analysis.make        chi_step2_write_channel_file.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this case the <code>.make</code> files are used to compile the code, and the <code>.cpp</code> files are the actual instructions for the analyses.</p>
</div>
</div>
<div class="sect4">
<h5 id="_objects">Objects</h5>
<div class="paragraph">
<p>LSDTopoTools contains a number of methods to process topographic data, and these methods live within <strong>objects</strong>.
The <strong>objects</strong> are entities that store and manipulate data.
Most users will only be exposed to the driver functions,
but if you want to create your own analyses you might have a look at the objects.</p>
</div>
<div class="paragraph">
<p>The objects sit in the directory below the driver functions. They all have names starting with <code>LSD</code>,
so, for examples, there are objects called <code>LSDRaster</code>, <code>LSDFlowInfo</code>, <code>LSDChannel</code> and so on.
Each object has both a <code>.cpp</code> and a <code>.hpp</code> file.</p>
</div>
<div class="paragraph">
<p>If you want the details of what is in the objects in excruciating detail,
you can go to our automatically generated documentation pages, located here: <a href="http://www.geos.ed.ac.uk/~s0675405/LSD_Docs/index.html" class="bare">http://www.geos.ed.ac.uk/~s0675405/LSD_Docs/index.html</a>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_libraries">Libraries</h5>
<div class="paragraph">
<p>THe objects in LSDTopoTools required something called the <a href="http://math.nist.gov/tnt/">Template Numerical Toolkit</a>,
which handles the rasters and does some computation. It comes with the LSDTopoTools package.
You will see it in a subfolder within the folder containing the objects.
This library compiled along with the code using instructions from the makefile.
That is, you don&#8217;t need to do anything special to get it to compile or install.</p>
</div>
<div class="paragraph">
<p>There are some other libraries that are a bit more complex which are used by certain LSDTopoTools packages,
but we will explain those in later chapters when we cover the tools that use them.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_the_typical_directory_layout">4.1.3. The typical directory layout</h4>
<div class="imageblock">
<div class="content">
<img src="images/Directory_structure.png" alt="LSDTopoTools directory structure">
</div>
<div class="title">Figure 2. The typical directory structure of LSDTopoTools.</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_getting_the_code_using_git">4.2. Getting the code using Git</h3>
<div class="paragraph">
<p>The development versions of LSDTopoTools live at the University of Edinburgh&#8217;s code development pages, <a href="https://sourced.ecdf.ed.ac.uk/projects/geos/LSD_devel/">sourceEd</a>,
and if you want to be voyeuristic you can always go to the <a href="https://sourced.ecdf.ed.ac.uk/projects/geos/LSD_devel/timeline">timeline</a> there and see exactly what we are up to.</p>
</div>
<div class="paragraph">
<p>If you actually want to download working versions of the code, however, your best bet is to go to one of our open-source working versions hosted on <a href="https://github.com/">Github</a>.
To get code on Github you will need to know about the version control system <a href="http://git-scm.com/"><code>git</code></a>.</p>
</div>
<div class="paragraph">
<p>What follows is an <strong>extremely</strong> abbreviated introduction to <code>git</code>.
If you want to know more about it, there are thousands of pages of documentation waiting for you online.
Here we only supply the basics.</p>
</div>
<div class="sect3">
<h4 id="_getting_started_with_git">4.2.1. Getting started with Git</h4>
<div class="paragraph">
<p>We start with the assumption that you have installed <code>git</code> on your computer.
If it isn&#8217;t installed, you should consult the appendices for instructions on how to install it.</p>
</div>
<div class="paragraph">
<p>You can call <code>git</code> with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note: Much of what I will describe below is also described in the <a href="http://git-scm.com/book/en/">Git book</a>, available online.</p>
</div>
<div class="paragraph">
<p>If it is your first time using <code>git</code>, you should configure it with a username and email:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git config --global user.name "John Doe"
$ git config --global user.email johndoe@example.com</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now, if you are the kind of person who cares what the internet thinks of you,
you might want to set your email and username to be the same as on your <a href="https://github.com/">Github</a> account
(this is easily done online) so that your contributions to open source projects wil be documented online.</p>
</div>
<div class="paragraph">
<p>You can <code>config</code> some other stuff as well, if you feel like it, such as your editor and merge tool.
If you don&#8217;t know what those are, don&#8217;t bother with these <code>config</code> options:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git config --global merge.tool vimdiff
$ git config --global core.editor emacs</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note: If you want a local configuration, you need to be in a repository (see below) and use the <code>--local</code> instead of <code>--global</code> flag.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">You can check all your options with</dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">  $ git config --list
  core.repositoryformatversion=0
  core.filemode=true
  core.bare=false
  core.logallrefupdates=true
  core.editor=emacs
  user.name=simon.m.mudd
  user.email=Mudd.Pile@pileofmudd.mudd
  merge.tool=vimdiff</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_pulling_a_repository_from_github">4.2.2. Pulling a repository from Github</h4>
<div class="paragraph">
<p>Okay, once you have set up git, you are ready to get some code!
To get the code, you will need to <code>clone</code> it from a repository.
Most of our code is hosted on <a href="https://github.com/">Github</a>,
later in this chapter we &lt;&lt;<a href="https://github.com/">Github</a>,point you to some of our repositories&gt;&gt;,
but for now we will run you through an example.</p>
</div>
<div class="paragraph">
<p>First, navigate to a folder where you want to keep your repositories.
You do not need to make a subfolder for the specific repository; git will do that for you.</p>
</div>
<div class="paragraph">
<p>Go to  <a href="https://github.com/">Github</a> and navigate to a repository you want to grab (in git parlance, you will <code>clone</code> the repository).
Here is one that you might try: <a href="https://github.com/LSDtopotools/LSDTopoTools_ChiMudd2014" class="bare">https://github.com/LSDtopotools/LSDTopoTools_ChiMudd2014</a>.</p>
</div>
<div class="paragraph">
<p>If you look at the right side of this website there will be a little box that says <code>HTTPS clone URL</code>.
Copy the contents of this box. In your powershell or terminal window type</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git clone https://github.com/LSDtopotools/LSDTopoTools_ChiMudd2014.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>The repository will be cloned into the subdirectory <code>LSDTopoTools_ChiMudd2014</code>.
Congratulations, you just got the code!</p>
</div>
<div class="sect4">
<h5 id="_keeping_the_code_up_to_date">Keeping the code up to date</h5>
<div class="paragraph">
<p>Once you have the code, you might want to keep up with updates.
To do this, you just go to the directory that contains the repository whenever you start working and run</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git pull -u origin master</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>origin</code> is the place you cloned the repository from (in this case a specific Github repository) and
<code>master</code> is the branch of the code you are working on.
Most of the time you will be using the <code>master</code> branch,
but you should read the <a href="https://git-scm.com/">git documentation</a> to find out
<a href="https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging">how to branch your repository</a>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_keeping_track_of_changes">Keeping track of changes</h5>
<div class="paragraph">
<p>Once you have an updated version of the code you can simply run it to do your own analyses.
But if you are making modification to the code, you probably will want to track these changes.
To track changes use the <code>git commit</code> command.</p>
</div>
<div class="paragraph">
<p>If you change multiple files, you can commit everything in a folder (including all subdirectories) like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git commit -m "This is a message that should state what you've just done." .</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or you can commit individual, or multiple files:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git commit -m "This is a message that should state what you've just done." a.file
$ git commit -m "This is a message that should state what you've just done." more.than one.file</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_making_your_own_repository">4.2.3. Making your own repository</h4>
<div class="paragraph">
<p>If you start to modify our code, or want to start keeping track of your own scripts,
you might create your own repositories using git and host them on
<a href="https://github.com/">Github</a>, <a href="https://bitbucket.org/">Bitbucket</a> or some other hosting website.</p>
</div>
<div class="paragraph">
<p>First, you go to a directory where you have some files you want to track.
You will need to initiate a <strong>git</strong> repository here. This assumes you have <strong>git</strong> installed.
Type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">git init</code></pre>
</div>
</div>
<div class="paragraph">
<p>to initiate a repository.
If you are downloading an LSDTopoTools repository from github, you won&#8217;t need to <code>init</code> a repository.</p>
</div>
<div class="paragraph">
<p>So now you gave run <code>git init</code> in some folder to initiate a repository.
You will now want to add files with the add command::</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ls
a.file a_directory
$ git add a.file a_directory</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>Git</code> adds all files in a folder, including all the files in a named subdirectoy.</p>
</div>
<div class="paragraph">
<p>If you want to add a specific file(s), you can do something like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git add *.hpp
$ git add A_specific.file</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_committing_to_a_repository">Committing to a repository</h5>
<div class="paragraph">
<p>Once you have some files in a repository,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git commit -m "Initial project version" .</code></pre>
</div>
</div>
<div class="paragraph">
<p>Where the . indicates you want everything in the current directory including subfolders.</p>
</div>
</div>
<div class="sect4">
<h5 id="_pushing_your_repository_to_github">Pushing your repository to Github</h5>
<div class="paragraph">
<p><a href="https://github.com/">Github</a> is a resource that hosts git repositories.
It is a popular place to put open source code.
To host a repository on <a href="https://github.com/">Github</a>, you will need to set up the repository before
syncing your local repository with the github repository.
Once you have initiated a repository on <a href="https://github.com/">Github</a>, it will helpfully tell you the URL of the repository.
This URL will look something like this: <a href="https://github.com/username/A_repository.git" class="bare">https://github.com/username/A_repository.git</a>.</p>
</div>
<div class="paragraph">
<p>To place the repository sitting on your computer on <a href="https://github.com/">Github</a>,
you need to use the  <code>push</code> command. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git remote add origin https://github.com/simon-m-mudd/OneD_hillslope.git
$ git push -u origin master
  Counting objects: 36, done.
  Delta compression using up to 64 threads.
  Compressing objects: 100% (33/33), done.
  Writing objects: 100% (36/36), 46.31 KiB, done.
  Total 36 (delta 8), reused 0 (delta 0)
  To https://github.com/simon-m-mudd/OneD_hillslope.git
  * [new branch]      master -&gt; master
  Branch master set up to track remote branch master from origin.</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once you have uploaded an initial copy, you will need to keep it in sync with
local copies. You can push things to github with::</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git push -u origin master</code></pre>
</div>
</div>
<div class="paragraph">
<p>One thing that can go wrong is that your repository will be out of sync, and you will get messages like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">! [rejected]        master -&gt; master (non-fast-forward)
error: failed to push some refs to 'https://github.com/simon-m-mudd/OneD_hillslope.git'
hint: Updates were rejected because the tip of your current branch is behind
hint: its remote counterpart. Merge the remote changes (e.g. 'git pull')
hint: before pushing again.
hint: See the 'Note about fast-forwards' in 'git push --help' for details.</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can try to fix this by making a <code>pull</code> request:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git pull origin</code></pre>
</div>
</div>
<div class="paragraph">
<p>and if you are lucky you will not have to engage in <a href="https://help.github.com/articles/resolving-a-merge-conflict-from-the-command-line/">conflict resolution</a>.
If you do get a conflict (for example if someone else has pushed a change and you started from an outdated file),
you will need to merge the files. Doing that is beyond the scope of this documentation,
but there are many resources on the web for using git so help is only a few electrons away.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_where_to_get_the_code">4.3. Where to get the code</h3>
<div class="paragraph">
<p>Okay, now to actually get the code! There are several versions floating around.
<strong>They are not all the same!</strong>. The best two ways to get the code both involve downloading the code from <a href="https://github.com">github</a>.</p>
</div>
<div class="paragraph">
<p>One way to do this is to go into a repository and download the repository as a <code>.zip</code> file.</p>
</div>
<div class="paragraph">
<p>If, however, you are planning on keeping up with updates, it is probably better to use the software <code>git</code> to get the code.</p>
</div>
<div class="sect3">
<h4 id="_latest_release_versions_on_github">4.3.1. Latest release versions on GitHub</h4>
<div class="paragraph">
<p>We post the latest release versions of the software on <a href="https://github.com">GitHub</a>.</p>
</div>
<div class="paragraph">
<p>The github site is: <a href="https://github.com/LSDtopotools" class="bare">https://github.com/LSDtopotools</a>.
This site contains a number of offerings: documentation, notes, automation scripts, plotting scripts and other goodies.
At the moment (September, 2015) the "latest release" offerings here are rather limited,
but we hope to change this in the near future.</p>
</div>
</div>
<div class="sect3">
<h4 id="_csdms">4.3.2. CSDMS</h4>
<div class="paragraph">
<p>When we publish papers that use new algorithms, we tend to post the code on the
Community Surface Dynamics Modeling System website, found here: <a href="http://csdms.colorado.edu/wiki/Main_Page" class="bare">http://csdms.colorado.edu/wiki/Main_Page</a>.</p>
</div>
<div class="paragraph">
<p>These versions are the ones used in the publications, so they are representative of the code used in the papers but not the latest versions.
Currently our <a href="http://csdms.colorado.edu/wiki/Main_Page">CSDMS</a> offerings are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A tool for examining river profiles: <a href="http://csdms.colorado.edu/wiki/Model:Chi_analysis_tools" class="bare">http://csdms.colorado.edu/wiki/Model:Chi_analysis_tools</a></p>
</li>
<li>
<p>A tool for finding channel heads: <a href="http://csdms.colorado.edu/wiki/Model:DrEICH_algorithm" class="bare">http://csdms.colorado.edu/wiki/Model:DrEICH_algorithm</a></p>
</li>
<li>
<p>A tool for measuring hillslope length: <a href="http://csdms.colorado.edu/wiki/Model:Hilltop_flow_routing" class="bare">http://csdms.colorado.edu/wiki/Model:Hilltop_flow_routing</a></p>
</li>
<li>
<p>A tool for finding bedrock outcrops: <a href="http://csdms.colorado.edu/wiki/Model:SurfaceRoughness" class="bare">http://csdms.colorado.edu/wiki/Model:SurfaceRoughness</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_3">4.4. Summary</h3>
<div class="paragraph">
<p>You should now have some idea as to where to retrieve the code,
and what you will find in your directories once it is downloaded.
We are now ready to actually move on to using the code!</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_first_analysis">5. First Analysis</h2>
<div class="sectionbody">
<div class="sidebarblock">
<div class="content">
<div class="title">If you have jumped directly to here</div>
<div class="paragraph">
<p>You might be so eager to start that you have jumped directly here without reading any of the background material.
This is fine as long as you know what you are doing!
To start this chapter, you should:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Make sure you can open a <strong>terminal or powershell window</strong>.</p>
</li>
<li>
<p>Make sure you have a <strong>C++ compiler</strong> (we use <code>g++</code>) and the <strong>make tool</strong> installed.</p>
</li>
<li>
<p>Make sure you have <strong>git</strong> installed.</p>
</li>
<li>
<p>Make sure you have the <strong>GDAL utilities</strong> installed and working.</p>
</li>
<li>
<p>Get some topographic data and convert it to <strong>projected coordinates</strong> (we prefer WGS1984 UTM projections).</p>
</li>
<li>
<p>Make sure you have <strong>python</strong> with <strong>scipy</strong> including <strong>numpy</strong> and <strong>matplotlib</strong> working on your computer.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>If you understand all of the preliminary steps, you are ready to move on to your first analysis.
If not, the previous chapters will get you up to speed.</p>
</div>
<div class="sect2">
<h3 id="_preparing_your_data_and_folders">5.1. Preparing your data and folders</h3>
<div class="paragraph">
<p>Don&#8217;t be messy!
Your life will be much more pleasant if you set up a sensible directory structure before your start performing analyses.
The programs in LSDTopoTools allow you to both read and write data from directories of your choice,
so there is no need to pile everything in one directory.
In fact, we would recommend keeping your data quite separate from the code.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Terminal window cheat sheet</div>
<div class="paragraph">
<p>Here are some commands and shortcuts that you will find useful while using the terminal window.
They are things that work in Linux (and should therefore work on OSX, since it is built on Linux).
Not all will work in a Windows powershell, which is why if you are running Windows we recommend,
creating a <a href="#_turning_your_windows_machine_into_a_linux_machine">virtual Linux machine</a> on your Windows computer.
Useful commands are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Navigate to a directory: <code>$ cd /directory/name/</code>.</p>
</li>
<li>
<p>Go down a directory level: <code>$ cd ..</code></p>
</li>
<li>
<p>See what directory you are in: <code>$ pwd</code></p>
</li>
<li>
<p>See what files are in this directory: <code>$ ls</code></p>
</li>
<li>
<p>Copy a file: <code>cp /my/directory/a.file /another/directory/new.filename</code></p>
</li>
<li>
<p>Move a file: <code>mv /my/directory/a.file /another/directory/new.filename</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>There are also a number of keyboard shortcuts that are useful:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Use <code>tab</code> to autocomplete (start typing a filename and hit tab and Linux will complete the filename for you!)</p>
</li>
<li>
<p>Use <code>ctrl-a</code> to go to the beginning of a line in the terminal.</p>
</li>
<li>
<p>Use <code>ctrl-e</code> to go to the end of a line in the terminal.</p>
</li>
<li>
<p>Use the up and dawn arrows to go through your history of commands.</p>
</li>
<li>
<p>If you highlight text with you mouse you can hit the center mouse button to copy text.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>How you organize your directories is, of course, up to you, but we can gently suggest a directory structure.
Because LSDTopoTools is distributed from several different <a href="https://github.com/LSDtopotools">GitHub repositories</a>,
It probably makes sense to make one directory to house all the different repositories,
and another to house your data.</p>
</div>
<div class="paragraph">
<p>The tutorials will be based on a structure where the repositories are located in a folder <code>home/LSDTT_repositories/</code> and the data is located in a folder <code>home/topographic_data/</code>.
If you have a different directory structure just substitute in your directories when running the examples.
If you do this for a living (like we do), you might want to set up a sensible structure for you topographic data,
for example by having folders for the type of data, e.g.:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
home/topographic_data/
$ ls
Aster30m    SRTM90m
lidar       IfSAR
SRTM30m</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then within each data type I&#8217;ve arranged geographically, e.g.:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
home/topographic_data/
$ cd lidar
$ ls
California
Colorado
Italy
Switzerland</code></pre>
</div>
</div>
<div class="paragraph">
<p>Again, the way you organize this data is totally up to you,
but you will save yourself from substantial amounts of stress later if you set up a sensible directory structure from the start.</p>
</div>
</div>
<div class="sect2">
<h3 id="_get_and_compile_your_first_lsdtopotools_program">5.2. Get and compile your first LSDTopoTools program</h3>
<div class="paragraph">
<p>Okay, the first step is to navigate to the folder where you will keep your repositories.
In this example, that folded is called <code>/home/LSDTT_repositories</code>.
In a terminal window, go there with the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd /home/LSDTT_repositories/</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can use the <code>pwd</code> command to make sure you are in the correct directory.
If you don&#8217;t have the directory, use <code>mkdir</code> to make it.</p>
</div>
<div class="sect3">
<h4 id="_clone_the_code_from_git">5.2.1. Clone the code from Git</h4>
<div class="paragraph">
<p>Now, clone the repository from <a href="https://github.com">GitHub</a>.
The repository in the first example is here: <a href="https://github.com/LSDtopotools/LSDTopoTools_AnalysisDriver" class="bare">https://github.com/LSDtopotools/LSDTopoTools_AnalysisDriver</a>.
The command to clone is:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ git clone https://github.com/LSDtopotools/LSDTopoTools_AnalysisDriver.git</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_if_you_would_rather_not_use_code_git_code">5.2.2. If you would rather not use <code>git</code></h4>
<div class="paragraph">
<p>Perhaps you feel like being difficult and have decided not to use <code>git</code>,
because you find its name offensive or because <a href="https://en.wikipedia.org/wiki/Linus_Torvalds">Linus Torvalds</a> once threw an apple core at your cat.</p>
</div>
<div class="paragraph">
<p>In that case you can download a zipped version of the repository, and unzip it</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ wget https://github.com/LSDtopotools/LSDTopoTools_AnalysisDriver/archive/master.zip
$ gunzip master.zip</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compile_the_code">5.2.3. Compile the code</h4>
<div class="paragraph">
<p>Okay, now you should have the code. You will still be sitting in the directory
<code>/home/LSDTT_repositories/</code>, so navigate up to the directory <code>LSDTopoTools_AnalysisDriver/Analysis_driver/</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ cd LSDTopoTools_AnalysisDriver
$ cd Analysis_Driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can now compile the code with</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f Drive_analysis_from_paramfile.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>I am afraid there will be a lot of warnings. We apologize for being naughty programmers.
However, after all of those warnings you should be able to type <code>ls</code> and see a program called <code>LSDTT_analysis_from_paramfile.out</code>.
<strong>Congratualtions!</strong> You have compiled your first LSDTopoTools program. You are now ready to do some analysis.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_running_your_first_analysis">5.3. Running your first analysis</h3>
<div class="paragraph">
<p>We are going to run the first example on some example data.
For the purposes of this example, we are going to put the data into a folder called
<code>home/topographic_data/IfSAR</code>. We called the folder IfSAR since the data is derived from <a href="https://en.wikipedia.org/wiki/Interferometric_synthetic_aperture_radar">IfSAR</a>.
Again, you can call the data whatever you like, but you need to adjust the path names for your directory structure.</p>
</div>
<div class="sect3">
<h4 id="_first_analysis_example_data">5.3.1. First analysis: example data</h4>
<div class="paragraph">
<p>Navigate into your data folder and download the data using the <a href="http://www.gnu.org/software/wget/">wget</a> tool
We have placed several example datasets on a github repository.
Today we will be working with a topographic map from Scotland, you can get it with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/WhiteadderDEM.tif</code></pre>
</div>
</div>
<div class="paragraph">
<p>This data is in <code>.tif</code> format! Quite a lot of the data you might download from the web is in this format.
LSDTopoTools doesn&#8217;t read <code>tif</code> files (that is a job for the future), so <strong>you need to convert to a valid file format</strong>.
We will convert the data using GDAL: see the section <a href="#translating-your-raster-into-something-that-can-be-used-by-lsdtopotoolbox">Translating your raster into something that can be used by LSDTopoToolbox</a>.</p>
</div>
<div class="paragraph">
<p>Our preference is for the data to be in UTM WGS1984 coordinates.
You can look up the UTM zones on <a href="http://www.dmap.co.uk/utmworld.htm">this map compiled by Alan Morton</a>.
The Whiteadder catchement is close to Edinburgh Scotland in zone UTM zone 30N
To convert the data to ENVI <code>bil</code> format (which is our preferred format) type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ gdalwarp -t_srs '+proj=utm +zone=30 +datum=WGS84' -of ENVI WhiteadderDEM.tif WhiteadderDEM.bil</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Now, see if the file is there</dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ls
WhiteadderDEM.bil          WhiteadderDEM.hdr
WhiteadderDEM.bil.aux.xml  WhiteadderDEM.tif</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you looked at the file in a GIS you might have additional files with the extension <code>.aux.xml</code>.
The important thing is that you now have files with the extensions <code>bil</code> and <code>hdr</code>.</p>
</div>
<div class="paragraph">
<p>Important: There are two formats that use the file extension <code>bil</code>: the <strong>ENVI</strong> format (which is the one we use)
and an <strong>ESRI</strong> format. Make sure your <code>bil</code> files are in <strong>ENVI</strong> format.
You can always check using <code>gdalinfo</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_placing_the_paramfile">5.3.2. Placing the paramfile</h4>
<div class="paragraph">
<p>The code is flexible enough that the parameter file can be in a different
location from the data, but I think it is good practice to keep the parameter
files with the data. The parameter file not only runs the software, but
<strong>more importantly it is a reproducible record of your analyses!</strong> So if you are
doing research you should save these files. The software is designed so that
if you send someone else the parameter file and the DEM they can reproduce
your analysis exactly. This differentiates our software from GUI driven
software like ArcMap and QGIS.</p>
</div>
<div class="paragraph">
<p>Okay, lets actually move the file. An example file came with the source code.
You can use the cp` command to make a copy of this file in your data folder.</p>
</div>
<div class="paragraph">
<p>TIP:Keep two terminal windows open, one in the directory with your data, and one in the directory with the compiled code.</p>
</div>
<div class="paragraph">
<p>Note:Your directories will have different names than those shown here so
modify the paths shown below appropriately:</p>
</div>
<div class="paragraph">
<p>If you follow our advice, go into the folder with the data and copy across the parameter file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/topographic_data/IfSAR
$ cp /home/LSDTT_repositories/LSDTopoTools_AnalysisDriver/Analysis_driver/Example.LSDTT_driver Example.LSDTT_driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Alternatively you can copy from the Analysis_driver folder:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/LSDTopoTools_AnalysisDriver/Analysis_driver
/home/topographic_data/IfSAR
$ cp Example.LSDTT_driver /home/topographic_data/IfSAR/Example.LSDTT_driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now make sure you are in the topography folder and check to see if the file is there:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/topographic_data/IfSAR
$ ls
Example.LSDTT_driver  WhiteadderDEM.bil.aux.xml  WhiteadderDEM.tif
WhiteadderDEM.bil     WhiteadderDEM.hdr</code></pre>
</div>
</div>
<div class="paragraph">
<p>We will use <code>Example.LSDTT_driver</code> as a template, but will want to change some of the values in that file.
You might want to keep the original, so we suggest making a copy of the parameter file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">cp Example.LSDTT_driver Whiteadder.LSDTT_driver</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_modifying_the_parameter_file">5.3.3. Modifying the parameter file</h4>
<div class="paragraph">
<p>Before you run the program you need to modify the parameter file.
The parameter file is just plain text, so you will need a text editor to modify it.
You can modify it in your favorite text editor, but <strong>don&#8217;t</strong> use a program that
inserts a bunch of stupid formatting like Wordpad or Word.</p>
</div>
<div class="paragraph">
<p>In fact most text editors in Windows systems have the unfortunate habit of
inserting diabolical hidden characters, called <a href="http://en.wikipedia.org/wiki/Control_character">control characters</a>
that you will never see or notice if you just look at text but will completely
screw up the program. We have endeavored to remove these characters
within our code, but I highly recommend editing the parameter file either
in linux, or using a text editor on Windows that won&#8217;t insert these characters.</p>
</div>
<div class="paragraph">
<p>For windows, we use <a href="http://www.pspad.com/">Pspad</a> or <a href="https://atom.io/">Atom</a></p>
</div>
<div class="paragraph">
<p>For linux, we use either <a href="http://en.wikipedia.org/wiki/Emacs">emacs</a> or <a href="http://en.wikipedia.org/wiki/Vim_(text_editor)">vim</a></p>
</div>
<div class="paragraph">
<p>You can also use <a href="http://brackets.io/">brackets</a> for both Windows and Linux.</p>
</div>
<div class="paragraph">
<p>These linux text editors take a bit of getting used to, so unless you are going to start
writing code, you should probably stick with <strong>Brackets</strong>, <strong>Pspad</strong> or <strong>Atom</strong>.</p>
</div>
<div class="paragraph">
<p>In many text editors, you can select the text formatting. It turns out there are different formattings for different operating systems.
You should use the magic of the internet to determine how to change the text formatting.
Many editors have the options <strong>MAC</strong>, <strong>DOS</strong>, and <strong>UNIX</strong> formatting. You want <strong>UNIX</strong> formatting.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Okay, lets get started modifying this file. Open it in your text editor. It will look a little bit like this::</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># This is a driver file for LSDTopoTools
# Any lines with the # symbol in the first row will be ignored

# File information
dem read extension: bil
dem write extension: bil
read path: /home/topographic_data/IfSAR
read fname: WhiteadderDEM

# Parameters for various topographic analysis
min_slope_for_fill: 0.0001
# pixel_threshold_for_channel_net: 200

# The different analyses to be run
write fill: true
write hillshade: true
# write channel_net: true</code></pre>
</div>
</div>
</li>
<li>
<p>These files have a specific format. Any line that starts with the <code>#</code> symbol is ignored: you can put comments here.</p>
</li>
<li>
<p>Lines with parameters are separated with a colon (<code>:</code>). The text before the colon is the parameter, and the text
after the colon is the parameter value.
For example, in the above file, <code>dem read extension</code> is the parameter and <code>bil</code> is the parameter value.</p>
<div class="ulist">
<ul>
<li>
<p>The parameter names are <strong>NOT</strong> case sensitive: <code>dem read extension</code> is the same as <code>DEM rEaD extenSION</code> as far as the program is concerned.</p>
</li>
<li>
<p>The parameter values <strong>ARE</strong> case sensitive: <code>bil</code> is <strong>NOT</strong> the same as <code>BIL</code>.</p>
</li>
<li>
<p>The program will only understand the parameter name if you get it exactly correct. So if you misspell or put an underscore where a space should
be, the program will not be able to understand. So be careful when editing these files!!</p>
</li>
</ul>
</div>
</li>
<li>
<p>Okay, first, we want to make sure the file path and the file names are correct. These two lines::</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">dem read extension: bil
dem write extension: bil</code></pre>
</div>
</div>
<div class="paragraph">
<p>tell the program that you want to read and write <strong>ENVI</strong> files. That is our intention, so we will leave these lines alone. The default is <code>bil</code> so you could
actually delete these two lines and the program would still work.</p>
</div>
</li>
<li>
<p>Next are lines for the <code>read path</code> and the <code>read fname</code>.
If you didn&#8217;t have lines for these it would default to the
path of the parameter file and the name of the parameter file,
excluding everything after the <code>.</code>.
However I would recommend assigning these.
To figure out what the path to your data is,
first make sure the data is there using <code>ls</code> and then type <code>pwd</code> to get the path:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">$ pwd
/home/topographic_data/IfSAR</code></pre>
</div>
</div>
</li>
<li>
<p>The <code>read fname</code> is the name of the DEM <strong>WITHOUT the extension</strong>.
So if the DEM is called <code>WhiteadderDEM.bil</code> then the <code>read fname</code> would be <code>WhiteadderDEM</code>.
These names are <strong>CASE SENSITIVE</strong>.</p>
<div class="paragraph">
<p>You should modify your parameter file with the correct directory:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># This is a driver file for LSDTopoTools
# Any lines with the # symbol in the first row will be ignored

# File information
dem read extension: bil
dem write extension: bil
read path: /home/topographic_data/IfSAR
read fname: WhiteadderDEM

# Parameters for various topographic analysis
min_slope_for_fill: 0.0001
# pixel_threshold_for_channel_net: 200

# The different analyses to be run
write fill: true
write hillshade: true
# write channel_net: true</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<strong>Do not just copy the above file: your directory will be different!</strong>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>You can also change the path and name of the files you write.
The keywords are <code>write path</code> and <code>write fname</code>. For example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-parafile" data-lang="parafile">write path: /home/smudd/a_different/directory
write fname: DifferentDEMname</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you leave these blank then the output will just write to the read directory. For now don&#8217;t add write path information.</p>
</div>
</li>
<li>
<p>Further down there are some parameters:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># Parameters for various topographic analysis
min_slope_for_fill: 0.0001
# pixel_threshold_for_channel_net: 200</code></pre>
</div>
</div>
<div class="paragraph">
<p>The first one <code>min_slope_for_fill</code> sets a minimum topographic slope after the <code>fill</code> function.
The fill function makes sure there are no internally drained basins in the DEM,
and is a standard task in topographic analysis.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The parameter name has underscores: don&#8217;t replace these with spaces or the program won&#8217;t understand!
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The parameter is actually a bit redundant
since the default for this parameter is 0.0001, so deleting this line wouldn&#8217;t change the output. However, the line is left
in if you want to change it.</p>
</div>
<div class="paragraph">
<p>The next line has a <code>#</code> symbol in front so is ignored by the program.</p>
</div>
</li>
<li>
<p>The next bit tells the program what you want to do with the DEM.:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># The different analyses to be run
write fill: true
write hillshade: true
# write channel_net: true</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this case these instructions are telling the program to write the fill DEM and the hillshade DEM.
The program will not write a channel network (<code>write channel_net</code>) since this line has a <code>#</code> as its first character.</p>
</div>
<div class="paragraph">
<p>You might be asking: doesn&#8217;t ArcMap and QGIS have fill and hillshade functions?
They do indeed, but for large rasters our code is much faster,
and using our parameter files you can create reproducible analyses that can easily be
sent to collaborators, students, clients, etc.</p>
</div>
<div class="paragraph">
<p>These functions will only run if the parameter value is <code>true</code>.</p>
</div>
</li>
<li>
<p>Okay, save your changes to the parameter file; we will now move on to performing the analyses.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_running_the_analyses_in_this_case_writing_fill_and_hillshade_rasters">5.3.4. Running the analyses (in this case, writing fill and hillshade rasters)</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You need to run the program (<code>LSDTT_analysis_from_paramfile.out</code>) from the folder containing the program.
We would suggest keeping two terminal windows open, one in which you are in the directory of the data,
and another where you are in the directory of the program.
You can always find out what directory you are in by using the command <code>pwd</code>.</p>
</li>
<li>
<p><code>LSDTT_analysis_from_paramfile.out</code> runs with two arguments:</p>
</li>
<li>
<p>The path to the parameter file.</p>
</li>
<li>
<p>The name of the parameter file.</p>
</li>
<li>
<p>You should have already found the path to your data
(go to your data folder and type <code>pwd</code>).
The name of the parameter file includes extension.
So to run the program you type this:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./LSDTT_analysis_from_paramfile.out /home/topographic_data/IfSAR Whiteadder.LSDTT_driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>./</code> is a Linux thing.
When you run programs you tell Linux that the program is in this directory with <code>./</code>.</p>
</div>
</li>
<li>
<p>Once you&#8217;ve entered the above command,
there will be some output to screen telling you what the code is doing,
and then it will finish.</p>
</li>
<li>
<p><code>LSDTT_analysis_from_paramfile.out</code> has put the output in the data folder,
so use <code>ls</code> in this folder to see if the data is there:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ls
Example.LSDTT_driver       WhiteadderDEM.tif    Whiteadder_hs.hdr
WhiteadderDEM.bil          Whiteadder_fill.bil  Whiteadder.LSDTT_driver
WhiteadderDEM.bil.aux.xml  Whiteadder_fill.hdr
WhiteadderDEM.hdr          Whiteadder_hs.bil</code></pre>
</div>
</div>
</li>
<li>
<p>Hey, look at that!
There are a bunch of new files.
There are two new rasters, each with a <code>bil</code> file and a <code>hdr</code> file.
These are the fill raster: <code>Whiteadder_fill.bil</code> and the hillshade raster <code>Whiteadder_hs.bil</code>.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_look_at_the_output">5.3.5. Look at the output</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Now that you&#8217;ve done some analyses,
you can look at the data in either your favorite GIS or using python.
If you don&#8217;t know how to do that, you should have a look at our appendix: <a href="#Tools-for-viewing-data">[Tools-for-viewing-data]</a>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_4">5.4. Summary</h3>
<div class="paragraph">
<p>By now you should be able to clone one of our programs from Github, compile it, and run it on your computer.
Now we can move on to more complex topographic analyses.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_simple_surface_metrics_slope_curvature_aspect_etc">6. Simple surface metrics (slope, curvature, aspect, etc)</h2>
<div class="sectionbody">
<div class="paragraph">
<p>By now you should have compiled the program <code>LSDTT_analysis_from_paramfile.out</code>.
If you haven&#8217;t done this, go to the previous chapter: <a href="#_first_analysis">First Analysis</a>.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">If you have jumped directly to here</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You need to have a compiler, the make utility, and the GDAL utilities available.
If you don&#8217;t know what these are go to the previous chapters.</p>
</li>
<li>
<p>You need to get and compile the source code; see here: <a href="#get-and-compile-source">[get-and-compile-source]</a>.</p>
</li>
<li>
<p>You should make a folder for your data; see here: <a href="#make-folder">[make-folder]</a>.</p>
</li>
<li>
<p>If you don&#8217;t have data, get the example data; see here: <a href="#get-example-data">[get-example-data]</a>.</p>
</li>
<li>
<p>Move the parameter file to the data folder; see here: <a href="#param-to-data-folder">[param-to-data-folder]</a>.</p>
</li>
<li>
<p>Rename your parameter file (so you don&#8217;t confuse this with other analyses). You can do this
using the <code>cp</code> command:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cp Example.LSDTT_driver A_sensible_name.LSDTT_driver</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the extension to the parameter file (in this case <code>.LSDTT_driver</code>) doesn&#8217;t matter. You could
call the file <code>Wacky.Monkey_Gumballs</code> if you wanted.
It is the <em>format</em> of this file that is important, not the filename.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Open two terminal windows (Instructions here: <a href="#_the_terminal_and_powershells">The terminal and powershells</a>).</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_modifying_the_parameter_file_2">6.1. Modifying the parameter file</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You should be starting with a parameter file in your data folder that has been copied from
somewhere else. You will now need to modify this file.</p>
</li>
<li>
<p>Open the file in your favorite text editor. If this is from a previous analysis, you might see
something a bit like this:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># This is a driver file for LSDTopoTools
# Any lines with the # symbol in the first row will be ignored

# File information
dem read extension: bil
dem write extension: bil
read path: /home/smudd/topographic_tools/topographic_data/NextMap/Scotland
read fname: WhiteadderDEM

# Parameters for various topographic analysis
min_slope_for_fill: 0.0001
# pixel_threshold_for_channel_net: 200

# The different analyses to be run
write fill: true
write hillshade: true
# write channel_net: true</code></pre>
</div>
</div>
</li>
<li>
<p>If a line has a <code>#</code> symbol, that line is a comment and the program <code>LSDTT_analysis_from_paramfile.out</code>
will ignore it.</p>
</li>
<li>
<p>First, we need to deal with the file format and location.
The file information in this case is:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># File information
dem read extension: bil
dem write extension: bil
read path: /home/smudd/topographic_tools/topographic_data/NextMap/Scotland
read fname: WhiteadderDEM</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will work for me, but you will have to change this line:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">read path: /home/smudd/topographic_tools/topographic_data/NextMap/Scotland</code></pre>
</div>
</div>
<div class="paragraph">
<p>to your path:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">read path: /home/s01429521/my/sensible/path/Scotland/</code></pre>
</div>
</div>
<div class="paragraph">
<p>To figure out what the path is you can type <code>pwd</code> in the terminal window when you are in your data folder.</p>
</div>
<div class="paragraph">
<p>If you are not using the example data, you will need to change the read fname to the name of your data.
So for example, if you are starting with a DEM called <code>Sierra.bil</code>,
the read fname will be <code>Sierra</code>.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Some notes abot parameter files</div>
<div class="ulist">
<ul>
<li>
<p>The parameter names are <strong>NOT</strong> case sensitive: <code>dem read extension</code> is the same as <code>DEM rEaD extenSION</code> as far as the program is concerned.</p>
</li>
<li>
<p>The parameter values <strong>ARE</strong> case sensitive: <code>bil</code> is <strong>NOT</strong> the same as <code>BIL</code>.</p>
</li>
<li>
<p>The program will only understand the parameter name if you get it exactly correct.
So if you misspell or put an underscore where a space should
be, the program will not be able to understand.
So be careful when editing these files!!</p>
</li>
</ul>
</div>
</div>
</div>
</li>
<li>
<p>Now lets move on to parameter values. At the moment these are:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># Parameters for various topographic analysis
min_slope_for_fill: 0.0001
# pixel_threshold_for_channel_net: 200</code></pre>
</div>
</div>
<div class="paragraph">
<p>The first and third lines above are comments, and are ignored by the program.
We don&#8217;t actually need the <code>min_slope_for_fill</code> parameter for this run,
but if you leave that it it won&#8217;t affect the program.</p>
</div>
</li>
<li>
<p>To get our simple surface metrics, we are going to use a polyfit function. This fits a polynomial to the topographic surface
over a fixed window, and then calculates topographic metrics of this polynomial rather than calculating metrics on the data
itself. This technique is employed to smooth high frequency noise, such as that from pits and mounds caused by falling trees.</p>
<div class="paragraph">
<p>For LiDAR data, we have found that you want a polyfit window that is around 7 metres in radius.
This is based on work by <a href="http://pages.uoregon.edu/~jroering/outgoing/2010RoeringTreesSoilEPSL2010.pdf">Roering et al., 2010</a> and
<a href="http://www.geos.ed.ac.uk/homes/smudd/Hurst_JGR2012.pdf">Hurst et al., 2012</a>.
For coarser data, you probably want to smooth over at least 1 pixel radius, so if you havbe a 10m DEM your window radius should be &gt;10m.</p>
</div>
<div class="paragraph">
<p>In this example we are using old NextMap data (it was processed around 2007). Sadly this data isn&#8217;t so great: it is full of lumps.
The data resolution is 5 metres, but we are going to use a polyfit radius of 15.1 metres to make sure we get three pixels on each side of the centre pixel.</p>
</div>
<div class="paragraph">
<p>The keyword is <code>polyfit_window_radius</code>, so in your parameter file you should have these lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># Parameters for various topographic analysis
min_slope_for_fill: 0.0001
# pixel_threshold_for_channel_net: 200
polyfit_window_radius: 15.1</code></pre>
</div>
</div>
</li>
<li>
<p>We also want to add some lines to the parameter file to designate a method for calculating slope. The default method is called <code>d8</code>.
It takes the slope between a pixel and its steepest downslope neighbor.
For this example, we want the <code>polyfit</code> method, wherein the data is fit with a polynomial and the slope is determined by differentiating this polynomial.
To switch the slope method to <code>polyfit</code>, you use the flag for <code>slope_method</code>:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># Methods used in analyses
slope_method: polyfit</code></pre>
</div>
</div>
<div class="paragraph">
<p>The first line above (<code># Methods used in analyses</code>) is a comment so ignored by the program, but it is useful to add these
comments to the parameter files so that other people can tell what you are doing.</p>
</div>
</li>
<li>
<p>Now you should tell the program what rasters to write. In this case we want curvature, aspect, and slope,
so this section of the parameter file should look like:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># The different analyses to be run
write slope: true
write curvature: true
write aspect: true</code></pre>
</div>
</div>
</li>
<li>
<p>Okay, save your changes to the parameter file;
we will now move on to performing the analyses. It should look like this:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># This is a driver file for LSDTopoTools
# Any lines with the # symbol in the first row will be ignored

# File information
dem read extension: bil
dem write extension: bil
read path: /home/smudd/topographic_tools/topographic_data/NextMap/Scotland
read fname: WhiteadderDEM

# Parameters for various topographic analysis
min_slope_for_fill: 0.0001
# pixel_threshold_for_channel_net: 200
slope_method: polyfit
polyfit_window_radius: 15.1

# The different analyses to be run
write slope: true
write aspect: true
write curvature: true</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_running_the_analyses_in_this_case_writing_fill_and_hillshade_rasters_2">6.2. Running the analyses (in this case, writing fill and hillshade rasters)</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You will now need to run the program <code>LSDTT_analysis_from_paramfile.out</code>.
Some details about running this program are in the first tutorial (<a href="#First-analysis">[First-analysis]</a>) in case you have forgotten.</p>
</li>
<li>
<p>I renamed my parameter file `Whiteadder_Surf.LSDTT_driver, so to run the code you need to type the following into the command line::</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./LSDTT_analysis_from_paramfile.out /home/smudd/topographic_tools/topographic_data/NextMap/Scotland Whiteadder_Surf.LSDTT_driver</code></pre>
</div>
</div>
</li>
<li>
<p>The program will spit out text to screen as it works.
Once it is finished, you can look at the data in your favorite GIS.
You can check to see if all the files are there by going into your data folder and typing <code>ls</code>.
You should see something like:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ls
Example.LSDTT_driver  Whiteadder_fill.bil  Whiteadder.LSDTT_driver        Whiteadder_Surf_curvature.hdr
WhiteadderDEM.bil     Whiteadder_fill.hdr  Whiteadder_Surf_aspect.bil     Whiteadder_Surf.LSDTT_driver
WhiteadderDEM.hdr     Whiteadder_hs.bil    Whiteadder_Surf_aspect.hdr     Whiteadder_Surf_slope.bil
WhiteadderDEM.tif     Whiteadder_hs.hdr    Whiteadder_Surf_curvature.bil  Whiteadder_Surf_slope.hdr</code></pre>
</div>
</div>
</li>
<li>
<p>Something is actually a little funny here. Why are the output files all named <code>Whiteadder_Surf&#8230;&#8203;</code>?
The default output file names are the name of the parameter file with the extension removed.
If you want to change the output names you can either change the name of the parameter file,
or, alternatively, you can include the write file name in the parameter file:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">write fname: MyFileName</code></pre>
</div>
</div>
</li>
<li>
<p>Another thing to note: If you use <code>ArcMap</code> to calculate curvature, it will get the sign wrong! Ridgetops have negative curvature
and valleys have positive curvature. This is reversed in <code>ArcMap</code>. Our software gives the correct curvature.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_summary_5">6.3. Summary</h3>
<div class="paragraph">
<p>You should now be able to extract some simple topographic metrics from a DEM using our Driver_analysis program.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_channel_extraction">7. Channel extraction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Landscapes are almost always dissected by a network of channels,
and extracting channel networks from topographic data is a common yet frequently challenging task in topographic analysis.  We have a variety of different channel network extraction algorithms that can be used depending on the characteristics of the landscape to be studied (such as the relief and presence of artifical features), or the resolution of the available digital elevation models (DEMs).
In this chapter we go through the many methods of channel extraction available within <a href="https://lsdtopotools.github.io/">LSDTopoTools</a>,
ranging from rudimentary methods (e.g., <a href="#_basic_channel_extraction_using_thresholds">Basic channel extraction using thresholds</a>)
to methods that aim to precicely locate channel heads from high resolution data.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick guide if you already know what you are doing</div>
<div class="paragraph">
<p>Here is a quick overview of how to set up and run the code, if you have done it before:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Choose the channel extraction method that you would like to use.</p>
</li>
<li>
<p>Make sure your DEM is in <code>bil</code> format and is in the repository folder</p>
</li>
<li>
<p>Create a parameter file for your DEM</p>
</li>
<li>
<p>Compile the code using <code>make -f channel_extraction_TypeOfExtraction.make</code>, where <code>TypeOfExtraction</code> is the extraction method you want to use (either area_threshold, pelletier, geonet, or dreich).</p>
</li>
<li>
<p>Run the program with <code>./channel_extraction_TypeOfExtraction.out /path_to_repository_folder/ parameter_file.driver</code></p>
</li>
<li>
<p>Open the resulting <code>bil</code> and CSV files in the GIS of your choice.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_get_the_code_for_channel_extraction">7.1. Get the code for channel extraction</h3>
<div class="paragraph">
<p>Our code for channel extraction can be found in our GitHub repository.  This repository contains code for extracting channel networks using a variety of different methods ranging from simple contributing area thresholds to more complex geometric and theoretical approaches for extracting channels from high-resolution datasets.</p>
</div>
<div class="sect3">
<h4 id="_clone_the_github_repository">7.1.1. Clone the GitHub repository</h4>
<div class="paragraph">
<p>First navigate to the folder where you will keep the GitHub repository.  In this example it is called <code>/home/LSDTT_repositories</code>.  To navigate to this folder in a UNIX terminal use the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd /home/LSDTT_repositories/</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can use the command <code>pwd</code> to check you are in the right folder.  Once you are in this folder, you can clone the repository from the <a href="https://github.com">GitHub website</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ git clone https://github.com/LSDtopotools/LSDTopoTools_ChannelExtraction.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>Navigate to this folder again using the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd LSDTopoTools_ChannelExtraction/</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_alternatively_get_the_zipped_code">7.1.2. Alternatively, get the zipped code</h4>
<div class="paragraph">
<p>If you don&#8217;t want to use <em>git</em>, you can download a zipped version of the code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ wget https://github.com/LSDtopotools/LSDTopoTools_ChannelExtraction/archive/master.zip
$ gunzip master.zip</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="https://github.com">GitHub</a> zips all repositories into a file called <code>master.zip</code>,
so if you previously downloaded a zipper repository this will overwrite it.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_get_the_example_datasets">7.1.3. Get the example datasets</h4>
<div class="paragraph">
<p>We have provided some example datasets which you can use in order to test the channel extraction algorithms. In this tutorial we will work using a lidar dataset from Indian Creek, Ohio. You can get it from our ExampleTopoDatasets repository using <code>wget</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/indian_creek.bil
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/indian_creek.hdr</code></pre>
</div>
</div>
<div class="paragraph">
<p>This dataset is already in the preferred format for use with LSDTopoTools (the ENVI <code>bil</code> format). The figure below shows a shaded relief map of part of the Indian Creek DEM which will be used in these examples.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ind_map.png" alt="Shaded relief map of Indian Creek">
</div>
<div class="title">Figure 3. Shaded relief image of Indian Creek catchment, Ohio USA, UTM Zone 17N</div>
</div>
</div>
<div class="sect3">
<h4 id="_get_the_example_parameter_files">7.1.4. Get the example parameter files</h4>
<div class="paragraph">
<p>We have also provided some examples parameter files that are used to run each method of channel extraction.  You can check out the entire folder of example parameter files using subversion by typing the following in the command line:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ svn checkout https://github.com/LSDtopotools/ExampleTopoDatasets/trunk/example_parameter_files/ExampleFiles_ChannelExtraction</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you don&#8217;t have subversion you can use wget to get the individual files (this must be done separately for each file) e.g.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/tree/master/example_parameter_files/ExampleFiles_ChannelExtraction/indian_creek_dreich.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once you have downloaded the example files then put them in the repository folder <code>LSDTopoTools_ChannelExtraction</code>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_basic_channel_extraction_using_thresholds">7.2. Basic channel extraction using thresholds</h3>
<div class="paragraph">
<p>One of the most simple ways of extracting channel networks from DEMs uses a contributing area threshold.  This method is useful for coarse resolution (e.g. &gt;10m) DEMs, where topographic features of the channel heads themselves cannot be reliably identified from the DEM. The user has to specify the threshold area, which represents the upstream area that must drain to a pixel before it is considered as part of the channel.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The area threshold chosen will affect the density of the channel network.  This should be considered carefully, and compared against field-mapped channel head data if these are available.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>We will work through an example using the Indian Creek example dataset that you downloaded.</p>
</div>
<div class="sect3">
<h4 id="_compile_the_code_2">7.2.1. Compile the code</h4>
<div class="paragraph">
<p>We can extract threshold area channel networks using the driver function called <code>channel_extraction_area_threshold.cpp</code>.  To compile the code you first need to navigate to the driver functions folder in the repository.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd driver_functions_ChannelExtraction/</code></pre>
</div>
</div>
<div class="paragraph">
<p>When in this folder type the following to compile the driver:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f channel_extraction_area_threshold.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will create a program called <code>channel_extraction_area_threshold.out</code></p>
</div>
</div>
<div class="sect3">
<h4 id="_run_the_analysis">7.2.2. Run the analysis</h4>
<div class="paragraph">
<p>To run the analysis you first need to create a parameter file, with which we will set the key user-defined parameters.  To create your parameter file, open any text editor and create a file with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Name of the DEM without extension
Minimum slope for filling the DEM (suggested to be 0.0001)
Threshold area for channel extraction</code></pre>
</div>
</div>
<div class="paragraph">
<p>The threshold area must be given in m<sup>2</sup>.  You need to save this parameter file in the folder <code>LSDTopoTools_ChannelExtraction</code> (one folder above the driver functions folder).  For the Indian Creek site we can create a parameter file called <code>indian_creek_threshold.driver</code> with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">indian_creek
0.0001
1000</code></pre>
</div>
</div>
<div class="paragraph">
<p>After creating the parameter file we can then run the code using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_area_threshold.out /path_to_repository_folder/ param_file_name</code></pre>
</div>
</div>
<div class="paragraph">
<p>For our Indian Creek example our command would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_area_threshold.out /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/ indian_creek_threshold.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once this program has run, it will create several files with the extracted channel network.  These include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A CSV file with the channel heads e.g. <code>indian_creek_CH_nodeindices_for_arc.csv</code></p>
</li>
<li>
<p>A <code>bil</code> file with the channel heads e.g. <code>indian_creek_CH.bil</code></p>
</li>
<li>
<p>A <code>bil</code> file with the stream network with Strahler stream ordering e.g. <code>indian_creek_SO.bil</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The figure below shows the extracted channel network for the Indian Creek field site with a threshold of 1000 m<sup>2</sup>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ind_so_area.png" alt="Map of Indian Creek with channel network extracted from threshold area">
</div>
<div class="title">Figure 4. Map of Indian Creek with channel network extracted from threshold area</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_geometric_channel_extraction_methods">7.3. Geometric channel extraction methods</h3>
<div class="paragraph">
<p>For higher-resolution DEMs a number of different methods have been developed to extract channel networks more accurately.  This section details how to extract channels using methods relying on geometric signatures of channel incision, primarily how it affects planform curvature. Although many methods have been developed that use a variety of planform curvature to detech channel heads, we will discuss three methods: the Geonet method the Geonet method (developed by Passalacqua et al. 2010a, b, 2012), a method developed by Pelletier (2013) and implemented in LSDTopoTools, and a similar geometric method available within LSDTopoTools.</p>
</div>
<div class="sect3">
<h4 id="_geonet_external_software">7.3.1. Geonet (external software)</h4>
<div class="paragraph">
<p>The Geonet algorithm filters the DEM using a Perona-Malik filter, then uses a planform curvature threshold which is statistically derived from the landscape to detect channel heads. For full information on how Geonet works please see Passalcqua et al. (2010a, b, 2012). It then uses a contributing area threshold to thin the skeleton and create the final channel network.  The Geonet algorithm is available free to download from <a href="https://sites.google.com/site/geonethome/home">the Geonet website</a>. This site also contains the code documentation and user guides on how to get started with Geonet. It is a cross platform MATLAB package (you will need a MATLAB licence to run in its present form).</p>
</div>
</div>
<div class="sect3">
<h4 id="_pelletier">7.3.2. Pelletier</h4>
<div class="paragraph">
<p><a href="http://onlinelibrary.wiley.com/doi/10.1029/2012WR012452/abstract">Pelletier (2013)</a> developed an algorithm that is similar to Geonet in that it identifies channel heads based on a planform curvature threshold.  The main differences between this algorithm and Geonet are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>It uses an optimal Wiener threshold to filter the data rather than a Perona-Malik filter</p>
</li>
<li>
<p>It sets a user-defined curvature threshold (e.g. 0.1 m<sup>-1</sup>) rather than defining it statistically for the landscape in question</p>
</li>
<li>
<p>It does not use a contributing area threshold to thin the skeleton - instead it uses a multi-directional flow routing algorithm</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Pelletier algorithm has been implemented in LSDTopoTools.  In order to run it you should follow the steps below.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
To run the Pelletier algorithm you need to have the Fast Fourier Transform Library downloaded into your folder <code>LSDTopoTools_ChannelExtraction</code>. You can download it at <a href="http://www.fftw.org/download.html" class="bare">http://www.fftw.org/download.html</a>.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="_compile_the_code_3">Compile the code</h5>
<div class="paragraph">
<p>To compile the code navigate to the folder driver_functions_ChannelExtraction.  In a terminal window type the following to compile the driver:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f channel_extraction_pelletier.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will create a program called <code>channel_extraction_pelletier.out</code> which you can use to run the code.</p>
</div>
</div>
<div class="sect4">
<h5 id="_run_the_analysis_2">Run the analysis</h5>
<div class="paragraph">
<p>We first need to create a parameter file similar to that for the <a href="#_basic_channel_extraction_using_thresholds">Basic channel extraction using thresholds</a>. To create your parameter file, open any text editor and create a file with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Name of the DEM without extension
Minimum slope for filling the DEM (suggested to be 0.0001)
Threshold area for initial channel network (should be small e.g. 250)
Curvature threshold for channel extraction (suggested by Pelletier (2013) to be 0.1 to avoid extracting threshold hillslopes)
Minimum catchment area (suggested to be 400)</code></pre>
</div>
</div>
<div class="paragraph">
<p>You need to save this parameter file in the folder <code>LSDTopoTools_ChannelExtraction</code> (one folder above the driver functions folder).  For the Indian Creek site we can create a parameter file called <code>indian_creek_pelletier.driver</code> with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">indian_creek
0.0001
250
0.1
400</code></pre>
</div>
</div>
<div class="paragraph">
<p>After creating the parameter file we can then run the code using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_pelletier.out /path_to_repository_folder/ param_file_name</code></pre>
</div>
</div>
<div class="paragraph">
<p>For our Indian Creek example our command would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_pelletier.out /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/ indian_creek_pelletier.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once this program has run, it will create several files with the extracted channel network.  These include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A CSV file with the channel heads e.g. <code>indian_creek_CH_Pelletier_nodeindices_for_arc.csv</code></p>
</li>
<li>
<p>A <code>bil</code> file with the channel heads e.g. <code>indian_creek_CH_Pelletier.bil</code></p>
</li>
<li>
<p>A <code>bil</code> file with the stream network with Strahler stream ordering e.g. <code>indian_creek_SO_Pelletier.bil</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The figure below shows the extracted channel network using the Pelletier algorithm for the Indian Creek field site with a planform curvature threshold of 0.1 m<sup>-1</sup>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ind_so_pel.png" alt="Map of Indian Creek with channel network extracted from Pelletier algorithm">
</div>
<div class="title">Figure 5. Map of Indian Creek with channel network extracted from Pelletier algorithm</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_the_lsdtopotools_geometric_method">7.3.3. The LSDTopoTools geometric method</h4>
<div class="paragraph">
<p>Within LSDTopoTools we have also developed a method for extracting channel heads via planform curvature.  We first of all filter the DEM using an Optimal Wiener filter, then use a quantile-quantile threshold to statistically determine the planform curvature threshold from the landscape. It then uses a <a href="http://www.ncbi.nlm.nih.gov/pubmed/18390379">connected components threshold</a> to extract the channel network.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
To run the LSDTopoTools algorithm you need to have the Fast Fourier Transform Library downloaded into your folder <code>LSDTopoTools_ChannelExtraction</code>. You can download it at <a href="http://www.fftw.org/download.html" class="bare">http://www.fftw.org/download.html</a>.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="_compile_the_code_4">Compile the code</h5>
<div class="paragraph">
<p>To compile the code navigate to the folder driver_functions_ChannelExtraction.  In a terminal window type the following to compile the driver:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f channel_extraction_wiener.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will create a program called <code>channel_extraction_wiener.out</code> which you can use to run the code.</p>
</div>
</div>
<div class="sect4">
<h5 id="_run_the_analysis_3">Run the analysis</h5>
<div class="paragraph">
<p>We first need to create a parameter file similar to that for the <a href="#_basic_channel_extraction_using_thresholds">Basic channel extraction using thresholds</a>. To create your parameter file, open any text editor and create a file with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Path and file name of the DEM without extension
Path and output name prefix for your files
Path and output name prefix for the quantile-quantile information
Window radius for filtering the DEM
Threshold area for thinning the channel skeleton
Connected components threshold (should be 100)</code></pre>
</div>
</div>
<div class="paragraph">
<p>The threshold area is given in m<sup>2</sup>. You need to save this parameter file in the folder <code>LSDTopoTools_ChannelExtraction</code> (one folder above the driver functions folder).  For the Indian Creek site we can create a parameter file called <code>indian_creek_wiener.driver</code> with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">RasterFile /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/indian_creek
OutputRasterFile /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/indian_creek
QQFile /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/indian_creek_qq
window_radius_for_surface_fitting 6
threshold_drainage_area 1000
connected_components_threshold 100</code></pre>
</div>
</div>
<div class="paragraph">
<p>After creating the parameter file we can then run the code using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_wiener.out /path_to_repository_folder/ param_file_name</code></pre>
</div>
</div>
<div class="paragraph">
<p>For our Indian Creek example our command would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_wiener.out /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/ indian_creek_wiener.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once this program has run, it will create several files with the extracted channel network.  These include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A CSV file with the channel heads e.g. <code>indian_creek_CH_wiener_nodeindices_for_arc.csv</code></p>
</li>
<li>
<p>A <code>bil</code> file with the channel heads e.g. <code>indian_creek_CH_wiener.bil</code></p>
</li>
<li>
<p>A <code>bil</code> file with the stream network with Strahler stream ordering e.g. <code>indian_creek_SO_wiener.bil</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The figure below shows the extracted channel network using the LSDTopoTools geometric algorithm with an Optimal Wiener filter for the Indian Creek field site.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ind_so_wiener.png" alt="Map of Indian Creek with channel network extracted from LSDTopoTools geometric algorithm with an Optimal Wiener filter">
</div>
<div class="title">Figure 6. Map of Indian Creek with channel network extracted from LSDTopoTools geometric algorithm with an Optimal Wiener filter</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_channel_extraction_using_the_dreich_method">7.4. Channel extraction using the Dreich method</h3>
<div class="paragraph">
<p>The <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013WR015167/abstract">Dreich method</a>
of channel head extraction aims to find channel heads by looking at the break in the properties of topographic profiles
that occur when fluvial incision gives way to hillslope sediment transport processes. It is different from the geometric methods described above in that it looks for a theoretical signal of fluvial incision rather than the planform curvature of the landscape.  The method you use should be chosen based on the particular aims of your study: if you are interested in extracting the valley network (all concave parts of the landscape) then you should use a geometric method, but if you are interested in extracting the fluvial channel network then you should use the Dreich method.</p>
</div>
<div class="paragraph">
<p>The stable version of the Dreich algorithm that was released with our <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013WR015167/abstract">WRR paper</a> is hosted on <a href="http://csdms.colorado.edu/wiki/Model:DrEICH_algorithm">CSDMS</a>.  The version available from our GitHub repository is the newest version of the code containing some improvements over the stable version.  We have made some changes to the way that valleys are extracted from the DEM before the Dreich algorithm is run.  In our previous version we used a curvature threshold of 0.1 m<sup>-1</sup> to select valleys for analysis as a pre-processing stage.  We have now changed the code so that this curvature threshold is statistically derived from the landscape in question using the same method as that of the Geonet algorithm (Passalacqua et al., 2010a, b, 2012).  After the initial valley network is extracted, the user may then select the stream order of valleys in which to run the DrEICH algorithm.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
To run the Dreich algorithm you need to have the Fast Fourier Transform Library downloaded into your folder <code>LSDTopoTools_ChannelExtraction</code>. You can download it at <a href="http://www.fftw.org/download.html" class="bare">http://www.fftw.org/download.html</a>.
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_run_the_chi_analysis">7.4.1. Run the chi analysis</h4>
<div class="paragraph">
<p>Before the Dreich algorithm can be run the <em>m/n</em> value for the landscape must be determined.  This can be done using the <a href="#_chi_analysis">Chi analysis</a> in LSDTopoTools.</p>
</div>
</div>
<div class="sect3">
<h4 id="_compile_the_code_5">7.4.2. Compile the code</h4>
<div class="paragraph">
<p>We can extract threshold area channel networks using the driver function called <code>channel_extraction_dreich.cpp</code>.  To compile the code you first need to navigate to the driver functions folder in the repository.  When in this folder type the following to compile the driver:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f channel_extraction_dreich.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will create a program called <code>channel_extraction_dreich.out</code></p>
</div>
</div>
<div class="sect3">
<h4 id="_run_the_analysis_4">7.4.3. Run the analysis</h4>
<div class="paragraph">
<p>We first need to create a parameter file similar to that for the <a href="#_basic_channel_extraction_using_thresholds">Basic channel extraction using thresholds</a>. To create your parameter file, open any text editor and create a file with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Path and file name of the DEM without extension
Path and output name prefix for your files
Window radius for filtering the DEM
Threshold area for initial channel network (should be 1000)
Connected components threshold for initial valley network (should be 100)
A_0 for chi analysis (should be 1000)
m/n value for landscape (calculate using Chi analysis tools)
Number of tributary junctions downstream of valley head to run DrEICH algorithm on (set to 1 for whole valley network)</code></pre>
</div>
</div>
<div class="paragraph">
<p>You need to save this parameter file in the folder <code>LSDTopoTools_ChannelExtraction</code> (one folder above the driver functions folder).  For the Indian Creek site we can create a parameter file called <code>indian_creek_dreich.driver</code> with the following lines:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">RasterFile /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/indian_creek
OutputRasterFile /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/indian_creek
window_radius_for_surface_fitting 6
threshold_drainage_area 1000
connected_components_threshold 100
A_0 1000
m_over_n 0.437
number_of_junctions_dreich 1</code></pre>
</div>
</div>
<div class="paragraph">
<p>After creating the parameter file we can then run the code using the following command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_dreich.out /path_to_repository_folder/ param_file_name</code></pre>
</div>
</div>
<div class="paragraph">
<p>For our Indian Creek example our command would be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./channel_extraction_dreich.out /home/LSDTT_repositories/LSDTopoTools_ChannelExtraction/ indian_creek_dreich.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once this program has run, it will create several files with the extracted channel network.  These include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A <code>bil</code> file with the valley network with Strahler stream ordering e.g. <code>indian_Creek_SO_valley.bil</code></p>
</li>
<li>
<p>A CSV file with the channel heads e.g. <code>indian_creek_CH_DrEICH_nodeindices_for_arc.csv</code></p>
</li>
<li>
<p>A <code>bil</code> file with the channel heads e.g. <code>indian_creek_CH_DrEICH.bil</code></p>
</li>
<li>
<p>A <code>bil</code> file with the stream network with Strahler stream ordering e.g. <code>indian_creek_SO_DrEICH.bil</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The figure below shows the extracted channel network using the DrEICH algorithm for the Indian Creek field site.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ind_so_dreich.png" alt="Map of Indian Creek with channel network extracted from DrEICH algorithm">
</div>
<div class="title">Figure 7. Map of Indian Creek with channel network extracted from DrEICH algorithm</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_6">7.5. Summary</h3>
<div class="paragraph">
<p>By now you should be able to extract channel networks using a variety of methods. For coarse-resolution DEMs you can extract the channel network using a simple area threshold, although the choice of threshold must be carefully considered. For higher-resolution DEMs you can use either a geometric method (if you are interested in extracting the valley network), or a process-based method such as the DrEICH algorithm (if you are interested in the fluvial domain).  These methods all require a certain number of user-defined parameters, so the user should take care to select these carefully as their value may impact the resulting channel network.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_selecting_a_window_size">8. Selecting A Window Size</h2>
<div class="sectionbody">
<div class="paragraph">
<p>These instructions will take you through the steps needed to identify the correct
window radius to use in the surface fitting routines, following
the techniques published in <a href="http://www.sciencedirect.com/science/article/pii/S0012821X10004784">Roering et al. (2010)</a>
and <a href="http://onlinelibrary.wiley.com/doi/10.1029/2011JF002057/full">Hurst et al. (2012)</a>. It
is assumed that you are already comfortable with using LSDTopoTools, and have worked
though the tutorial: <a href="#_first_analysis">First Analysis</a>. This analysis is often a precursor to other
more complex processes, and will ensure that fitted surfaces capture topographic
variations at a meaningful geomorphic scale.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick guide if you already know what you are doing</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Compile the code with: <code>make -f PolyFitWindowSize.make</code></p>
</li>
<li>
<p>Run the program <code>PolyFitWindowSize.out</code> using the path (with trailing slash), the
filename and the file format as arguments.</p>
</li>
<li>
<p>Analyse the resulting data files using the provided python script, <code>Window_Size.py</code>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_overview">8.1. Overview</h3>
<div class="paragraph">
<p>This driver file will run the surface fitting routines at a range of window sizes up to 100 meters, to
produce a series of curvature rasters for the supplied landscape. The mean, interquartile range,
and standard deviation of each curvature raster is calculated and these values are
written to a text file.</p>
</div>
<div class="paragraph">
<p>The resulting text file can then be loaded by the provided python script, <code>Window_Size.py</code>,
which will produce plots of how the mean, interquartile range, and standard deviation
of curvature varies with the surface fitting window size.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">This code will produce</dt>
<dd>
<p>A <code>*.txt</code> file containing the surface statistics for each window size.</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_input_data">8.2. Input Data</h3>
<div class="paragraph">
<p>This driver only requires an input DEM, this file can be at any resolution and must be
in <code>*.bil</code>, <code>flt</code> or <code>asc</code>. format. Guidance on converting data into these formats
can be found in the chapter covering basic <a href="#_gdal">GDAL</a> operations. Note that as data
resolution decreases (i.e. pixel size increases) the ability to resolve individual
hillslopes reduces, and so this technique becomes less important.</p>
</div>
</div>
<div class="sect2">
<h3 id="_compile_the_driver">8.3. Compile The Driver</h3>
<div class="paragraph">
<p>The code is compiled using the provided makefile, <code>PolyFitWindowSize.make</code> and the command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f PolyFitWindowSize.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which will create the binary file, <code>PolyFitWindowSize.out</code> to be executed.</p>
</div>
</div>
<div class="sect2">
<h3 id="_run_the_code">8.4. Run The Code</h3>
<div class="paragraph">
<p>The driver is run with three arguments:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Path</dt>
<dd>
<p>The path pointing to where the input raster file is stored. This is also
where the output data will be written.</p>
</dd>
<dt class="hdlist1">Filename</dt>
<dd>
<p>The filename prefix, without an underscore. If the DEM is called <code>Oregon_DEM.flt</code>
the filename would be <code>Oregon_DEM</code>. This will be used to give the output files a distinct identifier.</p>
</dd>
<dt class="hdlist1">Format</dt>
<dd>
<p>The input file format. Must be either <code>bil</code>, <code>flt</code> or <code>asc</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The syntax on a unix machine is as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./PolyFitWindowSize.out &lt;path to data file&gt; &lt;Filename&gt; &lt;file format&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>And a complete example (your path and filenames may vary):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./PolyFitWindowSize.out /home/s0675405/DataStore/Final_Paper_Data/NC/ NC_DEM flt</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_the_output_data">8.5. The Output Data</h3>
<div class="paragraph">
<p>The final outputs are stored in a plain text file, <code>&lt;Filename&gt;_Window_Size_Data.txt</code>,
which is written to the data folder supplied as an argument.</p>
</div>
<div class="paragraph">
<p>This file contains the data needed to select the correct window size. The file has the the
following columns, from left to right:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Length_scale</dt>
<dd>
<p>The window size used in the surface fitting routines to generate
this row of data.</p>
</dd>
<dt class="hdlist1">Curv_mean</dt>
<dd>
<p>Mean curvature for the landscape.</p>
</dd>
<dt class="hdlist1">Curv_stddev</dt>
<dd>
<p>Standard deviation of curvature for the landscape.</p>
</dd>
<dt class="hdlist1">Curv_iqr</dt>
<dd>
<p>Interquartile range of curvature for the landscape.</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_using_python_to_select_a_window_size">8.6. Using Python To Select A Window Size</h3>
<div class="paragraph">
<p>The latest version of the python scripts which accompany this analysis driver can be found
<a href="https://github.com/sgrieve/GeneralAnalysis">here</a> and provide a complete framework to select
a window size for surface fitting.</p>
</div>
<div class="paragraph">
<p>Once the driver has been run, and the data file, <code>&lt;Filename&gt;_Window_Size_Data.txt</code>,
has been generated, the python script can be executed using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python Window_Size.py &lt;Path&gt; &lt;Data Filename&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The two input arguments are similar to the driver file&#8217;s inputs:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Path</dt>
<dd>
<p>The full path to where the data file is stored, with a trailing slash. E.g.
<code>/home/data/</code>. This is also where the output plot will be written.</p>
</dd>
<dt class="hdlist1">Data Filename</dt>
<dd>
<p>The filename of the data file generated by the driver.
E.g. <code>Orgeon_DEM_Window_Size_Data.txt</code>.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>A complete example (your path and filenames will be different):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python Window_Size.py /home/data/ Oregon_DEM_Window_Size_Data.txt</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plot generated by the python script can be interpreted to select a valid window
size for the surface fitting routine. For discussions about this technique refer to
<a href="http://www.sciencedirect.com/science/article/pii/S0012821X10004784">Roering et al. (2010)</a>
and <a href="http://onlinelibrary.wiley.com/doi/10.1029/2011JF002057/full">Hurst et al. (2012)</a>.
The plot generated should look similar to this example taken from the Gabilan Mesa test dataset, available from the ExampleTopoDatasets repository:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/WindowSizeFig.png" alt="Example window size plot">
</div>
</div>
<div class="paragraph">
<p>The plot is divided into three sections. The top plot is the change in the interquartile
range of curvature with window size, the middle plot is the change in mean curvature
with window size and the bottom plot is the change in the standard deviation of
curvature with window size.</p>
</div>
<div class="paragraph">
<p><a href="http://www.sciencedirect.com/science/article/pii/S0012821X10004784">Roering et al. (2010)</a>
and <a href="http://onlinelibrary.wiley.com/doi/10.1029/2011JF002057/full">Hurst et al. (2012)</a>
suggest that a clear scaling break can be observed in some or all of these three plots,
which characterizes the transition from a length scale which captures meter-scale features
such as tree throw mounds to a length scale which corresponds to individual hillslopes.</p>
</div>
<div class="paragraph">
<p>Care must be taken when using this technique as it is challenging to differentiate between measurement noise
and topographic roughness (e.g. tree throw mounds) in data if the shot density of the point cloud
from which the DEM is generated it too low or it has been poorly gridded. Pay close attention
to the metadata provided with your topographic data. If none is provided this is probably a bad sign!</p>
</div>
<div class="paragraph">
<p>In our example, a length scale of between 4 and 8 meters would be appropriate, supported by
the scaling breaks identified in the plots with the red arrows:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/WindowSizeFigAnnotated.png" alt="Example window size plot">
</div>
</div>
<div class="paragraph">
<p>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_extracting_hillslope_lengths">9. Extracting Hillslope Lengths</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section gives an overview of how to use the hillslope length driver (<strong>LH_Driver.cpp</strong>)
and it&#8217;s companion (<strong>LH_Driver_RAW.cpp</strong>) to quickly generate hillslope length data for a
series of basins, along with other basin average metrics within a larger DEM file. It
is assumed that you are already comfortable with using LSDTopoTools, and have worked
though the tutorial: <a href="#_first_analysis">First Analysis</a>.</p>
</div>
<div class="paragraph">
<p>For applications considering landscapes at geomorphic (millenial) timescales use the main
driver, for event scale measurements use the RAW driver. All instructions on this page will
work for either driver. For convenience it will refer only to <code>LH_Driver.cpp</code> but either driver
can be used.</p>
</div>
<div class="paragraph">
<p>This code is used to to produce the data for Grieve et al. (in review.).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick guide if you already know what you are doing</div>
<div class="paragraph">
<p>Here is a quick overview of how to set up and run the code, if you have done it before:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Generate a channel head file for the landscape.</p>
</li>
<li>
<p>Get the window size for the surface fitting routines.</p>
</li>
<li>
<p>Compile the code with: <code>make -f LH_Driver.make</code></p>
</li>
<li>
<p>Run the program <code>LH_Driver.out</code> using the path (with trailing slash), the filename prefix, window radius, basin order, a floodplain switch, and a switch to write rasters if desired as arguments.</p>
</li>
<li>
<p>Analyse the resulting data files using python.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_overview_2">9.1. Overview</h3>
<div class="paragraph">
<p>This driver file will combine several LSDTopoTools Functions in order to generate
as complete a range of basin average and hillslope length metrics as possible. The tool will
generate:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>A HilltopData file with metrics calculated for each hilltop pixel which can be routed to a stream pixel.</p>
</li>
<li>
<p>A file containing basin averaged values of hillslope lengths and other standard metrics.</p>
</li>
<li>
<p>An optional collection of trace files, which can be processed to create a shapefile of the trace paths across the landscape.
These can be enabled by setting a flag inside the driver on line 141.</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_input_data_2">9.2. Input Data</h3>
<div class="paragraph">
<p>This driver takes the following input data:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 6. Input data for the hillslope length code</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input data</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Raw DEM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster named <code>&lt;prefix&gt;_DEM.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The raw DEM to be analysed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Channel Heads</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Channel head raster named <code>&lt;prefix&gt;_DEM_CH.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A file containing channel heads, which can be generated using the <a href="http://csdms.colorado.edu/wiki/Model:DrEICH_algorithm">DrEICH algorithm</a>. See the <a href="#Channel Extraction">[Channel Extraction]</a> chapter for more information.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Floodplain Mask</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A binary mask of floodplains named <code>&lt;prefix&gt;_FloodPlain.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Floodplain data which can be used to ensure that analysis only occurs on the
hillslopes. This is an optional input.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Surface Fitting Window Size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The surface fitting window size can be constrained using the steps outlined in <a href="#_selecting_a_window_size">Selecting A Window Size</a>. This should be performed to ensure the
correct parameter values are selected.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_compile_the_driver_2">9.3. Compile The Driver</h3>
<div class="paragraph">
<p>The code is compiled using the provided makefile, <code>LH_Driver.make</code> and the command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f LH_Driver.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which will create the binary file, <code>LH_Driver.out</code> to be executed.</p>
</div>
</div>
<div class="sect2">
<h3 id="_run_the_hillslope_length_driver">9.4. Run The Hillslope Length Driver</h3>
<div class="paragraph">
<p>The driver is run with six arguments:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Path</dt>
<dd>
<p>The data path where the channel head file and DEM is stored. The output data
will be written here too.</p>
</dd>
<dt class="hdlist1">Prefix</dt>
<dd>
<p>The filename prefix, without an underscore. If the DEM is called <code>Oregon_DEM.flt</code>
the prefix would be <code>Oregon</code>. This will be used to give the output files a distinct identifier.</p>
</dd>
<dt class="hdlist1">Window Size</dt>
<dd>
<p>Radius in spatial units of kernel used in surface fitting. Selected using window_size.</p>
</dd>
<dt class="hdlist1">Stream Order</dt>
<dd>
<p><a href="http://en.wikipedia.org/wiki/Strahler_number">The Strahler number</a> of basins to be extracted. Typically
a value of 2 or 3 is used, to ensure a good balance between sampling density and basin area.</p>
</dd>
<dt class="hdlist1">Floodplain Switch</dt>
<dd>
<p>If a floodplain raster has been generated it can be added to the
channel network by setting this switch to <code>1</code>. This will ensure that hillslope traces terminate at the hillslope-fluvial
transition. If no floodplain raster is available, or required, this switch should be set to
<code>0</code>.</p>
</dd>
<dt class="hdlist1">Write Rasters Switch</dt>
<dd>
<p>When running this driver several derivative rasters can be generated
to explore the results spatially. If this is required, set this switch to <code>1</code>. To
avoid writing these files set the switch to <code>0</code>. The rasters which will be written are:</p>
<div class="ulist">
<ul>
<li>
<p>A pit filled DEM</p>
</li>
<li>
<p>Slope</p>
</li>
<li>
<p>Aspect</p>
</li>
<li>
<p>Curvature</p>
</li>
<li>
<p>Stream network</p>
</li>
<li>
<p>Drainage basins of the user defined order</p>
</li>
<li>
<p>Hilltop curvature</p>
</li>
<li>
<p>Hillslope length</p>
</li>
<li>
<p>Hillslope gradient, computed as relief/hillslope length</p>
</li>
<li>
<p>Relief</p>
</li>
<li>
<p>A hillshade of the DEM</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The syntax to run the driver on a unix machine is as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./LH_Driver.out &lt;Path&gt; &lt;Prefix&gt; &lt;Window Radius&gt; &lt;Stream order&gt; &lt;Floodplain Switch&gt; &lt;Write Rasters Switch&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>And a complete example (your path and filenames will vary):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./LH_Driver.out /home/s0675405/DataStore/LH_tests/ Oregon 6 2 1 0</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_analysing_the_results">9.5. Analysing The Results</h3>
<div class="paragraph">
<p>The final outputs are stored in two plain text files, which are written to the data
folder supplied as the argument <code>path</code>.</p>
</div>
<div class="sect3">
<h4 id="__prefix_paper_data_txt">9.5.1. &lt;Prefix&gt;_Paper_Data.txt</h4>
<div class="paragraph">
<p>This file contains all of the basin average values for each basin, these files contain
a large number of columns, providing a wealth of basin average data. The columns in the
file, from left to right are as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>BasinID =  Unique ID for the basin.</p>
</li>
<li>
<p>HFR_mean = Mean hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>HFR_median = Median hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>HFR_stddev = Standard deviation of hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>HFR_stderr = Standard error of hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>HFR_Nvalues = Number of values used in hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>HFR_range = Range of hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>HFR_min = Minimum hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>HFR_max = Maximum hilltop flow routing derived hillslope length.</p>
</li>
<li>
<p>SA_binned_LH = Hillslope length from binned slope area plot.</p>
</li>
<li>
<p>SA_Spline_LH = Hillslope length from spline curve in slope area plot.</p>
</li>
<li>
<p>LH_Density = Hillslope length from drainage density.</p>
</li>
<li>
<p>Area = Basin area.</p>
</li>
<li>
<p>Basin_Slope_mean = Mean basin slope.</p>
</li>
<li>
<p>Basin_Slope_median = Median basin slope.</p>
</li>
<li>
<p>Basin_Slope_stddev = Standard deviation of basin slope.</p>
</li>
<li>
<p>Basin_Slope_stderr = Standard error of basin slope.</p>
</li>
<li>
<p>Basin_Slope_Nvalues = Number of basin slope values.</p>
</li>
<li>
<p>Basin_Slope_range = Range of basin slopes.</p>
</li>
<li>
<p>Basin_Slope_min = Minimum basin slope.</p>
</li>
<li>
<p>Basin_Slope_max = Maximum basin slope.</p>
</li>
<li>
<p>Basin_elev_mean = Mean basin elevation.</p>
</li>
<li>
<p>Basin_elev_median = Median basin elevation.</p>
</li>
<li>
<p>Basin_elev_stddev = Standard deviation of basin elevation.</p>
</li>
<li>
<p>Basin_elev_stderr = Standard error of basin elevation.</p>
</li>
<li>
<p>Basin_elev_Nvalues = Number of basin elevation values.</p>
</li>
<li>
<p>Basin_elev_Range = Range of basin elevations.</p>
</li>
<li>
<p>Basin_elev_min = Minimum basin elevation.</p>
</li>
<li>
<p>Basin_elev_max = Maximum basin elevation.</p>
</li>
<li>
<p>Aspect_mean = Mean aspect of the basin.</p>
</li>
<li>
<p>CHT_mean = Mean hilltop curvature of the basin.</p>
</li>
<li>
<p>CHT_median = Median hilltop curvature of the basin.</p>
</li>
<li>
<p>CHT_stddev = Standard deviation of hilltop curvature of the basin.</p>
</li>
<li>
<p>CHT_stderr = Standard error of hilltop curvature of the basin.</p>
</li>
<li>
<p>CHT_Nvalues = Number of hilltop curvature values used.</p>
</li>
<li>
<p>CHT_range = Range of hilltop curvatures.</p>
</li>
<li>
<p>CHT_min = Minimum hilltop curvature in the basin.</p>
</li>
<li>
<p>CHT_max = Maximum hilltop curvature in the basin.</p>
</li>
<li>
<p>EStar = \(E*\) value from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>.</p>
</li>
<li>
<p>RStar = \(R*\) value from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>.</p>
</li>
<li>
<p>HT_Slope_mean = Mean slope calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_Slope_median = Median slope calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_Slope_stddev = Standard deviation of slope calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_Slope_stderr = Standard error of slope calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_Slope_Nvalues = Number of slope values calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_Slope_range = Range of slopes calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_Slope_min = Minimum slope calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_Slope_max = Maximum slope calculated using (relief/hillslope length).</p>
</li>
<li>
<p>HT_relief_mean = Mean relief.</p>
</li>
<li>
<p>HT_relief_median = Median relief.</p>
</li>
<li>
<p>HT_relief_stddev = Standard deviation of relief.</p>
</li>
<li>
<p>HT_relief_stderr = Standard error of relief.</p>
</li>
<li>
<p>HT_relief_Nvalues = Number of relief values used.</p>
</li>
<li>
<p>HT_relief_range = Range of reliefs.</p>
</li>
<li>
<p>HT_relief_min = Minimum relief.</p>
</li>
<li>
<p>HT_relief_max = Maximum relief.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This file can be loaded and the data visualized using
<a href="http://github.com/sgrieve/LH_Paper_Plotting/tree/master/Analysis_Code">these python scripts</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="__prefix_hilltopdata_csv">9.5.2. &lt;Prefix&gt;_HilltopData.csv</h4>
<div class="paragraph">
<p>This file contains hillslope metrics calculated for every hilltop pixel in the
dataset which was routed successfully to a stream pixel. The columns in the
file, from left to right are as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>X is the x coordinate of the hilltop pixel.</p>
</li>
<li>
<p>Y is the x coordinate of the hilltop pixel.</p>
</li>
<li>
<p>hilltop_id is the value of the hilltop pixel.</p>
</li>
<li>
<p>S is the slope calculated as relief/hillslope length.</p>
</li>
<li>
<p>R is the relief, the change in elevation between the hilltop and the channel</p>
</li>
<li>
<p>Lh is the hillslope flow length.</p>
</li>
<li>
<p>BasinID is the junction outlet number of the basin the hilltop is within.</p>
</li>
<li>
<p>StreamID is the value of the stream pixel reached by the trace.</p>
</li>
<li>
<p>HilltopSlope is the gradient of the pixel hwere the trace started.</p>
</li>
<li>
<p>DivergentCountFlag is the count of divergent pixels crossed. <strong>Depreciated</strong></p>
</li>
<li>
<p>PlanarCountFlag - Count of planar cells crossed <strong>Depreciated</strong></p>
</li>
<li>
<p>E_Star = \(E*\) value from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>.</p>
</li>
<li>
<p>R_Star = \(R*\) value from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>.</p>
</li>
<li>
<p>EucDist - Euclidean length of the trace from hilltop to channel</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This file can be loaded and the data visualized using
<a href="http://github.com/sgrieve/LH_Paper_Plotting/tree/master/Analysis_Code">these python scripts</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_trace_files">9.5.3. Trace Files</h4>
<div class="paragraph">
<p>An optional switch can be set within the code to print out the coordinates of the path
of each trace, allowing hilltop flow paths to be visualized. This option is not exposed at the command line as it will considerably slow the execution of the algorithm.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
This will generate a large number of text files, which some operating systems can struggle to handle.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To enable this feature open the driver file <code>LH_Driver.cpp</code> and find the following parameters which should be located around line 140:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">bool print_paths_switch = false;
int thinning = 1;
string trace_path = "";
bool basin_filter_switch = false;
vector&lt;int&gt; Target_Basin_Vector;</code></pre>
</div>
</div>
<div class="paragraph">
<p>These control the path file printing and give several options to limit the scope of the path printing to ensure a manageable number of files are generated. The possible values for each parameter are:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 7. Path file printing parameters</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>print_paths_switch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Set this to <code>true</code> to print paths and <code>false</code> to not print paths (the default)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>thinning</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The default value of <code>1</code> will keep every trace, whereas any other value will thin the data and write every <code>nth</code> trace to a file.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>trace_path</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The directory that the trace files will be written to, it is <strong>strongly</strong> recommended that this be an empty directory.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>basin_filter_switch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Set this to <code>true</code> if you only want to write trace files contained within traget basins. <code>false</code> will process the whole DEM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Target_Basin_Vector</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Vector of ints</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If <code>basin_filter_switch</code> is set to true, populate this vector with the IDs of the basins to be studied.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Once these parameters have been set, re-compile the driver following the steps in <a href="#_compile_the_driver">Compile The Driver</a> and run the code. Once the code has executed a large number of files will have been generated in the supplied path. They are plain text, space delimited files which have the following headings:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>X Coordinate.</p>
</li>
<li>
<p>Y Coordinate.</p>
</li>
<li>
<p>Count of divergent pixels crossed during the trace.</p>
</li>
<li>
<p>Hillslope length.</p>
</li>
<li>
<p>Count of planar pixels crossed during the trace.</p>
</li>
<li>
<p>E_Star from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>.</p>
</li>
<li>
<p>R_Star from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>.</p>
</li>
<li>
<p>Euclidean length of trace.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A python script is provided to process these files into a shapefile, which can be viewed in any GIS package, or plotted using other python scripts provided. The python script to process these files is located <a href="http://github.com/sgrieve/LH_Paper_Plotting/tree/master/Analysis_Code">here</a> and is called <code>trace_process_1_1.py</code>. To run this file, alter the input path to point to where the trace files are stored, and then set the output path to a new directory which must already exist.</p>
</div>
<div class="paragraph">
<p>The line:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">files = files[::100] # only processing every 100th trace for speed</code></pre>
</div>
</div>
<div class="paragraph">
<p>is used to thin the dataset to speed up processing, in case this was not performed earlier. Again, a value of <code>1</code> will keep all of the data, and any other integer will keep every <code>nth</code> file. Once the code has been executed a single shapefile will be produced in the user defined output directory.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_worked_example">9.6. Worked Example</h3>
<div class="paragraph">
<p>In this final section a typical hillslope length analysis will be performed from start to finish to demonstrate how to use this algorithm on real data. For this example we will use a very small section of Gabilan Mesa, to facilitate rapid processing.</p>
</div>
<div class="sect3">
<h4 id="_getting_the_data">9.6.1. Getting the data</h4>
<div class="paragraph">
<p>The data is located in the ExampleTopoDatasets repository. Firstly, we must create a new directory to store our topogrpahic data:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ mkdir data
$ pwd
/home/s0675405/LH/data/</code></pre>
</div>
</div>
<div class="paragraph">
<p>We will only take the data we need, which is the Gabilan Mesa DEM and the associated DrEICH channel head file, so we can use wget to download the data:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan.bil
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan.hdr
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan_CH.bil
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan_CH.hdr</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should now have the following files in your data folder:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/s0675405/LH/data/
$ ls
gabilan.bil  gabilan_CH.bil  gabilan_CH.hdr  gabilan.hdr</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_getting_the_code">9.6.2. Getting The Code</h4>
<div class="paragraph">
<p>Next we need to download the code from the CSDMS repository where the latest stable version of the hilltop flow routing algorithm is located. This can again be downloaded using wget and it will come as a zipfile, which should be extracted into a separate folder to the data:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/csdms-contrib/Hilltop_flow_routing/archive/master.zip
$ unzip master.zip</code></pre>
</div>
</div>
<div class="paragraph">
<p>Finally we need to get the visualization python scripts so we can explore the data:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/sgrieve/LH_Paper_Plotting/archive/master.zip
$ unzip master.zip</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we should have 3 folders, one with the data, one with the main c++ code and a third with the python code.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ls
data  Hilltop_flow_routing-master  LH_Paper_Plotting-master</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_running_the_code">9.6.3. Running The Code</h4>
<div class="paragraph">
<p>We need to check that the filenames for our input and output data make sense in the <code>LH_Driver.cpp</code> file. Open the file in a text editor and look at the line which loads the DEM:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">LSDRaster DEM((path+filename+"_dem"), "flt");</code></pre>
</div>
</div>
<div class="paragraph">
<p>We are working with <code>bil</code> files, so need to change the <code>"flt"</code> to <code>"bil"</code>, which can be done with a simple search and replace within your text editor.</p>
</div>
<div class="paragraph">
<p>The code also expects our data to be tagged <code>*_dem</code> so lets rename our data files to make life simpler:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/s0675405/LH/data
$ mv gabilan.bil gabilan_dem.bil
$ mv gabilan.hdr gabilan_dem.hdr
$ mv gabilan_CH.bil gabilan_dem_CH.bil
$ mv gabilan_CH.hdr gabilan_dem_CH.hdr
$ ls
gabilan_dem.bil  gabilan_dem_CH.bil  gabilan_dem_CH.hdr  gabilan_dem.hdr</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we can navigate back to the directory where the driver and makefile are stored and make the driver:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/s0675405/LH/Hilltop_flow_routing-master/driver_functions_GrieveLH2015
$ make -f LH_Driver.make
g++ -c -Wall -O3 -pg -g ../LSDParticle.cpp -o ../LSDParticle.o
g++ -c -Wall -O3 -pg -g ../LSDCRNParameters.cpp -o ../LSDCRNParameters.o
g++ -Wall -O3 -pg -g LH_Driver.o ../LSDMostLikelyPartitionsFinder.o ../LSDIndexRaster.o ../LSDRaster.o ../LSDFlowInfo.o ../LSDJunctionNetwork.o ../LSDIndexChannel.o ../LSDChannel.o ../LSDStatsTools.o ../LSDBasin.o ../LSDShapeTools.o ../LSDParticle.o ../LSDCRNParameters.o -o LH_Driver.out</code></pre>
</div>
</div>
<div class="paragraph">
<p>Some warnings may appear which can be ignored as long as the final few lines look something like they do above and the file <code>LH_Driver.out</code> is created.</p>
</div>
<div class="paragraph">
<p>The binary file can then be run using the desired input arguments</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./LH_Driver.out /home/s0675405/LH/data/ gabilan 5 2 0 0</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once the code is completed it will print some data to the screen about the success rate of the traces. Due to the nature of real topography there will always be a small number of failed traces, traces which hit the edge of the DEM should also be rare, but these are excluded from analysis as they are truncated. If these values are very large relative to the stream count, which denotes traces which have successfully completed, there may be a problem with your input data. In the case of this worked example we get the following results:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">Hilltop count: 2170
Stream count: 2157
Fail count: 7
Uphill count: 0
Edge count: 6</code></pre>
</div>
</div>
<div class="paragraph">
<p>Returning to the data folder we can see the the two data files described earlier in this chapter have been written.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/s0675405/LH/data
$ ls
gabilan_dem.bil     gabilan_dem_CH.hdr  gabilan_dreich__HilltopData.csv
gabilan_dem_CH.bil  gabilan_dem.hdr     gabilan_dreich_PaperData.txt</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_plotting_data">9.6.4. Plotting Data</h4>
<div class="paragraph">
<p>We can now load the data files into the python scripts to visualize the data. Firstly, we can make a histogram to view the distribution of hillslope length values for our landscape using the <code>RAW_LH_Hist.py</code> script. We need to update the plotting parameters to reflect our data, the following lines can be edited within the script using any text editor:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">#================ modifyable parameters start here ====================

#paths to the data and to save the figure to
path = '../../data/' #path to the folder contaning the hilltopdata files
filename = 'gabilan_dreich__HilltopData.csv'
figpath = path #path to save the final figures

#plot style parameters
xmax = 400
ymax = 40
xstep = 50
ystep = 10
title_move = 0.

#plot labels
location = 'Gabilan Mesa'

#================ modifyable parameters end here ====================</code></pre>
</div>
</div>
<div class="paragraph">
<p>The plot style parameters require a bit of trial and error to get the the correct axis limits, so the code may need to be executed several times. Once the parameters have been set the script can be run at the command line:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">python RAW_LH_Hist.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which produces a histogram within the data folder.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/LH_Hist_Raw.png" alt="Hillslope length histogram">
</div>
</div>
<div class="paragraph">
<p>This process can be repeated to run any of the plotting scripts provided with this package, as each has a similar interface.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_7">9.7. Summary</h3>
<div class="paragraph">
<p>You should now be able to generate hillslope length data from high resolution topography.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_dimensionless_erosion_and_relief">10. Dimensionless Erosion and Relief</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The relationship between topographic relief and erosion rate can be used to interrogate dynamic forces which interact to shape the Earth&#8217;s surface. Roering et al. (2007) formulated a dimensionless relationship between relief (R*) and erosion rate (E*) which allows comparisons between landscapes of vastly differing forms. Hurst et al. (2013) used this technique to identify topographic uplift and decay along the Dragons Back Pressure Ridge, CA. However, in spite of its utility, it has always been a challenging method to implement. In this chapter we go through the steps required to generate E* R* data using <a href="https://lsdtopotools.github.io/">LSDTopoTools</a> from high resolution topography at a range of spatial scales, following Grieve et al. (2015).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick guide if you already know what you are doing</div>
<div class="paragraph">
<p>Here is a quick overview of how to set up and run the code, if you have done it before:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Generate a channel head file for the landscape.</p>
</li>
<li>
<p>Run the hillslope lenth driver, following the  <a href="#_extracting_hillslope_lengths">Extracting Hillslope Lengths</a> chapter.</p>
</li>
<li>
<p>Compile the code with: <code>make -f E_STAR_R_STAR.make</code></p>
</li>
<li>
<p>Run the program <code>E_STAR_R_STAR.out</code> using the path (with trailing slash), the filename prefix, the minimum patch area in pixels, the minimum number of data points per basin and the basin order.</p>
</li>
<li>
<p>Analyze the resulting data files using <code>Plot_ER_Data.py</code>.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_get_the_code_for_dimensionless_erosion_and_relief_analysis">10.1. Get the code for dimensionless erosion and relief analysis</h3>
<div class="paragraph">
<p>Our code for E*R* analysis can be found in our GitHub repository.  This repository contains code for extracting channel networks, generating hillslope length data and processing this topographic data into a form which can be used to generate E* R* relationships.</p>
</div>
<div class="sect3">
<h4 id="_clone_the_github_repository_2">10.1.1. Clone the GitHub repository</h4>
<div class="paragraph">
<p>First navigate to the folder where you will keep the GitHub repository.  In this example it is called <code>/home/LSDTT_repositories</code>.  To navigate to this folder in a UNIX terminal use the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd /home/LSDTT_repositories/</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can use the command <code>pwd</code> to check you are in the right folder.  Once you are in this folder, you can clone the repository from the <a href="https://github.com">GitHub website</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ git clone https://github.com/LSDtopotools/LSDTT_Hillslope_Analysis.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>Navigate to this folder again using the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd LSDTT_Hillslope_Analysis/</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_alternatively_get_the_zipped_code_2">10.1.2. Alternatively, get the zipped code</h4>
<div class="paragraph">
<p>If you don&#8217;t want to use <em>git</em>, you can download a zipped version of the code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ wget https://github.com/LSDtopotools/LSDTT_Hillslope_Analysis/archive/master.zip
$ gunzip master.zip</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="https://github.com">GitHub</a> zips all repositories into a file called <code>master.zip</code>,
so if you previously downloaded a zipper repository this will overwrite it.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_get_the_python_code">10.1.3. Get the Python code</h4>
<div class="paragraph">
<p>In addition to the topographic analysis code, some python code is provided to handle the generation of the E* R* data and its visualization. This code is stored in a separate <a href="https://github.com">GitHub</a> repository which can be checked out in the same manner as before. It is a good idea to place the python code into a separate directory to avoid confusion later on.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ git clone https://github.com/sgrieve/ER_Star.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>Navigate to this folder again using the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd ER_STAR/</code></pre>
</div>
</div>
<div class="paragraph">
<p>or if you prefer to avoid <em>git</em>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ wget https://github.com/LSDtopotools/LSDTopoTools_ER_STAR/archive/master.zip
$ gunzip master.zip</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The python code has a number of dependences which you should check prior to trying to run the code, as it could give confusing error messages.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_checking_your_python_package_versions">10.1.4. Checking your Python package versions</h4>
<div class="paragraph">
<p>For the code to run correctly the following packages must be installed with a version number greater than or equal to the version number listed below. The code has only been tested on Python 2.7 using the listed versions of these packages, so if you experience unexpected behavior on a higher version, try installing the specified version.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">matplotlib</dt>
<dd>
<p>Version 1.43</p>
</dd>
<dt class="hdlist1">numpy</dt>
<dd>
<p>Verision 1.9.2</p>
</dd>
<dt class="hdlist1">scipy</dt>
<dd>
<p>Version 0.16.0</p>
</dd>
<dt class="hdlist1">uncertainties</dt>
<dd>
<p>Version 2.4.6</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>To test if you have a package installed, launch python at the terminal and try to import each package in turn. For example, to test if we have numpy installed:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python
Python 2.7.6 (default, Jun 22 2015, 18:00:18)
[GCC 4.8.2] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import numpy
&gt;&gt;&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>If importing the package does nothing, that means it has worked, and we can now check the version of numpy</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">&gt;&gt;&gt; numpy.__version__
&gt;&gt;&gt; '1.9.2'</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this case my version of numpy is new enough to run <code>Plot_ER_Data.py</code> without any problems. Repeat this test for each of the 4 packages and if any of them are not installed or are too old a version, it can be installed by using <code>pip</code> at the unix terminal or upgraded by using the <code>--upgrade</code> switch.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo pip install &lt;package name&gt;
$ sudo pip install --upgrade &lt;package name&gt;</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_get_the_example_datasets_2">10.1.5. Get the example datasets</h4>
<div class="paragraph">
<p>We have provided some example datasets which you can use in order to test this algorithm. In this tutorial we will work using a LiDAR dataset and accompanying channel heads from Gabilan Mesa, California. You can get it from our ExampleTopoDatasets repository using <code>wget</code> and we will store the files in a folder called <code>data</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/data
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan.bil
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan.hdr
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan_CH.bil
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/gabilan_CH.hdr</code></pre>
</div>
</div>
<div class="paragraph">
<p>This dataset is already in the preferred format for use with LSDTopoTools (the ENVI <code>bil</code> format). However the filenames are not structured in a manner which the code expects. Both the hillslope length driver and the E*R* driver expect files to follow the format <code>&lt;prefix&gt;_&lt;filetype&gt;.bil</code> so we should rename these four files to follow this format.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/so675405/data
$ mv gabilan.bil gabilan_DEM.bil
$ mv gabilan.hdr gabilan_DEM.hdr
$ mv gabilan_CH.bil gabilan_DEM_CH.bil
$ mv gabilan_CH.hdr gabilan_DEM_CH.hdr
$ ls
gabilan_DEM.bil  gabilan_DEM_CH.bil  gabilan_DEM_CH.hdr  gabilan_DEM.hdr</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now the prefix for our data is <code>gabilan</code> and we are ready to look at the code itself.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_processing_high_resolution_topography">10.2. Processing High Resolution Topography</h3>
<div class="paragraph">
<p>The generation of E* R* data is built upon the ability to measure hillslope length and relief as spatially continuous variables across a landscape. This is performed by using the hillslope length driver outlined in the <a href="#_extracting_hillslope_lengths">Extracting Hillslope Lengths</a> chapter.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
When running the hillslope length driver, ensure that the switch to write the rasters is set to <code>1</code> as these rasters are required by the <code>E_STAR_R_STAR.cpp</code> driver.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This driver performs the hilltop segmentation and data averaging needed to generate E* R* data at the scale of individual hilltop pixels, averaged at the hillslope scale and at a basin average scale.</p>
</div>
</div>
<div class="sect2">
<h3 id="_input_data_3">10.3. Input Data</h3>
<div class="paragraph">
<p>This driver takes the following input data:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 8. Input data for the <code>E_STAR_R_STAR.cpp</code> driver.</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input data</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Raw DEM</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster named <code>&lt;prefix&gt;_DEM.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The raw DEM to be analysed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hillslope length raster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster named <code>&lt;prefix&gt;_HFR_LH.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster of hillslope length measurements generated by <code>LH_Driver.cpp</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Topographic relief raster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster named <code>&lt;prefix&gt;_Relief.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster of topographic relief measurements generated by <code>LH_Driver.cpp</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hilltop curvature raster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster named <code>&lt;prefix&gt;_CHT.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster of hilltop curvature measurements generated by <code>LH_Driver.cpp</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Slope raster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster named <code>&lt;prefix&gt;_Slope.flt</code>.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster of topographic gradient generated by <code>LH_Driver.cpp</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum Patch Area</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum number of pixels required for a hilltop to be used for spatial averaging.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum Number of Basin Data Points</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum number of data points required for each basin average value to be computed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Basin Order</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="http://en.wikipedia.org/wiki/Strahler_number">The Strahler number</a> of basins to be extracted. Typically
a value of 2 or 3 is used, to ensure a good balance between sampling density and basin area.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_compile_the_driver_3">10.4. Compile The Driver</h3>
<div class="paragraph">
<p>Once you have generated the hillslope length data you must compile the <code>E_STAR_R_STAR.cpp</code> driver. This is performed by using the provided makefile, <code>LH_Driver.make</code> and the command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f E_STAR_R_STAR.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>Which will create the binary file, <code>E_STAR_R_STAR.out</code> to be executed.</p>
</div>
</div>
<div class="sect2">
<h3 id="_run_the_code_2">10.5. Run the code</h3>
<div class="paragraph">
<p>Once the driver has been compiled it can be run using the following arguments:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Path</dt>
<dd>
<p>The data path where the input data files are stored. The output data will be written here too.</p>
</dd>
<dt class="hdlist1">Prefix</dt>
<dd>
<p>The filename prefix, without an underscore. If the DEM is called <code>Oregon_DEM.flt</code>
the prefix would be <code>Oregon</code>. This will be used to give the output files a distinct identifier.</p>
</dd>
<dt class="hdlist1">Minimum Patch Area</dt>
<dd>
<p>The minimum number of pixels required for a hilltop to be used for spatial averaging.</p>
</dd>
<dt class="hdlist1">Minimum Number of Basin Data Points</dt>
<dd>
<p>The minimum number of data points required for each basin average value to be computed.</p>
</dd>
<dt class="hdlist1">Basin Order</dt>
<dd>
<p><a href="http://en.wikipedia.org/wiki/Strahler_number">The Strahler number</a> of basins to be extracted. Typically
a value of 2 or 3 is used, to ensure a good balance between sampling density and basin area.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>In our example we must navigate to the directory where the file was compiled and run the code, providing the five input arguments:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/ER_Code_Package/Drivers
$ ./E_STAR_R_STAR.out /home/data/ gabilan 50 50 2</code></pre>
</div>
</div>
<div class="paragraph">
<p>A more general example of the input arguments would is:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./E_STAR_R_STAR.out &lt;path to data files&gt; &lt;filename prefix&gt; &lt;min. patch area&gt; &lt;min. basin pixels&gt; &lt;basin order&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once the code has run, it will produce 5 output files, tagged with the input filename prefix. In the case of our example, these files are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>gabilan_E_R_Star_Raw_Data.csv</p>
</li>
<li>
<p>gabilan_E_R_Star_Patch_Data.csv</p>
</li>
<li>
<p>gabilan_E_R_Star_Basin_2_Data.csv</p>
</li>
<li>
<p>gabilan_Patches_CC.bil</p>
</li>
<li>
<p>gabilan_Patches_CC.hdr</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The three <code>.csv</code> files are the data files containing the raw, hilltop patch and basin average data which is used by <code>Plot_ER_Data.py</code> to generate the E* R* results. The <code>.bil</code> and accompanying <code>.hdr</code> files contain the hilltop network used for the spatial averaging of the data, with each hilltop coded with a unique ID. This can be used to check the spatial distribution of hilltops across the study site.</p>
</div>
</div>
<div class="sect2">
<h3 id="_analyzing_dimensionless_relationships">10.6. Analyzing Dimensionless Relationships</h3>
<div class="paragraph">
<p>Once the code has been run and the data has been generated, it can be processed using the Python script <code>Plot_ER_Data.py</code> which was downloaded into the directory:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/ER_Star
$ ls
bin_data.py  Plot_ER_Data.py  Settings.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>The three Python files are all needed to perform the E* R* analysis. The main code is contained within <code>Plot_ER_Data.py</code> and it makes use of <code>bin_data.py</code> to perform the binning of the data. The file <code>Settings.py</code> is the file that users should modify to run the code on their data.</p>
</div>
<div class="paragraph">
<p><code>Settings.py</code> is a large parameter file which must be modified to reflect our input data and the nature of the plots we want to generate. Each parameter is described within the file, but these descriptions are also produced here for clarity. It should be noted that a useful method for managing large sets of data and plotting permutations is to generate several <code>Settings.py</code> files and swapping between them as needed. The following tables outline all of the parameters which can be used to configure the E* R* plots.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 9. Paramter information to load data.</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter Name</th>
<th class="tableblock halign-left valign-top">Possible Values</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Path</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any valid path</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be wrapped in quotes with a trailing slash eg 'home/user/data/'</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Prefix</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Filename prefix</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Must be wrapped in quotes and match the prefix used in <code>ER_STAR.cpp</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Order</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Basin order used in <code>ER_STAR.cpp</code> to extract the drainage basins. eg 1,2,5</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 10. Options to select data to be plotted</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter Name</th>
<th class="tableblock halign-left valign-top">Possible Values</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RawFlag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 or 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Use 1 to plot the raw data and 0 to not plot it.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DensityFlag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Use 0 to not plot the raw data as a density plot and 1 to plot a density plot. Values greater than 1 will be used the thin the data. For example 2 will plot every second point. Reccommended!</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BinFlag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'raw', 'patches' or ''</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Use 'raw' to bin the raw data, 'patches' to bin the hilltop patch data and an empty string, '' to not perform binning. Note that quotes are needed for all cases.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NumBins</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of bins to be generated. Must be an integer. eg 5,11,20. Will be ignored if <code>BinFlag</code> is left blank.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MinBinSize</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum number of data points required for a bin to be valid. eg 5,20,100. Will be ignored if <code>BinFlag</code> is left blank.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PatchFlag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 or 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Use 1 to plot the patch data and 0 to not plot it.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BasinFlag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 or 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Use 1 to plot the basin data and 0 to not plot it.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">LandscapeFlag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0 or 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Use 1 to plot the landscape average data and 0 to not plot it.</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 11. Options controlling the fitting of the critical gradient</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter Name</th>
<th class="tableblock halign-left valign-top">Possible Values</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sc_Method</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A real number or 'raw', 'patches' or 'basins'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Either input a real number eg 0.8,1.2,1.052 to set the Sc value and avoid the fitting of Sc. Or select 'raw','patches' or 'basins' (including the quotes) to use the named dataset to constrain the best fit Sc value through bootstrapping.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NumBootsraps</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Any integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of iterations for the bootstrapping procedure. 10000 is the default, larger values will take longer to process.</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 12. Options controlling the plot style</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Parameter Name</th>
<th class="tableblock halign-left valign-top">Possible Values</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ErrorBarFlag</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True or False</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True to plot errorbars on datapoints, False to exclude them. Errorbars are generated as the standard error unless otherwise stated.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Format</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'png','pdf','ps','eps','svg'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">File format for the output E* R* plots. Must be one of: 'png','pdf','ps','eps','svg', including the quotes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">GabilanMesa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True or False</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True to plot the example data from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>, False to exclude it.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OregonCoastRange</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True or False</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True to plot the example data from <a href="http://www.sciencedirect.com/science/article/pii/S0012821X07006061">Roering et al. (2007)</a>, False to exclude it.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">SierraNevada</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True or False</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True to plot the example data from <a href="http://onlinelibrary.wiley.com/doi/10.1029/2011JF002057/abstract">Hurst et al. (2012)</a>, False to exclude it.</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_density_plot">10.6.1. Density Plot</h4>
<div class="paragraph">
<p>Firstly we will generate a density plot from the raw E* R* data. To do this we must update the path to our data files, the prefix and the basin order so that our files can be loaded. These modifications can be done in any text editor.</p>
</div>
<div class="paragraph">
<p>As we want to display a density plot we must also place a value other than 0 for the <code>DensityFlag</code> parameter, and ensure that all other parameters in the second parameter table are set to 0 or in the case of <code>BinFlag</code>, an empty string ''.</p>
</div>
<div class="paragraph">
<p>We will set the critical gradient to a value of 0.8, to avoid running the bootstrapping calculations. <code>ErrorBarFlag</code> should be set to <code>False</code>, along with the example data options, and the file format can be left as the default value.</p>
</div>
<div class="paragraph">
<p>The below complete settings file has the comments removed for clarity, as these are not needed by the program.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># Parameters to load the data
Path = '/home/s0675405/data/'
Prefix = 'gabilan'
Order = 2

# Options to select data to be plotted
RawFlag = 0
DensityFlag = 1
BinFlag = ''
NumBins = 20
MinBinSize = 100
PatchFlag = 0
BasinFlag = 0
LandscapeFlag = 0

# Options regarding the fitting of the critical gradient
Sc_Method = 0.8
NumBootsraps = 100

# Plot style options
ErrorBarFlag = False
Format = 'png'

# Comparison data to be plotted from the other studies
GabilanMesa = False
OregonCoastRange = False
SierraNevada = False</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once the settings file has been generated, the code can be run from the terminal:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python Plot_ER_Data.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will write a file called <code>gabilan_E_R_Star.png</code> to the data folder, which should look like this:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/gabilan_E_R_Star_density.png" alt="Density plot">
</div>
</div>
<div class="paragraph">
<p>This plot shows the density of the E* R* measurements for this test datatset, the data is quite sparse due to the small size of the input DEM, but the majority of data points still plot close to the steady state curve.</p>
</div>
</div>
<div class="sect3">
<h4 id="_hilltop_patch_plot">10.6.2. Hilltop Patch Plot</h4>
<div class="paragraph">
<p>Having completed the first example plot it becomes very simple to re-run the code to generate different plots. In this example we will plot the hilltop patch data points with error bars. To do this we need to change our settings file as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># Parameters to load the data
Path = '/home/s0675405/data/'
Prefix = 'gabilan'
Order = 2

# Options to select data to be plotted
RawFlag = 0
DensityFlag = 0
BinFlag = ''
NumBins = 20
MinBinSize = 100
PatchFlag = 1
BasinFlag = 0
LandscapeFlag = 0

# Options regarding the fitting of the critical gradient
Sc_Method = 0.8
NumBootsraps = 100

# Plot style options
ErrorBarFlag = True
Format = 'png'

# Comparison data to be plotted from the other studies
GabilanMesa = False
OregonCoastRange = False
SierraNevada = False</code></pre>
</div>
</div>
<div class="paragraph">
<p>This set of parameters generates a small number of hilltop patch data points which plot in similar locations as the raw data.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/gabilan_E_R_Star_patches.png" alt="Patch plot">
</div>
</div>
<div class="paragraph">
<p>To plot the basin average data, the same set of paramters would be used</p>
</div>
</div>
<div class="sect3">
<h4 id="_binned_plot">10.6.3. Binned Plot</h4>
<div class="paragraph">
<p>To bin the raw data, we need to set the <code>BinFlag</code> parameter to 'raw' and select a number of bins to place our data into:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># Parameters to load the data
Path = '/home/s0675405/data/'
Prefix = 'gabilan'
Order = 2

# Options to select data to be plotted
RawFlag = 0
DensityFlag = 0
BinFlag = 'raw'
NumBins = 20
MinBinSize = 100
PatchFlag = 0
BasinFlag = 0
LandscapeFlag = 0

# Options regarding the fitting of the critical gradient
Sc_Method = 0.8
NumBootsraps = 100

# Plot style options
ErrorBarFlag = True
Format = 'png'

# Comparison data to be plotted from the other studies
GabilanMesa = False
OregonCoastRange = False
SierraNevada = False</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this case, the result is fairly meaningless, as most of the bins have too few data points to be plottted, but on larger datasets this method can highlight landscape transience very clearly.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/gabilan_E_R_Star_bins.png" alt="Binned plot">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_fitting_the_critical_gradient">10.6.4. Fitting The Critical Gradient</h4>
<div class="paragraph">
<p>The final example for this section is how to use the code to estimate the critical gradient of a landscape. This is performed by configuring the bootstrapping parameters and in this case we will use the patch data and 1000 iterations to compute the best fit critical gradient.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># Parameters to load the data
Path = '/home/s0675405/data/'
Prefix = 'gabilan'
Order = 2

# Options to select data to be plotted
RawFlag = 0
DensityFlag = 0
BinFlag = ''
NumBins = 20
MinBinSize = 100
PatchFlag = 1
BasinFlag = 0
LandscapeFlag = 0

# Options regarding the fitting of the critical gradient
Sc_Method = 'patches'
NumBootsraps = 1000

# Plot style options
ErrorBarFlag = True
Format = 'png'

# Comparison data to be plotted from the other studies
GabilanMesa = False
OregonCoastRange = False
SierraNevada = False</code></pre>
</div>
</div>
<div class="paragraph">
<p>It should be noted that on a small dataset such as this the fitting will not be very robust as there are too few data points, but this example should demonstrate how to run the code in this manner on real data. The best fit critical gradient will be printed at the top of the final plot.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/gabilan_E_R_Star_fit.png" alt="Best fit plot">
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_8">10.7. Summary</h3>
<div class="paragraph">
<p>By now you should be able to generate dimensionless erosion rate and relief data from high resolution topography.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_chi_analysis">11. Chi analysis</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In the late 1800s, <a href="https://en.wikipedia.org/wiki/Grove_Karl_Gilbert">G.K. Gilbert</a> proposed that bedrock channel incision should be proportional to topographic gradients and the amount of water flowing in a channel.</p>
</div>
<div class="quoteblock">
<div class="title">From <a href="https://pubs.er.usgs.gov/publication/70039916">The USGS report on the Geology of the Henry Mountains</a></div>
<blockquote>
We have already seen that erosion is favored by declivity. Where the declivity is great the agents of erosion are powerful; where it is small they are weak; where there is no declivity they are powerless. Moreover it has been shown that their power increases with the declivity in more than simple ratio.
</blockquote>
<div class="attribution">
&#8212; G.K. Gilbert<br>
<cite>Geology of the Henry Mountains 1877</cite>
</div>
</div>
<div class="paragraph">
<p>Since then, many geomorpholgists have attempted to extract information about erosion rates from channel profiles.
Chi analysis is a method of extracting information from channel profiles that attempts to compare channels with different discharges first proposed by Leigh Royden and colleagues at MIT.
<a href="https://lsdtopotools.github.io/">LSDTopoTools</a> has a number of tools for performing chi analysis.</p>
</div>
<div class="paragraph">
<p>This document gives instructions on how to use the segment fitting tool for channel profile analysis
developed by the Land Surface Dynamics group at the University of Edinburgh.
The tool is used to examine the geometry of channels using the integral method of channel profile analysis.
For background to the method, and a description of the algorithms, we refer the reader to
<a href="http://www.http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract">Mudd et al. (2014)</a>.
For background into the strengths of the integral method of channel profile analysis,
the user should read <a href="http://mit.edu/perron/www/files/PerronRoyden13.pdf">Perron and Royden (2013, ESPL)</a>.</p>
</div>
<div class="paragraph">
<p>This document guides the user through the installation process, and explains how to use the model.
You will need a C++ compiler for this tutorial. If you have no idea what a C++ compiler is, see the appendix.
Visualisation of the model results is performed using Python scripts. We recommend installing
<a href="https://code.google.com/p/pythonxy/">Python(x,y)</a> or <a href="https://www.continuum.io/downloads">Anaconda</a>
and running the scripts within Spyder (which is installed with Python(x,y) and Anaconda).</p>
</div>
<div class="paragraph">
<p>Both the recommended compiler and Python are <strong>open source</strong>: you do not need to buy any
3rd party software (e.g., Matlab) to run our topographic analysis!</p>
</div>
<div class="sect2">
<h3 id="_background_to_chi_analysis">11.1. Background to chi analysis</h3>
<div class="paragraph">
<p>Chi analysis, or \(\chi\) analysis, is a means of normalizing channel gradient for either drainage area or discharge.</p>
</div>
<div class="paragraph">
<p>Chi analysis is a method for examining channel profiles.
If you are familiar with chi analysis, you can skip ahead to the section <a href="#Get and compile the chi analysis tools">[Get and compile the chi analysis tools]</a>.
This section covers the background to the method, and why it is useful.</p>
</div>
<div class="sect3">
<h4 id="_topographic_expression_of_climate_tectonics_and_lithology">11.1.1. Topographic expression of climate, tectonics, and lithology</h4>
<div class="paragraph">
<p>Sorry the section is under construction! But if you want to read more about chi analysis, have a look at these papers:
<a href="http://web.mit.edu/perron/www/files/PerronRoyden13.pdf">Perron and Royden, 2013</a>;
<a href="http://web.mit.edu/perron/www/files/RoydenPerron13.pdf">Royden and Perron, 2013</a>;
<a href="http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract">Mudd et al., 2014</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_get_the_chi_analysis_tools">11.2. Get the chi analysis tools</h3>
<div class="paragraph">
<p>First navigate to the folder where you will keep your repositories.
In this example, that folder is called <code>/home/LSDTT_repositories</code>.
In a terminal window, go there with the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd /home/LSDTT_repositories/</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can use the <code>pwd</code> command to make sure you are in the correct directory.
If you don&#8217;t have the directory, use <code>mkdir</code> to make it.</p>
</div>
<div class="sect3">
<h4 id="_clone_the_code_from_git_2">11.2.1. Clone the code from Git</h4>
<div class="paragraph">
<p>Now, clone the repository from <a href="https://github.com">GitHub</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ git clone https://github.com/LSDtopotools/LSDTopoTools_ChiMudd2014.git</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_alternatively_get_the_zipped_code_3">Alternatively, get the zipped code</h5>
<div class="paragraph">
<p>If you don&#8217;t want to use <em>git</em>, you can download a zipped version of the code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ wget https://github.com/LSDtopotools/LSDTopoTools_ChiMudd2014/archive/master.zip
$ gunzip master.zip</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="https://github.com">GitHub</a> zips all repositories into a file called <code>master.zip</code>,
so if you previously downloaded a zipper repository this will overwrite it.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compile_the_code_6">11.2.2. Compile the code</h4>
<div class="paragraph">
<p>Okay, now you should have the code. You will still be sitting in the directory
<code>/home/LSDTT_repositories/</code>, so navigate up to the directory <code>LSDTopoTools_ChiMudd2014/driver_functions_MuddChi2014/</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ cd LSDTopoTools_ChiMudd2014
$ cd driver_functions_MuddChi2014</code></pre>
</div>
</div>
<div class="paragraph">
<p>There are a number of makefiles (thse with extension <code>.make</code> in this folder).
These do a number of different things that will be explained later in this chapter.
We will compile them as we go through the various different types of chi analysis.</p>
</div>
</div>
<div class="sect3">
<h4 id="_get_some_example_data">11.2.3. Get some example data</h4>
<div class="paragraph">
<p>We are going to use example data from the Mandakini River in Northern India.
This river was the focus of a study by Rahul Devrani and others, you can find it here:
<a href="http://onlinelibrary.wiley.com/doi/10.1002/2015GL063784/full" class="bare">http://onlinelibrary.wiley.com/doi/10.1002/2015GL063784/full</a> (the paper is open access).</p>
</div>
<div class="paragraph">
<p>Again, we want to make sure our data is arranged somewhere sensible.
Make a directory for datasets and perhaps a folder specific to India.
Again, you don&#8217;t need to follow the same naming conventions as in these examples,
but you will have to remember the directory names!</p>
</div>
<div class="paragraph">
<p>I would open a second terminal window (one should already be open in the <strong>driver_functions_MuddChi2014</strong> folder)
and navigate to the data folder:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd /home/LSDTT_Data/India/</code></pre>
</div>
</div>
<div class="paragraph">
<p>The SRTM data from the catchment is stored on the data repository at GitHub:
<a href="https://github.com/LSDtopotools/ExampleTopoDatasets" class="bare">https://github.com/LSDtopotools/ExampleTopoDatasets</a>.</p>
</div>
<div class="paragraph">
<p>You probably don&#8217;t want to clone this repository since it contains a lot of DEMs,
so why don&#8217;t you just download the relevant files directly:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/Mandakini.bil
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/Mandakini.hdr</code></pre>
</div>
</div>
<div class="paragraph">
<p>We are also going to use a parameter file, which can be grabbed from Github:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/example_parameter_files/Mandakini.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Okay, you are now ready to move on to the examples.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_chi_analysis_part_1_getting_the_channel_profiles">11.3. Chi analysis, part 1: getting the channel profiles</h3>
<div class="paragraph">
<p>Our chi analysis method involves two steps.
The first extracts a channel profile
from a DEM. This processes is separated from the rest of the chi analysis for
memory management reasons:
these steps involve a DEM but once they are completed
chi analysis can proceed with much smaller <code>.chan</code> files</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick guide</div>
<div class="paragraph">
<p>If you already know more or less what you are doing, but need a quick reminder, here are the steps involved:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Download your DEM.</p>
</li>
<li>
<p>Project it into a projected coordinate system (we usually use UTM).</p>
</li>
<li>
<p>Export the DEM in <code>.flt</code> or <code>.bil</code> format. See the section on <a href="#gdal-notes-top">using GDAL</a> .</p>
</li>
<li>
<p>If the programs aren&#8217;t complied, make them with: chi_step1_write_junctions.make and chi_step2_write_channel_file.make</p>
</li>
<li>
<p>Run the program <code>chi1_write_junctions.exe</code> on your DEM.</p>
</li>
<li>
<p>Import the junction raster (<code>*.JI.flt</code>) into a GIS and pick a junction
(this is easiest if you also import the stream order (<code>*_SO.flt</code>) and hillshade (<code>*_HS.flt</code>).</p>
</li>
<li>
<p>Run <code>chi2_write_channel_file.exe</code>  to get the <code>.chan</code> file.
Once you do this you are ready to move on to section two: running the chi analysis!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_overview_3">11.3.1. Overview</h4>
<div class="paragraph">
<p>In this section we will extract a channel network,
and from this channel network we will choose a junction (or junctions)
from which we will run chi analyses.
Later in this chapter we will go over tools for running chi analysis across all the channels in a basin.</p>
</div>
</div>
<div class="sect3">
<h4 id="_running_the_channel_network_extraction">11.3.2. Running the channel network extraction</h4>
<div class="paragraph">
<p>The channel extraction code requires two steps.
In the first step,
the toolkit takes the raw DEM and prints several derived datasets from it.
The main dataset used for the next step is the junction index dataset.
The second step involves selecting a junction from which the chi analysis proceeds.</p>
</div>
<div class="sect4">
<h5 id="_compiling_the_source_code_for_junctions_and_channels">Compiling the source code for junctions and channels</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>This example will use the files that we downloaded in the previous section.
If you have your own files, you will need to substitites the correct file and directory names.</p>
</li>
<li>
<p>Make sure the necessary files are in your directory:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_Data/India/

$ ls
Mandakini.driver  Mandakini.bil  Mandakini.hdr</code></pre>
</div>
</div>
</li>
<li>
<p>The driver file must contain three lines.
The first line is the name of the DEM without the extension.
In this example the name is <code>Mandakini</code>. The next line is a minimum slope for the fill function.
The default is 0.0001.
The third line is the threshold number of pixels that contribute to another pixel before that pixel is considered a channel.
You can play with these numbers a bit, in this example, I have set the threshold to 300
(it is a 90m DEM so in the example the threshold drainage area is 2.5x10<sup>6</sup> m<sup>2</sup>).
Here are the first 3 lines of the file:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">mandakini
0.0001
300</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can check this in Linux with the <code>less</code> command. Just type <code>less Mandakini.drver</code> to see the file and <code>q</code> to quit.</p>
</div>
</li>
<li>
<p>Okay, if you have been following along, you should have two terminal windows open. One should be open in the folder containing your data, and the other should be open in the folder with the source code driver functions.</p>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 13. The two terminal windows</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Data terminal window</th>
<th class="tableblock halign-left valign-top">Source code terminal window</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><div><div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">$ pwd
/home/LSDTT_data/India/
$ ls
Mandakini.driver  Mandakini.bil  Mandakini.hdr</code></pre>
</div>
</div></div></td>
<td class="tableblock halign-left valign-top"><div><div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">$ pwd
/home/LSDTT_repositories/LSDTopoTools_ChiMudd2014/driver_functions_MuddChi2014/
$ ls
chi_get_profiles_driver.cpp
chi_get_profiles.make
chi_m_over_n_analysis_driver.cpp
chi_m_over_n_analysis.make
chi_step1_write_junctions_driver.cpp
chi_step1_write_junctions.make
chi_step2_write_channel_file_discharge.cpp
chi_step2_write_channel_file_discharge.make
chi_step2_write_channel_file_driver.cpp
chi_step2_write_channel_file.make</code></pre>
</div>
</div></div></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>In the source code terminal window, you need to compile two programs (step1 and step2):</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f chi_step1_write_junctions.make
&lt;&lt;Lots of warnings that you can ignore&gt;&gt;
$ make -f chi_step2_write_channel_file.make</code></pre>
</div>
</div>
</li>
<li>
<p>This will make two programs, <strong>chi1_write_junctions.exe</strong> and <strong>chi2_write_channel_file.exe</strong>.
Once you have done this, you need to run the driver program.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_writing_junctions">Writing junctions</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>For writing junctions, the driver program is called <code>chi1_write_junctions.exe</code>.
It takes 2 arguments.
The first is the path name into the folder where your data is stored, and the second is the name of the driver file.
To run the program, just type the program name and then the path name and driver file name.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<strong>The path has to end with a &#8216;/&#8217; symbol</strong>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If you are working in Linux, then the program name should be proceeded with a <code><code>./</code></code> symbol.
Here is a typical example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./chi1_write_junctions.exe /home/LSDTT_data/India/ Mandakini.driver</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
To run the code you need to be in the source code folder containing the <code>.exe</code> file, <strong>NOT</strong> the folder with the data.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>All the output from the software, however, will be printed to the data folder. <strong>That is, the software and data are kept separately.</strong></p>
</div>
</li>
<li>
<p>In later sections you will see that the driver file has the same format for all steps,
but for this step only the first three lines are read.
The driver file has a bunch of parameters that are described later but there is a file in the distribution called <code>Driver_cheat_sheet.txt</code>
that has the details of the parameter values.</p>
</li>
<li>
<p>This is going to churn away for a little while.
If you have used incorrect filenames the code should tell you.
The end result will be a large number of new files: The code prints</p>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 14. Files generated by chi1_write_junctions.exe.</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 80%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">File name contains</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>_fill</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A filled DEM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>_HS</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A hillshade raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>_SO</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster containing the stream orders of the channels.
Pixels that are not streams will have noData.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>_JI</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A raster containing the junction numbers.
You can use a GIS to inspect the junction numbers.
In the next step these numbers will be used to generate channels for analysis.</p></td>
</tr>
</tbody>
</table>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Note that for <code>flt</code> and <code>bil</code> formats each dataset will consist of a <code>bil</code> and a <code>hdr</code> file.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>So your directory will be full of files like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ls
Mandakini.hdr         Mandakini.driver
Mandakini.bil         Mandakini_HS.bil
Mandakini_CP.bil      Mandakini_HS.hdr
Mandakini_CP.hdr      Mandakini_JI.bil
Mandakini_JI.hdr
Mandakini_fill.bil    Mandakini_SO.bil
Mandakini_fill.hdr    Mandakini_SO.hdr</code></pre>
</div>
</div>
</li>
<li>
<p>You will then need to load these files into ArcMap and look at them.
alternative to ArcMap is <a href="http://www.uoguelph.ca/~hydrogeo/Whitebox/">Whitebox</a> which has the advantage of being open source.
<a href="http://www.qgis.org/en/site/">QGIS</a> is another good open source alternative to ArcMap.</p>
</li>
<li>
<p>You want to look at the channel network and junctions.
So at a minimum you should import</p>
<div class="ulist">
<ul>
<li>
<p>the hillshade raster</p>
</li>
<li>
<p>the stream order raster (<code>_SO</code> in filename) and</p>
</li>
<li>
<p>the junction index raster (<code>_JI</code> in filename)</p>
<div class="paragraph">
<p>into your preferred GIS.</p>
</div>
<div class="paragraph">
<p>The stream order raster will display the channel network, with each channel having a stream order.
<strong>The junction index file is the key file, you will need information from this file for the next step.</strong>
In the image below, the channel network is in cool colours and the junctions are in warm colours.
Each junction has a unique integer value, called the junction index.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/Mandakini_stream_network.jpg" alt="Stream network">
</div>
<div class="title">Figure 8. Stream network, with junctions in red and orange pixels</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Now, find the part of the map where you want to do the chi analysis.
You need to choose the junction at the downstream end of the channels where you will do your analysis.
Use the identify tool (it looks like an <code><code>i</code></code> in a blue circle on ArcMap)
to get the number of the junction that you want to use as the lowest junction in the channel network.
In the below image the arrow points to junction number 51.</p>
<div class="imageblock">
<div class="content">
<img src="images/Mandakini_select_junction.jpg" alt="Finding a junction">
</div>
<div class="title">Figure 9. Finding the junction number</div>
</div>
</li>
<li>
<p>Each junction has one and only one receiver junction, whereas it can have multiple donor junctions.
When you choose a junction, the extracted channel traces down to the node one before the receiver junction.
It then traces up the channel network, following the path that leads to the node the furthest flow
distance from the outlet junction. That is, when junctions are reached as the algorithm moves upstream
the upstream channel is determined by flow distance not drainage area. Below we show an image of this.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_extracting_the_code_chan_code_file">Extracting the <code>.chan</code> file</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Now that you have the junction number, you need to run the second program.
Before you run this program, you need to write a file that contains the parameters for the chi analysis.</p>
</li>
<li>
<p><strong>The first 3 lines of this file MUST be the same as the driver file in step 1.</strong>
The code does not check this so you need to make sure on your own this is the case.</p>
</li>
<li>
<p>The next two rows of the driver file are the junction number from which you want to extract the network.
and something that controls how the channel network is "pruned".
This is the ratio in area between the main stem and a tributary that must be exceeded for a tributary to be included in the analysis.
If this number is 1 you only get the main stem.
The smaller the number the more tributaries you get. A reasonable number seems to be <code>~0.02</code>.
Here is an example file:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Mandakini
0.0001
300
51
0.01</code></pre>
</div>
</div>
</li>
<li>
<p>There can be more information in the driver file (for example, parameters for a chi analysis),
but the channel network extraction program will ignore these;
it only looks at the first 5 lines of the driver function.</p>
</li>
<li>
<p>From here you run the program <code>chi2_write_channel_file.exe</code>.
You need to include the path name and the name of the chi parameter file.
In Linux the program should be proceeded with <code>./</code>. Here is an example:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./chi2_write_channel_file.exe /home/smudd/topographic_tools/test_suites/Mandakini/ chi_parameters.driver</code></pre>
</div>
</div>
</li>
<li>
<p>This will generate several files</p>
<div class="paragraph">
<div class="title">Files generated by chi2_write_channel_file.exe.</div>
<p>Note that for <code>flt</code> and <code>bil</code> formats each dataset will consist of a <code>bil</code> and a <code>hdr</code> file.</p>
</div>
</li>
</ol>
</div>
<table class="tableblock frame-all grid-all spread">
<colgroup>
<col style="width: 100%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">File name contains</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Description</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>basin</em></code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Immediately before the <code>.flt</code> extension the junction number will also be listed.
This file is a raster containing the outline of the contributing pixels to the basin
drained by the extracted channel network.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><em>ChanNet</em></code>, with extension <code>chan</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">A hillshade raster. After <code><em>ChanNet</em></code> the basin number will be printed.
This file is used by subsequent chi analysis: that is, further analysis does not involve the DEM,
all of the necessary information is translated into the <code>.chan</code> file.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.csv
This file can be imported into ArcMap or other GIS software.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">This file contain data on the nodes making up the channels in the <code>chan</code> file,
but the csv file can be imported into ArcMap or QGIS.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>+
ArcMap should be able to see the '.csv' file.</p>
</div>
<div class="paragraph">
<p>+
.Adding a csv file in ArcMap
image::images/channel_csv.jpg[Load a csv file]</p>
</div>
<div class="paragraph">
<p>+
If you load this layer and right click on it, you should be able to load the xy data</p>
</div>
<div class="paragraph">
<p>+
.Showing x and y data in ArcMap
image::images/csv_show_xy.jpg[Show xy data in ArcMap]</p>
</div>
<div class="paragraph">
<p>+
Loading the csv file will give you a shapefile with the channel nodes, and loading the <code><em>basin</em></code>
file will give you the basin. Here is the basin and the channel for junction <code>51</code> of the
Mandakini dataset</p>
</div>
<div class="paragraph">
<p>+
.The extraced basin with its channels
image::images/Mandakini_extracted_chan_and_basin.jpg[Channel and basin]</p>
</div>
<div class="paragraph">
<p>+
Note how the channel extends downstream from the selected junction. It stops one node before the
next junction. This way you can get an entire tributary basin that stops one node short of its
confluence with the main stem channel.</p>
</div>
</div>
<div class="sect4">
<h5 id="_format_of_the_chan_file">Format of the .chan file</h5>
<div class="paragraph">
<p>The segment fitting algorithm (see part 2)  works on a "channel" file (we use the extension <code>.chan</code> to denote a channel file).
The channel file starts with six lines of header information that is used to reference the channel to a DEM.
f the channel is not generated from a DEM these six rows can contain placeholder values.
The six rows are:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 15. First six rows of the .chan file.</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 75%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nrows</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">number of rows</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ncols</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">number of columns</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Xllcorner</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">location in the x coordinate of the lower left corner</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Yllcorner</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">location in the y coordinate of the lower left corner</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Node_spacing</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">the spacing of nodes in the DEM</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NoDataVal</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">the value used to indicate no data</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>This header information is not used in the segment analysis;
it is only preserved for channel data to have some spatial reference so that
scripts can be written to merge data from the channel files with DEM data.</p>
</div>
<div class="paragraph">
<p>The rest of the channel file consists of rows with 9 columns.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 16. Chan file contents, the first 6 rows are listed in the table above.</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 60%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Column number</th>
<th class="tableblock halign-left valign-top">paramter name</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Channel number</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">We use C++ style zero indexing so the main stem has channel number 0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Channel number of reciever channel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The reciever channel is the channel into which this channel flows.
The mainstem channel flows into itself, and currently the code can only handle simple geometries
where tributaries flow into the main stem channel only, so this column is always 0.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">node number on the receiver channel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is the node of the reciever channel into which the tributary flows.
Currently the reciever channel must be the main stem (channel 0).
The main stem is defined to flow into itself.
Suppose the main stem has 75 nodes.
The third column would then be 74 for the main stem (because of zero indexing: the first node in the main stem channel is node 0.
Nodes are organized from upstream down, so the most upstream node in the main stem channel is node zero.
Suppose tributary 1 entered the main stem on the 65th node of the main stem.
The third column for tributary 1 would be 64 (again, due to 0 indexing).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">node index on reciever channel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is the node index (generated by the <strong>LSDFlowInfo</strong> object)
of the point on the reciever channel into which this channel flows.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">row</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Row in a DEM the node occupies.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">column</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Column in a DEM the node occupies.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flow distance (metres)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The flow distance from the outlet of the node. It should be in metres.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">elevation (m)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Elevation of the node. It should be in meters.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">9</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Drainage area (m<sup>2</sup>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The drainage area of the node.
It will be in the square of the spatial units of the DEM;
if you have projected into UTM coordinates these will be in metres.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>+
Many of these columns are not used in the analysis but are there to allow the user to refer the channel file back to a DEM.
Columns are separated by spaces so rows will have the format:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">Chan_number receiver_chan receiver_node node_index row col flow_dist elev drainage_area</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here are the first few lines of the example file (<code>Mandakini_ChanNet_51.chan</code>):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">648
587
290249.625
3352521.5
88.81413269
-9999
0 0 271 4864 70 322 71253.0625  4609.008789 3762552.25
0 0 271 4999 71 322 71164.25  4609 3770440.25
0 0 271 5140 72 322 71075.4375  4602 3778328.25
0 0 271 5288 73 322 70986.625  4596 3786216
0 0 271 5444 74 323 70861.02344  4591 3794104
0 0 271 5615 75 323 70772.21094  4574 3928199.25
0 0 271 5799 76 323 70683.39844  4571 3936087.25
0 0 271 5992 77 324 70557.79688  4565 3975527
0 0 271 6190 78 325 70432.19531  4564 3983414.75</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now that you have the <code>.chan</code> file you are ready to move to the next section of the chi analysis:
<a href="#Chi profile analysis">part 2: constraining m/n and transforming profiles</a>.
This may have seen like quite a few steps, but once you get familiar with the workflow the
entire process should take no more than a few minutes.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_chi_profile_analysis_part_2_constraining_m_n_and_transforming_profiles">11.4. Chi profile analysis, part 2: constraining m/n and transforming profiles</h3>
<div class="paragraph">
<p>This is part 2 of the chi profile analysis documentation.
Part 1 can be found here in the section <a href="#_chi_analysis">part 1: getting the channel profiles</a>.
This section of the documentation assumes you have created a <code>.chan</code> file.
The format of the channel file is described in the section <a href="#_format_of_the_chan_file">Format of the .chan file</a>.
These "channel" files contain information about flow distance, elevation
and other properties of a channel network that are used to create a profile
transformed into so-called "chi" (\(\chi\)) space.
The transformation involves integrating drainage area along the length of the channel,
so that comparisons of channel steepness can be made for channels of different drainage area.</p>
</div>
<div class="paragraph">
<p>The analysis is similar to slope-area analysis but has some advantages;
the primary advantage of the method is that it does not take the gradient of noisy topographic data,
and so is less noisy than slope-area analysis.</p>
</div>
<div class="paragraph">
<p>The main disadvantage is that the method assumes channel profiles are well described by
predictions of the stream power erosion law. The various advantages and disadvantages of the method
are described by <a href="http://web.mit.edu/perron/www/files/PerronRoyden13.pdf">Perron and Royden, 2013 ESPL</a>.</p>
</div>
<div class="sect3">
<h4 id="_steps_involved_to_perform_channel_analysis">11.4.1. Steps involved to perform channel analysis</h4>
<div class="paragraph">
<p>After preparing the data (see section <a href="#Chi part 1">[Chi part 1]</a>),
performing the channel analysis involves 3 steps, including visualization of the data.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="#_performing_a_statistical_analysis_to_constrain_the_best_fit_m_n_ratio">Performing a statistical analysis to constrain the best fit m/n ratio</a></p>
</li>
<li>
<p><a href="#_extracting_the_transformed_chi_elevation_profiles">Extracting the transformed chi-elevation profiles</a></p>
</li>
<li>
<p><a href="#_visualizing_the_analysis">Visualizing the analysis</a></p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_performing_a_statistical_analysis_to_constrain_the_best_fit_m_n_ratio">11.4.2. Performing a statistical analysis to constrain the best fit m/n ratio</h4>
<div class="paragraph">
<p>Once the profile data has been converted into a <code>.chan</code> file,
the data can then be processed to determine the most likely m/n ratio for individual channels
and also via the collinearity test (see <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract&gt;">Mudd et al (2014)</a>).</p>
</div>
<div class="sect4">
<h5 id="_compiling_the_code_2">Compiling the code</h5>
<div class="paragraph">
<p>The code for running the statistical analysis to find the most likely m/n ratio can
be compiled by caling the makefile <code>chi_m_over_n_analysis.make</code>.</p>
</div>
<div class="paragraph">
<p>If you are using a windows machine and have installed <a href="http://www.cygwin.com/">Cygwin</a>
you need to ensure that you have installed the make utility.
The below instructions use the linux command prompt symbol (<code>$</code>),
but as long as you have make and a compiler installed on widows these
instructions should also work in a powershell terminal. See the section:
<a href="#_the_terminal_and_powershells">The terminal and powershells</a> for more details.</p>
</div>
<div class="paragraph">
<p>To make the file navigate the folder that contains it and run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f chi_m_over_n_analysis.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will create the program <code>chi_m_over_n_analysis.exe</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_running_the_code_2">Running the code</h5>
<div class="paragraph">
<p>The program 'chi_m_over_n_analysis.exe` is run with 2 arguments to the command line.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The first argument is the path name of the path where the <code>.chan</code> file is located,
along with a driver file that contains the parameters of the analysis.
All data will be printed to files in this path.</p>
</li>
<li>
<p>The second argument is the name of the driver file. We typically use a <code>.driver</code> extension
for the driver file but this is not a requirement.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For example, we call the program with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./chi_m_over_n_analysis.exe /home/smudd/topographic_tools/test_suites/Mandakini/ chi_parameters.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>./</code> leading <code>chi_m_over_n_analysis.exe</code> is only necessary on a linux system.
The driver file contains a number of parameters for running the analysis.
This file is used on several different programs so not all parameters are used by <code>chi_m_over_n_analysis.exe</code>.
The parameters must be listed in the correct order and there cannot be any extra information between parameters
(e.g., a string describing them). The parameters are:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 17. Cheat sheet for driver file</caption>
<colgroup>
<col style="width: 16%;">
<col style="width: 16%;">
<col style="width: 66%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Row number</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The prefix of the channel file</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The original name of the DEM. If your <code>.chan</code> file is called <code>mandakini_ChanNet_21729.chan</code>, then the first row of the driver file should be <code>mandakini</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum slope for fill function</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Not used by <code>chi_m_over_n_analysis.exe</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of contributing pixels for a channel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Not used by <code>chi_m_over_n_analysis.exe</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Junction number of channel.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is the junction number that was specified when the <code>.chan</code> file was created. So if your <code>.chan</code> file is called <code>mandakini_ChanNet_21729.chan</code>, then the fourth row should be <code>21729</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Area fraction for pruning</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Not used by <code>chi_m_over_n_analysis.exe</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(A_0\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A reference drainage area for integrating to chi space (\(m^2\))</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum segment length</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum number of pixels in a segment. See <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract">Mudd et al (2014)</a> for guidance.
Values between 10-20 are recommended.
The computational time required is a highly nonlinear inverse function of this parameter.
20 might lead to a run lasting a few minutes, whereas 5 might take many hours (or even days).
<strong>We recommend starting with a value of 14</strong>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\sigma\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The standard deviation of error on the DEM, and also error from geomorphic noise
(e.g., boulders in the channel). In meters.
See <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract">Mudd et al (2014)</a> paper)
<strong>For SRTM this should be something like 10-30 m.</strong>
The larger this number,
the fewer segments you will get (see <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract">Mudd et al (2014)</a>).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">9</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">starting \(m/n\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The starting m/n value to test the likelihood of.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(\Delta m/n\)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The change in \(m/n\) value that you want to loop over.
For example, suppose the starting \(m/n\) is 0.2
 and the change in \(m/n\)is 0.05,
 then the next \(m/n\) value after 0.2 is 0.25.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">\(n m/n\) values</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of \(m/n\) values you want to loop through.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">12</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Target nodes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The maximum number of nodes you want to run through the partitioning algorithm at a time.
Recommended values are 80-140.
The computational time is nonlinearly related to this parameter,
80 might take several minutes whereas 140 will take many hours, and 200 will take months.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">13</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Monte Carlo iterations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of iterations on the Monte Carlo routine that finds the
statistics for every node in the channel network
 rather than a subset of nodes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">14</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This parameters is legacy.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Not used <code>chi_m_over_n_analysis.exe</code>. One day we will remove this parameter but today is not that day.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">15</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Vertical drop for \(S-A\), in meters</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The vertical drop over which slope-area analysis will be performed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Horizontal drop for \(S-A\), in meters</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The horizontal interval over which slope area analysis will be performed</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">17</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Max change in \(A\) (in \(m^2\))</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The maximum change in drainage area of an interval for slope-area
analysis as a fraction of the area at the midpoint of an interval.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">18</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Target skip</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The "target skip", which is the average number of nodes the routine skips when it is trying to compute the best segments.
If the DEM is 90m resolution, for example, the resolution the algorithm will work at is ~300 meters. Here is an example file:</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>And here is the cheat sheet (also included in <code>driver_cheat_sheet.txt</code>):</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 18. Cheat sheet for driver file</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 80%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Example value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">e_bathdem</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">filename prefix</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">minimum slope, don&#8217;t change</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">300</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N contributing pixels for a channel.
Could reduce to, say 100 or even 50.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1332</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">junction number, this will change</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.05</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">area frac for channel pruning.
1= mainstem only, low numbers= more tribs</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A_0 for chi analysis: probably don&#8217;t need to change.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">20</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">minimum segment length. Should be between 5-20.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">20</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sigma: some estimate of uncertainty in elevation data.
Smaller = more segments</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.15</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">starting m/n for best for m/n testing</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.025</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">increment of m/n for best for m/n testing</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">20</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">number of m/n values tested for m/n testing</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">90</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">target length of nodes to be analy\ed for segments.
Should be between 80-150</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">250</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">number of iterations for Monte Carlo analysis. 250 seems okay</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.95</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Not used anymore!</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">20</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Vertical interval for sampling for S-A analysis.
Should be scaled to DEM resolution</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">500</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Horizontal interval for sampling for S-A analysis.
Should be scaled to DEM resolution</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An area thinning fraction for S-A analysis.
0.2 is probably about right.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The mean number of data nodes you skip for each node of segment analysis.
For LiDAR this can be 10 or more. Nextmap can be 2-10. SRTM 0-2.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Once this program has run, it will print out a file with the filename prefix and an extension of <code>.movern</code>.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
This program is computationally expensive!
Increasing the target length of nodes to be analyzed and reducing the minimum segment length
increases the computational time required in a highly nonlinear fashion.
Increasing the skip value can reduce computational time required.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can expect the computation to take several minutes
(e.g. minimum segment length ~20, target nodes ~100, skip set so mainstem has 300-500 nodes analysed)
to many hours (e.g. minimum segment length of 5, target nodes of 120-140, skip set such that thousands of nodes are analysed).</p>
</div>
</div>
<div class="sect4">
<h5 id="_the_movern_file">The 'movern' file</h5>
<div class="paragraph">
<p>The .movern file is produced by the statistical analysis of the channel network in order to find the most likely m/n ratio.
The filename contains information about parameter values; these are parsed by the visualisation algorithms.
The format of the filename is the filename prefix, followed by <code><em>BFmovern</em></code>, followed by the sigma values,
the skip value, the minimum segment length value the target nodes value and the junction number,
all separated by the underscore symbol (<code>_</code>). The file then has the extension <code>.movern</code>.
For example, the filename:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">mandakini_BFmovern_20_2_20_120_51.movern</code></pre>
</div>
</div>
<div class="paragraph">
<p>Indicates that</p>
</div>
<div class="ulist">
<ul>
<li>
<p>\(\sigma\) = 20</p>
</li>
<li>
<p>skip = 2</p>
</li>
<li>
<p>minimum segment length = 20</p>
</li>
<li>
<p>target nodes = 120</p>
</li>
<li>
<p>and the junction number being analyzed is 51.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The format of the file is:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 19. The format of the .movern file</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 80%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Row</th>
<th class="tableblock halign-left valign-top">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">In the first column of the first row there is a placeholder value,
 <code>-99</code>, followed by the \(m/n\) ratios tested each followed by a space.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">In the first column is a placeholder value,
<code>-99</code>, followed by the mean \(AICc\) (from n_iterations iterations)
for each tested \(m/n\) ratio for the collinearity test. These are separated by spaces.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">In the first column is a place holder value of <code>-99</code>,
followed by the standard deviation of the \(AICc\) for the collinearity test.
When fits are extremely poor, the likelihood approaches zero. Calculating the \(AICc\) involves taking the logarithm of the likelihood,
to avoid this, the code assigns a very small number to 0 likelihoods.
This results in a high, but not infinite, value of \(AICc\).
These poor fits will have a standard deviation of zero.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Even rows thereafter</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The first column is the channel number.
The following columns are the mean \(AICc\) values for that channel.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Odd rows thereafter</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The first column is the channel number.
The following columns are the standard deviations of the \(AICc\) values for that channel.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Here is an example file:</p>
</div>
<div class="listingblock">
<div class="title">An example movern file</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">-99 0.15 0.175
-99 4008 4008
-99 0 0
0 2004 2004
0 0 0
1 2004 2004
1 0 0
2 2004 2004
2 0 0
3 1766.89 1788.39
3 608.033 583.88
4 1905.04 1973.54
4 422.523 238.852
5 2004 2004
5 0 0
6 1975.36 1882.18
6 224.595 450.995</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_performing_a_sensitivity_analysis_on_the_best_fit_m_n_ratio">Performing a sensitivity analysis on the best fit \(m/n\) ratio</h5>
<div class="paragraph">
<p>For structurally or tectonically complex landscapes, it can be difficult to constrain the \(m/n\) ratio.
In such cases, it is wise to perform a sensitivity analysis of the best fit \(m/n\) ratio.
To facilitate this, we provide a python script, <code>movern_sensitivity_driver_generation.py</code>,
that generates a number of driver files with the parameters minimum_segment_length, sigma,
mean_skip and target_nodes that vary systematically.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">To get the python scripts</div>
<div class="paragraph">
<p>Python scripts for automating the code are in a github repository: <a href="https://github.com/LSDtopotools/LSDAutomation" class="bare">https://github.com/LSDtopotools/LSDAutomation</a>
You can either clone this repository (<code>git clone <a href="https://github.com/LSDtopotools/LSDAutomation.git" class="bare">https://github.com/LSDtopotools/LSDAutomation.git</a></code>)
or you can get the scripts directly using wget:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/movern_sensitivity_driver_generation.py</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>To run this script you will need to change the data directory and the filename of the original driver file within the script.</p>
</div>
<div class="paragraph">
<p>You will need to modify the script before you run it. On lines 41 and 43 you need to modify the data directory
and driver name of your files:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># set the directory and filename
DataDirectory =  "/home/smudd/topographic_tools/test_suites/Mandakini/"

DriverFileName = "chi_parameters.driver"</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you are running this file in Spyder from a windows machine, the path name will have slightly different formatting (you will need <code>\\</code> speperators):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python"># set the directory and filename
DataDirectory =  "m:\\topographic_tools\\test_suites\\Mandakini\\"</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you run from the command line you will need to navigate to the folder that contains the script.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The script will generate driver functions with varied skip, sigma, minimum segment length and total nodes values.
These will <strong>NOT</strong> be derived from the driver file you have identified, but rather will be set within the python script.</p>
</div>
<div class="listingblock">
<div class="title">Near the top of movern_sensitivity_driver_generation.py</div>
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">    # these are the number of different parameter values you want to use
    n_skip = 2
    n_sigma = 1
    n_msl = 2
    n_tn = 2

    # this is the starting value of the parameter values
    start_skip = 1
    start_sigma = 3.0
    start_msl = 10
    start_tn = 80

    # these are the change to the parameter value each time you iterate
    d_skip = 1
    d_sigma = 3
    d_msl = 5
    d_tn = 10</code></pre>
</div>
</div>
<div class="paragraph">
<p>The top four variable (that start with <code>n_</code>) tell you how many parameter values you want to loop through,
the next four (<code>start_</code>) dictate where the parameter will start, and the next four (<code>d_</code>) dictate the change in the parameter values.</p>
</div>
<div class="paragraph">
<p>For example, if <code>n_sigma = 3</code>, <code>start_sigma = 5</code> and <code>d_sigma = 4</code>, then the sigma values to be generated in <code>.driver</code> files will be
5, 9, and 13.</p>
</div>
<div class="paragraph">
<p>The driver files will be numbered (e.g., <code>my_driver.1.driver</code>, <code>my_driver.2.driver</code>, etc.):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ls *.driver
chi_parameters.1.driver
chi_parameters.2.driver
chi_parameters.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can run these with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./chi_m_over_n_analysis.exe /home/smudd/topographic_tools/test_suites/Mandakini/ my_driver.1.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or if you want to run them with no hangup and <code>nice</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ nohup nice ./chi_m_over_n_analysis.exe /home/smudd/topographic_tools/test_suites/Mandakini/ my_driver.1.driver &amp;</code></pre>
</div>
</div>
<div class="paragraph">
<p>And then just keep running them in succession until you use up all of your CPUs (luckily at Edinburgh we have quite a few)!</p>
</div>
<div class="paragraph">
<p>We have also written an additional python script called <code>Run_drivers_for_mn.py</code> which simply looks for all the drivers in folder
and sends them to your server. Once again, you&#8217;ll need to modify this python script before you run it in order to
give the script the correct data directory.
In this case the relevant line is line 18:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">DataDirectory =  "/home/smudd/topographic_tools/test_suites/Mandakini/"</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can run it from command line with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python Run_drivers_for_mn.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>Again, you&#8217;ll need to be in the directory holding this file to run it (but it doesn&#8217;t have to be in the same directory as the data).</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
This will send <strong>all</strong> drivers to your servers to be run, so if you generated 1000 drivers, then 1000 jobs will be
sent to the server. Use with caution!
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_extracting_the_transformed_chi_elevation_profiles">Extracting the transformed chi-elevation profiles</h5>
<div class="paragraph">
<p>The next stage of the analysis is to extract the chi (\(\chi\)) profiles.
To compile the program to extract the chi profiles, you need to use the makefile <code>chi_get_profiles.make</code>.
The program is compiled with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f  chi_get_profiles.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>The makefile compiles a program called <code>chi_get_profiles.exe</code>.
This is run, like <code>chi_m_over_n_analysis.exe</code> ,
with two arguments: the path name and the driver name:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./chi_get_profiles.exe /home/smudd/topographic_tools/test_suites/Mandakini/ chi_parameters.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>The driver file has exactly the same format as the driver file for <code>chi_m_over_n_analysis.exe</code>.
A chi profile will be produced for each \(m/n\) value outlined by these elements in the driver file:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>7th row: The starting (lowest) \(m/n\) value to test if it is the most likely.</p>
</li>
<li>
<p>8th row: The change in \(m/n\) value that you want to loop over
(suppose the starting \(m/n\) is 0.2 and the change in \(m/n\) is 0.05,
then the next \(m/n\)  value after 0.2 is 0.25).</p>
</li>
<li>
<p>9th row: The number of \(m/n\) values you want to loop through.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Users may wish to modify these values in the <code>driver</code>
file from the original values to explore only
those values which have "plausible" values of the \(m/n\) ratio
(see <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract">Mudd et al (2014)</a> for guidance).</p>
</div>
<div class="paragraph">
<p>For each \(m/n\) ratio tested, the code produces a file with the extension <code>.tree</code> and the string within the filename <code><em>fullProfileMC_forced</em></code>.
This filename also contains the m/n value so for example a filename might be called:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">pa_basin_fullProfileMC_forced_0.3_5_2_20_100_3124.tree</code></pre>
</div>
</div>
<div class="paragraph">
<p>The numbers in the filename are arranged in the following order:
 \(m/n\) ratio,  \(\sigma\) value, mean skip, minimum segment length and target nodes.
The final number before the extension (here, 3124) is copied from the 4th row of the driver file: it is the <code>junction number</code>.
Users can assign different numbers to different basins to facilitate automation of data analysis.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_the_code_tree_code_file">11.4.3. The <code>.tree</code> file</h4>
<div class="paragraph">
<p>The <code>.tree</code> file has as many rows as there are nodes in the channel network.
There will be more nodes in the <code>.tree</code> file than in the <code>.chan</code> file because the code extends all tributaries to the outlet.
Each row has 23 columns. The columns are</p>
</div>
<div class="ulist">
<ul>
<li>
<p>1st column: The channel number (like in .chan file)</p>
</li>
<li>
<p>2nd column: The receiver channel (like in .chan file)</p>
</li>
<li>
<p>3rd column: The node on receiver channel (like in .chan file)</p>
</li>
<li>
<p>4th column: The node index (like in .chan file)</p>
</li>
<li>
<p>5th column: The row of the node (like in .chan file)</p>
</li>
<li>
<p>6th column: The column of the node (like in the .chan file)</p>
</li>
<li>
<p>7th column: The flow distance of the node</p>
</li>
<li>
<p>8th column: The chi coordinate of the node</p>
</li>
<li>
<p>9th column: The elevation of the node</p>
</li>
<li>
<p>10th column: The drainage area of the node</p>
</li>
<li>
<p>11th column: The number of data points used to calculate node statistics.
Because of the skipping algorithm (see Mudd et al (2013 draft manuscript)) not all nodes are analysed each iteration.</p>
</li>
<li>
<p>12th column: The mean \(M_{\chi}\) value for the node.</p>
</li>
<li>
<p>13th column: The standard deviation of the \(M_{\chi}\)  value for the node.</p>
</li>
<li>
<p>14th column: The standard error of the \(M_{\chi}\)  value for the node.</p>
</li>
<li>
<p>15th column: The mean \(B_{\chi}\)  value for the node.</p>
</li>
<li>
<p>16th column: The standard deviation of the \(B_{\chi}\)  value for the node.</p>
</li>
<li>
<p>17th column: The standard error of the \(B_{\chi}\)  value for the node.</p>
</li>
<li>
<p>18th column: The mean \(DW\) value for the node.</p>
</li>
<li>
<p>19th column: The standard deviation of the \(DW\) value for the node.</p>
</li>
<li>
<p>20th column: The standard error of the \(DW\) value for the node.</p>
</li>
<li>
<p>21st column: The mean fitted elevation for the node.</p>
</li>
<li>
<p>22nd column: The standard deviation of the fitted elevation for the node.</p>
</li>
<li>
<p>23rd column: The standard error of the fitted elevation for the node.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_visualizing_the_analysis">11.4.4. Visualizing the analysis</h4>
<div class="paragraph">
<p>We have also provided python scripts for visualizing the data
(that is "LSDVisualisation": our code uses British spelling).</p>
</div>
<div class="sect4">
<h5 id="_aicc_plotting_py">AICc_plotting.py</h5>
<div class="paragraph">
<p>This script makes a plot of the \(AICc\) as a function of the
\(m/n\) ratio for each channel as well as for the collinearity test.
The mean and standard deviation of the \(AICc\)  is plotted.
In addition the \(m/n\) ratio with the minimum \(AICc\) value is highlighted, and there is a horizontal dashed line
depicting the minimum \(AICc\) value plus the standard deviation of the minimum \(AICc\) value.
This dashed line can help the user determine which
\(m/n\) ratios are plausible
(see <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013JF002981/abstract">Mudd et al (2014)</a>).
Here is an example:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/AICc_plotting.jpg" alt="AICc plot">
</div>
<div class="title">Figure 10. The AICc as a function of m/n. The m/n with the minimum AICc is the most likely m/n</div>
</div>
<div class="paragraph">
<p>To run the <code>AICc_plotting.py</code> script you must modify the path name and filename after line 35 of the script.
The file it takes is a <code>.movern</code> file.</p>
</div>
</div>
<div class="sect4">
<h5 id="_plotting_m_n_sensitivity_aicc_plotting_multiple_py">Plotting m/n sensitivity: AICc_plotting_multiple.py</h5>
<div class="paragraph">
<p>This script looks through a directory (you need to change the DataDirectory variable in the script) for any files with <strong>BFmovern_</strong>.movern
in them and plots the \(AICc\) results.
The code extracts the parameter values from the filename so each plotted figure has the parameter values in the title.
Note that this script plots to file instead of to screen.
You can change the kind of output file by changing the parameter  <code>OutputFigureFormat</code>.
See <a href="http://matplotlib.org/">MatPlotLib documentation</a> for options, but possibilities include <code>jpg</code> and <code>pdf</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_plotting_chi_profiles_and_m_chi_values_code_chi_visualisation_py_code">Plotting chi profiles and \(M_{\chi}\) values <code>chi_visualisation.py</code></h5>
<div class="paragraph">
<p>This script makes three figures.
First, you must define the path name and the filename after line 39 of the script.
This script takes a <code>.tree</code> file. The first figure is a plot of the channels in chi (\(\chi\)) space.
The transformed data is in a semi-transparent solid line and the best fit segments are in dashed lines.
Each tributary is plotted with a different colour.  Here is an example:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/chi_profile.jpg" alt="Chi profiles">
</div>
<div class="title">Figure 11. Profiles of elevation as a function of \(\chi\).</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These examples are derived from numerical model landscapes and are "perfect". Natural channels will be considerably noisier.**
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The second figure generated by this script is a figure showing the gradient in \(\chi\)-elevation space as a function of \(\chi\).
The gradient in \(\chi\)-elevation is indicative of a combination of erosion rate and erodibility,
so these plots allow perhaps a clearer idea of the different segments identified by the segment fitting algorithms.
The colour scheme from the first figure is carried forward, so that it is easy to identify the characteristics of each tributary. Here is an example:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/M_chi.jpg" alt="M_chi">
</div>
<div class="title">Figure 12. A plot of \(M_{\chi}\) as a function of \(\chi\).</div>
</div>
<div class="paragraph">
<p>The third figure displays the longitudinal channel profiles (elevation as a function of flow distance),
but these channel profiles are coloured by the gradient in \(\chi\)-elevation space. Here is an example:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/profile_Mchi_colour.jpg" alt="M_chi distributed">
</div>
<div class="title">Figure 13. A plot of \(M_{\chi}\) in profiles.</div>
</div>
</div>
<div class="sect4">
<h5 id="_plotting_the_sensitivity_of_best_fit_m_n_values_to_parameters_code_bf_movern_sensitivity_py_code">Plotting the sensitivity of best fit \(m/n\) values to parameters: <code>bf_movern_sensitivity.py</code></h5>
<div class="paragraph">
<p>This script looks in the directory DataDirectory for all the files with <strong>BFmovern_</strong>.movern in the filename and then compiles
the best fit \(m/n\) ratio from these files.
It then produces box and whisker plots of the best fit \(m/n\) ratio.
The red line is the median \(m/n\) ratio, the box shows the 25th  and 75th percentile \(m/n\) ratios,
the whiskers show the data range, with outliers (as determined by the Matplotlib function boxplot)
as "+" symbols. The boxes are notched; these give 85% confidence intervals to the median value after bootstrapping 10,000 times.
Here is an example plot:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/mn_sensitivity.jpg" alt="sensitivity of m/n ratio">
</div>
<div class="title">Figure 14. Box and whisker plots of m/n ratios: this shows how m/n varies as a function of segment fitting parameters.</div>
</div>
</div>
<div class="sect4">
<h5 id="_plotting_the_spatial_distribution_of_m_chi_values_code_raster_plotter_2d_only_py_code">Plotting the spatial distribution of \(M_{\chi}\) values: <code>raster_plotter_2d_only.py</code></h5>
<div class="paragraph">
<p>This script contains two functions.
One is for plotting the tributaries superimposed on a hillshade (or any other raster)
and another is for plotting the \(M_{\chi}\) values superimposed on a raster (we usually do this on the hillshade).</p>
</div>
<div class="paragraph">
<p>For this to work, the <code>.chan</code> file must be referenced to a coordinate system.
That means that the row and column information in the <code>.chan</code> file corresponds to the <code>xllcorner</code>, <code>yllcorner</code> and
<code>node spacing</code> data in the first few lines of the <code>.chan</code> file.
If you have the LSDTopoToolbox this will happen automatically, but if you are writing a script to generate your own
<code>.chan</code> files you`ll need to ensure that your channel nodes have the correct row and column data.</p>
</div>
<div class="paragraph">
<p>The DEM used for the hillshade does not need to be the same as the DEM used for the <code>.chan</code> file
(that is, it can have different n_rows and n_columns etc, so you can, in principle,
do a chi analysis on a clipped version of a DEM but then plot the results on the full DEM extent).
The two functions are:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>coloured_chans_like_graphs</code>: This takes two strings: the filename of the raster and the filename of the <code>.tree</code> file.
You have to include the full path name for both of these files.</p>
<div class="paragraph">
<p>The colouring scheme used for the channels is the same as in the <code>elevation</code> and \(M_{\chi}\) plots made by <code>chi_visualisation.py</code>.
Here is an example:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/raster_chan.jpg" alt="Map of channels">
</div>
<div class="title">Figure 15. A map showing the channels (colored by their number) within a basin</div>
</div>
</li>
<li>
<p><code>m_values_over_hillshade</code>: Again, this takes two strings: the filename of the raster and the filename of the <code>.tree</code> file.
You have to include the full path name for both of these files.</p>
<div class="paragraph">
<p>The colouring scheme on the \(M_{\chi}\) values is the same as in the <code>chi_visualisation.py</code> plot
where \(M_{\chi}\) is plotted on the channel profile. Here is an example:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/raster_Mchi.jpg" alt="M_chi in a basin">
</div>
<div class="title">Figure 16. The \(M_{\chi}\) of channels within a basin</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>To run one or the other of these function you need to scroll to the bottom of the script and comment or uncomment one of the function lines.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_a_sample_chi_analysis_workflow">11.4.5. A Sample Chi Analysis Workflow</h4>
<div class="paragraph">
<p><a href="http://www.geos.ed.ac.uk/~smudd/LSDTT_docs/html/_images/workflow.png">Link to the full-size version of the flowchart</a></p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/workflow.png" alt="m over n workflow">
</div>
<div class="title">Figure 17. The workflow for finding the m over n ratio</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_chi_analysis_part_3_getting_chi_gradients_for_the_entire_landscape">11.5. Chi analysis part 3: Getting chi gradients for the entire landscape</h3>
<div class="paragraph">
<p>The algorithms in the previous two sections were designed for users to statistically determine the \(m/n\) ratio of a given landscape.
The routines calculate the gradient in chi space (which we call \(M_{\chi}\)) but they focus on the main stem
(which in our code is calculated with the longest channel) and its biggest tributaries.</p>
</div>
<div class="paragraph">
<p>In many applications, however, users may with to map the chi gradient across a landscape. We provide a tool for doing so in the driver function 'map_chi_gradient.cpp'.</p>
</div>
<div class="sect3">
<h4 id="_compile_the_code_7">11.5.1. Compile the code</h4>
<div class="paragraph">
<p>The chi gradient mapping tool can be compiled by navigating to the driver function folder and running <code>make</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f map_chi_gradient.make</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_run_the_map_chi_gradient_tool">11.5.2. Run the map chi gradient tool</h4>
<div class="paragraph">
<p>The program is now ready to run with the correct inputs. The function takes two inputs</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The path to the parameter file.</p>
</li>
<li>
<p>The name of the parameter file.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>So if the parameter file is located at <code>/home/test_data/some_data/</code> and it is called 'test_chi_map.param', you run the program with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./map_chi_gradient.exe /home/test_data/some_data/ test_chi_map.param</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_the_parameter_file">The parameter file</h5>
<div class="paragraph">
<p>The parameter file has keywords followed by a value. The keywords need to be in the correct order. An example file is:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">DATADIR /home/data/FR/fr_data/
OUTPUTDIR /home/data/FR/ChiGradientMap_with_1_basins/

DEMFILE fr_5m
CHEADSFILE fr_CH_dreich_nodeindices_for_Arc
DEM_ext flt
BasinOrder 2
MinSlope 0.0001
A_0 1000
m_ov_n 0.30
number_of_mc_iterations 500
TargetNodes 80
MinSegLength 10
Sigma 10.0
Skip 0
threshold_pixels_for_chi 250
test_drainage_boundaries false</code></pre>
</div>
</div>
<div class="paragraph">
<p>Below is a table with the values for this parameter file:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 20. Cheat sheet for map chi gradient parameter file</caption>
<colgroup>
<col style="width: 12%;">
<col style="width: 37%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Description</th>
<th class="tableblock halign-left valign-top">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DATADIR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The directory where the data is stored.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Make sure there as a <code>/</code> character at the end.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OUTPUTDIR</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Where the output is written.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Make sure there as a <code>/</code> character at the end. IMPORTANT: the code does not check if this directory exists so you need to make sure it does exist before you run the program or it will crash.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEMFILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The prefix of the DEM (without the file extension)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">For example, if your DEM is called my_topography.bil then the prefix is my_topography.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CHEADSFILE</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A channel heads file that has been generated by a channel head algorithm (e.g., <a href="http://onlinelibrary.wiley.com/doi/10.1002/2013WR015167/full">Clubb et al., 2014</a>); this file will be in csv form from the channel heads program.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If <code>NULL</code> is selected, then the channel network will be built based on a flow accumulation threshold of 50 pixels.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">DEM_ext</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The DEM extension</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Should be either <code>bil</code>, <code>flt</code> or <code>asc</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">BasinOrder</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The lowest order basin to select channels. 2 is recommended.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">For example, if this is 2 then all 2nd order channels will be mapped. If it is 3 all 3rd order channels will be mapped.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MinSlope</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Minimum slope for the fill algorithm.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0001 is the standard value.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">A_0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reference drainage area for chi analysis.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1000 \(m^2\) is recommended.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">m_ov_n</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The <code>m/n</code> ratio.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If this not has been calculated, users should use 0.5.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">number_of_mc_iterations</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Number of Monte Carlo iterations for the statistical selection of channel segments.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">500 is the typical value but this number could be lower on slower systems.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TargetNodes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Maximum number of nodes to be analyzed for any sequence of segments.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Users should choose a value between 80-120. Lower numbers are more computationally efficient.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MinSegLength</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum length of a distinct segment.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Users should select values between 8-15 (10 is probably best).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sigma</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The uncertainty in elevation data in metres.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This could be the DEM uncertainty, but also contains the topographic roughness elements (e.g., boulders in the channel). In mountain channels 5-10m is a good choice.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">threshold_pixels_for_chi</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is the number of pixels of flow accumulation required for calculation of chi for the chi coordinate raster. In addition, this sets the threshold drainage area if you choose NULL for the CHEADSFILE.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Depends on raster resolution, but you might start with 50 if you have a 90 metre DEM.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">test_drainage_boundaries</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is a boolean that is true if you want to remove any basins draining to the edge of your DEM.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Either true (if you want to remove basins draining to the edge) or false (if you don&#8217;t).</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_9">11.6. Summary</h3>
<div class="paragraph">
<p>You should now be able to extract some simple topographic metrics from a DEM using our Driver_analysis program.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_basin_averaged_cosmogenic_analysis">12. Basin averaged cosmogenic analysis</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The LSDCosmoBasin toolkit is designed to automate calculation of basin averaged denudation rates determined estimated from the concentration of in situ cosmogenic nuclides.
Currently <sup>10</sup>Be and <sup>26</sup>Al are supported.</p>
</div>
<div class="paragraph">
<p>The toolkit requires:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data on cosmogenic samples.</p>
</li>
<li>
<p>A file containing filenames of the topographic data, and optional filenames for shielding rasters.</p>
</li>
<li>
<p>A parameter file.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The toolkit then produces:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A csv file that contains results of the analysis.</p>
</li>
<li>
<p>A text file that can be copied into the <a href="http://hess.ess.washington.edu/math/al_be_v22/al_be_erosion_multiple_v22.php&gt;">CRONUS online calculator</a> for data comparison.</p>
</li>
</ul>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Quick guide if you already know what you are doing</div>
<div class="paragraph">
<p>If you already know what you are doing, here is a quick guide to walk you through the process.
If one of these steps doesn&#8217;t make sence see the full documentation.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You will want a directory for both the source code and the data. Make these directories.</p>
</li>
<li>
<p>Get the latest version of the source code from <a href="https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide" class="bare">https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide</a>
If you don&#8217;t have it, use</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git clone https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>or if you have it use</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git pull -u origin master</code></pre>
</div>
</div>
<div class="paragraph">
<p>in your source code directory.</p>
</div>
</li>
<li>
<p>If you have just downloaded the source code, or if it has updates, you need to compile the code.
Go into the folder <strong>driver_functions_CRNBasinwide</strong> and use make:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f Spawn_DEMS_for_CRN.make
$ make -f Shielding_for_CRN.make
$ make -f Basinwide_CRN.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>After each call to <code>make</code> there will be a bunch of warnings that you can ignore.</p>
</div>
</li>
<li>
<p>In your data folder you will need a <code><strong>_CRNRasters.csv</code> file, a <code>*_CRNData.csv</code> file,
and a <code></strong>.CRNParams</code> file. If you don&#8217;t know what these are read the relevent parts of the full documentation</p>
</li>
<li>
<p>In your data folder you will also need some python scripts, which you can download individually:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/JoinSnowShielding.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/EliminateUnderscoreFromCRNDataSampleNames.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareDirectoriesForBasinSpawn.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareCRNRastersFileFromDirectory.py</code></pre>
</div>
</div>
</li>
<li>
<p>If you have some rasters (elevation, shielding, etc.) and you don&#8217;t have a <code>_CRNRasters.csv</code> file, update the path name in <code>PrepareCRNRastersFileFromDirectory.py</code> and run that script.</p>
</li>
<li>
<p>In your data folder, run <code>PrepareDirectoriesForBasinSpawn.py</code>.
You will need to update the path and the prefix at the bottom of this file.</p>
</li>
<li>
<p>In addition, sample names with the underscore character (<code><em></code>) are not allowed. The script
<code>EliminateUnderscoreFromCRNDataSampleNames.py</code> will replace all <code></em></code> characters with <code>-</code> characters.
You need to open this file and change the target directory before running. It will modify all <code>*_CRNData.csv</code> files it finds in that directory.</p>
</li>
<li>
<p>Next up, spawn the basins. Go into the source code directory and run:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX</code></pre>
</div>
</div>
</li>
<li>
<p>Now, you are ready to calculate topographic shielding. You should run:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./Shielding_for_CRN.exe PATHNAME DATAPREFIX</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you ran the spawning the data prefix will now have a <code>*_spawned</code> in it.
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
This is the most computationally expensive component of the process. It could take a while. In the full documentation there is some instructions as to how to do this computation using an embarrassingly parallel approach.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>If you decide to use previously reported snow shielding values, run the <code>JoinSnowShielding.py</code> function.
This will result in data files with the text <code>*_SS</code> in it.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_get_the_code_and_data_basin_averaged_cosmogenic_analysis">12.1. Get the code and data basin-averaged cosmogenic analysis</h3>
<div class="paragraph">
<p>This section goes walks you through getting the code and example data,
and also describes the different files you will need for the analysis.</p>
</div>
<div class="sect3">
<h4 id="_get_the_source_code_for_basin_averaged_cosmogenics">12.1.1. Get the source code for basin-averaged cosmogenics</h4>
<div class="paragraph">
<p>First navigate to the folder where you will keep your repositories.
In this example, that folder is called <code>/home/LSDTT_repositories</code>.
In a terminal window, go there with the <code>cd</code> command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ cd /home/LSDTT_repositories/</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can use the <code>pwd</code> command to make sure you are in the correct directory.
If you don&#8217;t have the directory, use <code>mkdir</code> to make it.</p>
</div>
<div class="sect4">
<h5 id="_clone_the_code_from_git_3">Clone the code from Git</h5>
<div class="paragraph">
<p>Now, clone the repository from <a href="https://github.com">GitHub</a>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ git clone https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide.git</code></pre>
</div>
</div>
<div class="sect5">
<h6 id="_alternatively_get_the_zipped_code_4">Alternatively, get the zipped code</h6>
<div class="paragraph">
<p>If you don&#8217;t want to use <em>git</em>, you can download a zipped version of the code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ wget https://github.com/LSDtopotools/LSDTopoTools_CRNBasinwide/archive/master.zip
$ gunzip master.zip</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="https://github.com">GitHub</a> zips all repositories into a file called <code>master.zip</code>,
so if you previously downloaded a zipper repository this will overwrite it.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_compile_the_code_8">Compile the code</h5>
<div class="paragraph">
<p>Okay, now you should have the code. You will still be sitting in the directory
<code>/home/LSDTT_repositories/</code>, so navigate up to the directory <code>LSDTopoTools_BasinwideCRN/driver_functions_BasinwideCRN/</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/LSDTT_repositories/
$ cd LSDTopoTools_CRNBasinwide
$ cd driver_functions_CRNBasinwide</code></pre>
</div>
</div>
<div class="paragraph">
<p>There are a number of makefiles (thse with extension <code>.make</code> in this folder).
These do a number of different things that will be explained later in this chapter.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_getting_example_data_the_san_bernardino_mountains">12.1.2. Getting example data: The San Bernardino Mountains</h4>
<div class="paragraph">
<p>We have provided some example data. This is on our Github example data website.</p>
</div>
<div class="paragraph">
<p>The example data has a number of digital elevation models in various formats,
but for these examples we will be only using one dataset, from the San Bernardino Mountains in California.</p>
</div>
<div class="paragraph">
<p>You should make a folder for your data using <code>mkdir</code> somewhere sensible.
For the purposes of this tutorial I&#8217;ll put it in the following folder:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/ExampleDatasets/SanBernardino/</code></pre>
</div>
</div>
<div class="paragraph">
<p>Again, we will only take the data we need, so use wget to download the data:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/SanBern.bil
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/SanBern.hdr
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/example_parameter_files/SanBern_CRNData.csv
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/example_parameter_files/SanBern_CRNRasters.csv
$ wget https://github.com/LSDtopotools/ExampleTopoDatasets/raw/master/example_parameter_files/SanBern.CRNParam</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should now have the following files in your data folder:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/ExampleDatasets/SanBernardino/
$ ls
SanBern.bil    SanBern_CRNData.csv     SanBern.CRNParam
SanBern.hdr    SanBern_CRNRasters.csv</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The file <code>SanBern_CRNRasters.csv</code> will need to be modified with the appropriate paths to your files! We will describe how to do that below.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_setting_up_your_data_directories_and_parameter_files">12.1.3. Setting up your data directories and parameter files</h4>
<div class="paragraph">
<p>Before you can run the code, you need to set up some data structures.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you downloaded the example data, these files will already exist.
These instructions are for when you need to run CRN analysis on your own datasets.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You can keep your topographic data separate from your cosmogenic data, if you so desire.
You&#8217;ll need to know the directory paths to these data.</p>
</li>
<li>
<p>In a single folder (again, it can be separate from topographic data),
you must put a i) <strong>parameter file</strong>, a <strong>cosmogenic data file</strong>, and a <strong>raster filenames file</strong> .</p>
</li>
<li>
<p>These three files must have the same <strong>prefix</strong>, and each have their own extensions.</p>
<div class="ulist">
<ul>
<li>
<p>The <strong>parameter file</strong> has the extension: <code>.CRNParam</code>.</p>
</li>
<li>
<p>The <strong>cosmogenic data file</strong> has the extension <code>_CRNData.csv</code>.</p>
</li>
<li>
<p>The <strong>raster filenames file</strong> has the extension <code>_CRNRasters.csv</code>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>For example, if the prefix of your files is <code>SanBern</code>,
then your three data files will be <code>SanBern.CRNParam</code>,
<code>SanBern_CRNData.csv</code>, and <code>SanBern_CRNRasters.csv</code>.</p>
</li>
<li>
<p>If the files do not have these naming conventions, the code <strong>WILL NOT WORK</strong>!
Make sure you have named your files properly.</p>
</li>
</ol>
</div>
<div class="sect4">
<h5 id="_the_parameter_file_2">The parameter file</h5>
<div class="paragraph">
<p>The parameter file contains some values that are used in the calculation of both shielding and erosion rates.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
This file must have the extension <code>.CRNParam</code>. The extension is <strong>case sensitive</strong>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The parameter file could be empty, in which case parameters will just take default values.
However, you may set various parameters. The format of the file is:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">parameter_name: parameter_value</code></pre>
</div>
</div>
<div class="paragraph">
<p>So for example a parameter file might look like:</p>
</div>
<div class="listingblock">
<div class="title">An example CRNparam file</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">min_slope: 0.0001
source_threshold: 12
search_radius_nodes: 1
threshold_stream_order: 1
theta_step: 30
phi_step: 30
Muon_scaling: Braucher
write_toposhield_raster: true
write_basin_index_raster: true</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
There cannot be a space between the parameter name and the ":" character,
so <code>min_slope : 0.0002</code> will fail and you will get the default value.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In fact all of the available parameters are listed above, and those listed above are default values.
The parameter names are not case sensitive. The parameter values are case sensitive.
These parameters are as follows:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 21. File input and output options</caption>
<colgroup>
<col style="width: 16%;">
<col style="width: 16%;">
<col style="width: 16%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">min_slope</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum slope between pixels used in the filling function (dimensionless)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">source_threshold</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">12</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of pixels that must drain into a pixel to form a channel.
This parameter makes little difference, as the channel network only plays a role in
setting channel pixels to which cosmo samples will snap. This merely needs to be
set to a low enough value that ensures there are channels associated with each
cosmogenic sample.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">search_radius_nodes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of pixels around the location of the cosmo location to search for
a channel. The appropriate setting will depend on the difference between the
accuracy of the GPS used to collect sample locations and the resolution of the DEM.
If you are using a 30 or 90m DEM, 1 pixel should be sufficient. More should be used
for LiDAR data.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">threshold_stream_order</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum stream or which the sample snapping routine considers a 'true' channel. The input is a <a href="https://en.wikipedia.org/wiki/Strahler_number">Strahler stream order</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">theta_step</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">30</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Using in toposhielding calculations. This is the step of azimuth (in degrees) over which shielding and
shadowing calculations are performed. <a href="http://onlinelibrary.wiley.com/doi/10.1002/esp.1336/abstract">Codilean (2005)</a>
recommends 5, but it seems to work without big changes
differences with 15. An integer that must be divisible by 360 (although if not the code will force it to
the closest appropriate integer).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">phi_step</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">30</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Using in toposhielding calculations. This is the step of inclination (in degrees) over which shielding and
shadowing calculations are performed. <a href="http://onlinelibrary.wiley.com/doi/10.1002/esp.1336/abstract">Codilean (2005)</a>
recommends 5, but it seems to work without big changes
differences with 10. An integer that must be divisible by 360 (although if not the code will force it to
the closest appropriate integer).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muon_scaling</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Braucher</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The scaling scheme for muons. Options are "Braucher", "Schaller" and "Granger". If you give
the parameter file something other than this it will default to Braucher scaling. These scalings take values
reported in <a href="http://www.ucl.ac.uk/~ucfbpve/cosmocalc/">COSMOCALC</a> as described by
<a href="http://onlinelibrary.wiley.com/doi/10.1029/2006GC001530/abstract">Vermeesch 2007</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write_toposhield_raster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">If true this writes a toposhielding raster if one does not exist.
Saves a bit of time but will take up some space on your hard disk!</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write_basin_index_raster</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">true</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">For each DEM this writes an LSDIndexRaster to file with the extension <code>_BASINS</code> that
has each of the basins that have been found for CRN analysis listed by basinID.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect4">
<h5 id="_the_cosmogenic_data_file">The cosmogenic data file</h5>
<div class="paragraph">
<p>This file contains the actual cosmogenic data: it has the locations of samples,
their concentrations of cosmogenics (<sup>10</sup>Be and <sup>26</sup>Al) and the uncertainty of these concentrations.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The cosmogenic data file must have the extension <code>_CRNData.csv</code>.
The extension is case sensitive.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This is a <code>.csv</code> file: that is a comma separated value file. It is in that format to be both excel and
<a href="http://pandas.pydata.org/">pandas</a> friendly.</p>
</div>
<div class="paragraph">
<p>The first row is a header that names the columns,
after that there should be 7 columns (separated by commas) and unlimited rows. The seven columns are:</p>
</div>
<div class="paragraph">
<p>sample_name, sample_latitude, sample_longitude, nuclide, concentration, AMS_uncertainty, standardisation</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Important notes about <strong>_CRNData.csv</strong> files</div>
<div class="ulist">
<ul>
<li>
<p>The sample name <strong>should not have spaces or underscore characters</strong>. If it has an underscore, you can run our script
<code>EliminateUnderscoreFromCRNDataSampleNames.py</code>, which is located here: <a href="https://github.com/LSDtopotools/LSDAutomation" class="bare">https://github.com/LSDtopotools/LSDAutomation</a>
The script will replace underscores with <code>-</code> characters. The reason for this is that our code uses the <code>_</code> as a separator
in filenames.</p>
</li>
<li>
<p>The latitude and longitude should be in decimal degrees. Negative latitude indicates southern hemisphere.</p>
</li>
<li>
<p>Nuclide can be either <strong>"Be10"</strong> or <strong>"Al26"</strong>. Any other option will be rejected.</p>
</li>
<li>
<p>Concentration is in atoms/gram</p>
</li>
<li>
<p>AMS uncertainty is also in atoms/gram</p>
</li>
<li>
<p>Standardisation is the name of the standards used in the AMS measurements. This is not always so easy to find
in published papers!! The defaults are "07KNSTD" for <sup>10</sup>Be and "KNSTD" for <sup>26</sup>Al. These seem to be used by many
people after 2007 when <a href="http://www.ssl.berkeley.edu/cosmochem/about.html">Kuni Nishiizumi</a> made them available (or at least that is when he published the paper).
If the samples are from before 2007 and you don&#8217;t know the standard use, you should use "KNSTD" for <sup>10</sup>Be and <sup>26</sup>Al.
There are many more standards floating around, but the Nishiizumi one seem the most widely used.
The options are (take a deep breath), for <sup>10</sup>Be:</p>
<div class="listingblock">
<div class="title">Options for <sup>10</sup>Be standardisation</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">"07KNSTD", "KNSTD", "NIST_Certified", "LLNL31000", "LLNL10000", "LLNL3000", "LLNL1000"
"LLNL300", "NIST_30000", "NIST_30200", "NIST_30300", "NIST_30600", "NIST_27900"
"S555","S2007", "BEST433", "BEST433N", "S555N", "S2007N"</code></pre>
</div>
</div>
<div class="paragraph">
<p>And for <sup>26</sup>Al:</p>
</div>
<div class="listingblock">
<div class="title">Options for <sup>26</sup>Al standardisation</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">"KNSTD", "ZAL94", "SMAL11", "0", "ZAL94N", "ASTER", "Z92-0222"</code></pre>
</div>
</div>
</li>
<li>
<p>In addition, you can have an <strong>optional</strong> column for the snow shielding.
This is intended to be used for places where you are attempting to reproduce erosion rates from previously reported snow shielding values.
We describe the snow shielding options later in the documentation, but if you include this number it will be a float between 0 (for total sheilding)
and 1 (for no shielding).</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>An example file would look like this (this is not real data):</p>
</div>
<div class="listingblock">
<div class="title">An example _CRNData.csv file</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Sample_name,Latitude,Longitude,Nuclide,Concentration,Uncertainty,Standardisation
LC07_01,-32.986389,-71.4225,Be10,100000,2500,07KNSTD
LC07_04,-32.983528,-71.415556,Be10,150000,2300,07KNSTD
LC07_06,-32.983028,-71.415833,Al26,4000,2100,KNSTD
LC07_08,-32.941333,-71.426583,Be10,30000,1500,07KNSTD
LC07_10,-33.010139,-71.435389,Be10,140000,25000,07KNSTD
LC07_11,-31.122417,-71.576194,Be10,120502,2500,07KNSTD</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or, with reported snow shielding:</p>
</div>
<div class="listingblock">
<div class="title">An example _CRNData.csv file with snow shielding</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Sample_name,Latitude,Longitude,Nuclide,Concentration,Uncertainty,Standardisation, Snow_shielding
LC07_01,-32.986389,-71.4225,Be10,100000,2500,07KNSTD,0.7
LC07_04,-32.983528,-71.415556,Be10,150000,2300,07KNSTD,0.8
LC07_06,-32.983028,-71.415833,Al26,4000,2100,KNSTD,1.0
LC07_08,-32.941333,-71.426583,Be10,30000,1500,07KNSTD,1.0
LC07_10,-33.010139,-71.435389,Be10,140000,25000,07KNSTD,1.0
LC07_11,-31.122417,-71.576194,Be10,120502,2500,07KNSTD,0.987</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you followed the instructions earlier in the section <a href="#_getting_example_data_the_san_bernardino_mountains">Getting example data: The San Bernardino Mountains</a>
then you will have a <code>CRNdata.csv</code> file called <code>Binnie_CRNData.csv</code> in your data folder.</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 22. CRNData.csv format (the first row contains a header)</caption>
<colgroup>
<col style="width: 16%;">
<col style="width: 16%;">
<col style="width: 16%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Column</th>
<th class="tableblock halign-left valign-top">Heading</th>
<th class="tableblock halign-left valign-top">type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Sample_name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The sample name <strong>NO spaces or underscore characters!</strong></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Latitude</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Latitude in decimal degrees.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Longitude</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Longitude in decimal degrees.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nuclide</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The nuclide. Options are <code>Al26</code> and <code>Be10</code>. Anything else will be rejected.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Concentration</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Concentration of the nuclide in atoms g<sup>-1</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uncertainty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uncertainty of the concentration of the nuclide in atoms g<sup>-1</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Standardization</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The standardization for the AMS measurments. See table below for options.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reported snow shielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The reported snow shielding value for a basin. Should be a ratio between 0 (fully shielded) and 1 (no shielding).
<strong>This column is OPTIONAL</strong>.</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 23. Nuclide standardisation options</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 80%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Nuclide</th>
<th class="tableblock halign-left valign-top">Options</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><sup>10</sup>Be</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>07KNSTD</code>, <code>KNSTD</code>, <code>NIST_Certified</code>, <code>LLNL31000</code>, <code>LLNL10000</code>, <code>LLNL3000</code>, <code>LLNL1000</code>
<code>LLNL300</code>, <code>NIST_30000</code>, <code>NIST_30200</code>, <code>NIST_30300</code>, <code>NIST_30600</code>, <code>NIST_27900</code>
<code>S555</code>,<code>S2007</code>, <code>BEST433</code>, <code>BEST433N</code>, <code>S555N</code>, <code>S2007N</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><sup>26</sup>Al</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>KNSTD</code>, <code>ZAL94</code>, <code>SMAL11</code>, <code>0</code>, <code>ZAL94N</code>, <code>ASTER</code>, <code>Z92-0222</code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect4">
<h5 id="_the_raster_names_file">The raster names file</h5>
<div class="paragraph">
<p>This file contains names of rasters that you want to analyze.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The raster names file must have the extension <code>_CRNRasters.csv</code>.
The extension is case sensitive.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>This file is a csv file that has as many rows as you have rasters that cover your CRN data.
Each row can contain between 1 and 4 columns.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The first column is the <strong>FULL</strong> path name to the Elevation raster and its prefix (that is, without the <code>.bil</code>, e.g.:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">/home/smudd/basin_data/Chile/CRN_basins/Site01/Site_lat26p0_UTM19_DEM</code></pre>
</div>
</div>
</li>
<li>
<p>The next column is <strong>either</strong> a full path name to a snow shielding raster <strong>or</strong> a snow shielding effective depth.
Both the raster and the single value should have units of g/cm^2 snow depth. If there is no number here
the default is 0.</p>
</li>
<li>
<p>The next column is <strong>either</strong> a full path name to a self shielding raster <strong>or</strong> a self shielding effective depth.
Both the raster and the single value should have units of g/cm<sup>2</sup> shielding depth. If there is no number here
the default is 0.</p>
</li>
<li>
<p>The next column is the <strong>FULL</strong> path to a toposhielding raster. If this is blank the code will run topographic
shielding for you. Note: topographic shielding is the most computationally demanding step in the cosmo analysis.</p>
<div class="paragraph">
<p>A typical file might will look like this:</p>
</div>
<div class="listingblock">
<div class="title">An example CRNRasters.csv file</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">/home//basin_data/Site01/Site01_DEM,0,0,/home/basin_data/Site01/Site01_DEM_TopoShield
/home/basin_data/Site02/Site02_DEM,5,10
/home/basin_data/Site03/Site03_DEM,5,/home/basin_data/Site03/Site03_DEM_SelfShield
/home/basin_data/Site04/Site04_DEM,/home/basin_data/Site04/Site04_DEM_SnowShield,/home/basin_data/Site04/Site04_DEM_SelfShield
/home/basin_data/Site05/Site05_DEM
/home/basin_data/Site06/Site06_DEM,/home/basin_data/Site06/Site06_DEM_SnowShield</code></pre>
</div>
</div>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 24. CRNRasters.csv format (the first row contains a header)</caption>
<colgroup>
<col style="width: 12%;">
<col style="width: 37%;">
<col style="width: 12%;">
<col style="width: 37%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Column</th>
<th class="tableblock halign-left valign-top">Heading</th>
<th class="tableblock halign-left valign-top">type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Path and prefix of elevation data</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Path and prefix of elevation data; does not include the extension (that is, does not include <code>.flt</code> or <code>.bil</code>)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Snow shielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float <strong>or</strong> string <strong>or</strong> empty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This could be empty, or contain a float, in which case it is the effective depth of snow (g cm<sup>-2</sup>) across the entire basin <strong>or</strong>
a string with the path and file prefix of the snow depth (g cm<sup>-2</sup>) raster. If empty, snow depth is assumed to be 0.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Self shielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float <strong>or</strong> string <strong>or</strong> empty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This could be empty, or contain a float, in which case it is the effective depth of material eroded(g cm<sup>-2</sup>) across the entire basin <strong>or</strong>
a string with the path and file prefix of the eroded depth (g cm<sup>-2</sup>) raster. If empty, eroded depth is assumed to be 0.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Topo shielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string <strong>or</strong> empty</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This could be empty <strong>or</strong> could contain
a string with the path and file prefix of the topographic shielding (a ratio between 0 and 1) raster.
If empty topographic shielding is assumed to be 1 (i.e., no shielding).</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_modifying_your_crnrasters_file_the_python_way">12.1.4. Modifying your CRNRasters file the python way</h4>
<div class="paragraph">
<p>The <code>_CRNRasters.csv</code> file contains the path names and the file prefixes of the rasters to be used in the analysis.
The paths will vary depending on your own file structures.
Updating these paths by hand can be quite tedious, so we have prepared a python script to automate this process.
You can get this script here:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareCRNRastersFileFromDirectory.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>The script <code>LSDOSystemTools.py</code> contians some tools for managing paths and files, the actual work is done by the script <code>PrepareCRNRastersFileFromDirectory.py</code>.</p>
</div>
<div class="paragraph">
<p>In an editor, go into <code>PrepareCRNRastersFileFromDirectory.py</code> and navigate to the bottom of the file.
Change the <code>path</code> to point to the directory with your DEMs. The <code>prefix</code> is the prefix of your files, so in this example change <code>prefix</code> to <code>SanBern</code>.
You can then run the script with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python PrepareCRNRastersFileFromDirectory.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>This script will then update the <code>_CRNRasters.csv</code> file to reflect your directory structure. The script also detects any associated shielding rasters.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_calculating_topographic_shielding">12.2. Calculating Topographic Shielding</h3>
<div class="paragraph">
<p>Cosmogenic nuclides are produced at or near the Earth&#8217;s surface by cosmic rays,
and these rays can be blocked by topography (i.e., big mountains cast "shadows" for cosmic rays).</p>
</div>
<div class="paragraph">
<p>In most cases, you will not have topographic shielding rasters available, and will need to calculate these.</p>
</div>
<div class="paragraph">
<p>Shielding calculation are computationally intensive, much more so than the actual erosion rate computations.
Because of the computational expense of shielding calculations, we have prepared a series of tools for speeding this computation.</p>
</div>
<div class="paragraph">
<p>The topographic shielding routines take the rasters from the <code>_CRNRasters.csv</code> file and the <code>_CRNData.csv</code> file and computes the location of all CRN basins.
They then clips a DEM around the basins (with a pixel buffer set by the user).
These clipped basins are then used to make the shielding calculations and the erosion rate calculations.</p>
</div>
<div class="paragraph">
<p>This process of clipping out each basin spans a large number of new DEM that require a new directory structure.
A python script is provided to set up this directory structure in order to organize the new rasters.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<strong>This process uses a large amount of storage on the hard disk because a new DEM will be written for each CRN basin.</strong>
</td>
</tr>
</table>
</div>
<div class="sect3">
<h4 id="_steps_for_preparing_the_rasters_for_shielding_calculations">12.2.1. Steps for preparing the rasters for shielding calculations</h4>
<div class="sect4">
<h5 id="_creation_of_subfolders_for_your_topographic_datasets">Creation of subfolders for your topographic datasets</h5>
<div class="paragraph">
<p>The first step is to create some subfolders to store topographic data.
We do this using a python script</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>First, place the <code>_CRNRasters.csv</code> and <code>_CRNData.csv</code> file into the same folder,
and make sure the <code>_CRNRasters.csv</code> file points to the directories that contain the topographic data.
If you are working with the example data (see section <a href="#_getting_example_data_the_san_bernardino_mountains">Getting example data: The San Bernardino Mountains</a>),
you should navigate to the folder with the data (for this example, the folder is in <code>/home/ExampleDatasets/SanBernardino/</code>):</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pwd
/home/ExampleDatasets/SanBernardino/
$ ls
SanBern_CRNData.csv  SanBern_CRNRasters.csv  SanBern.hdr
SanBern.bil         SanBern.CRNparam</code></pre>
</div>
</div>
<div class="paragraph">
<p>You will then need to modify <code>SanBern_CRNRasters.csv</code> to reflect your directory:</p>
</div>
<div class="listingblock">
<div class="title">Modify your <code>SanBern_CRNRasters.csv</code> file</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">/home/ExampleDatasets/SanBernardino/SanBern</code></pre>
</div>
</div>
<div class="paragraph">
<p>Each line in this file points to a directory holding the rasters to be analyzed.</p>
</div>
<div class="paragraph">
<p>In this case we are not supplying and shielding rasters.
For more details about the format of this file see the section: <a href="#_the_raster_names_file">The raster names file</a>.</p>
</div>
</li>
<li>
<p>Second, run the python script <code>PrepareDirectoriesForBasinSpawn.py</code>.</p>
<div class="ulist">
<ul>
<li>
<p>You can clone this script from GitHub; find it here: <a href="https://github.com/LSDtopotools/LSDAutomation" class="bare">https://github.com/LSDtopotools/LSDAutomation</a>
You will also need the file <code>LSDOSystemTools.py</code> from this repository.
The <code>LSDOSystemTools.py</code> file contains some scripts for making sure directories are in the correct format,
and for changing filenames if you happen to be switching between Linux and Windows.
It is unlikely that you will need to concern yourself with its contents, as long as
it is present in the same folder as the <code>PrepareDirectoriesForBasinSpawn.py</code> file.</p>
<div class="paragraph">
<p>The scripts can be downloaded directly using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/PrepareDirectoriesForBasinSpawn.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py</code></pre>
</div>
</div>
</li>
<li>
<p>You will need to scroll to the bottom of the script and change the <code>path</code>
(which is simply the directory path of the <code>_CRNRasters.csv</code> file.</p>
</li>
<li>
<p>You will need to scroll to the bottom of the script and change the <code>prefix</code>
(which is simply prefix of the <code>_CRNRasters.csv</code> file; that is the filename before <code>_CRNRasters.csv</code>
so if the filename is <code>YoYoMa_CRNRasters.csv</code> then <code>prefix</code> is <code>YoYoMa</code>. Note this is case sensitive.</p>
<div class="paragraph">
<p>In this example, scroll to the bottom of the file and change it to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">if __name__ == "__main__":
    path = "/home/ExampleDatasets/SanBernardino"
    prefix = "SanBern"
    PrepareDirectoriesForBasinSpawn(path,prefix)</code></pre>
</div>
</div>
</li>
<li>
<p>This python script does several subtle things like checking directory paths and then makes a new folder for each DEM.
The folders will contain all the CRN basins located on the source DEM.</p>
<div class="paragraph">
<p>If you are using the example data, the rather trivial result will be a directory called <code>SanBern</code>.</p>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_spawning_the_basins">Spawning the basins</h5>
<div class="paragraph">
<p>Now you will run a C++ program that spawns small rasters that will be used for shielding calculations.
First you have to compile this program.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>To compile, navigate to the folder <code>/home/LSDTT_repositories/LSDTopoTools_CRNBasinwide/driver_functions_CRNBasinwide/</code>.
If you put the code somewhere else, navigate to that folder.
Once you are in the folder with the driver functions, type:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f Spawn_DEMs_for_CRN.make</code></pre>
</div>
</div>
</li>
<li>
<p>The program will then compile (you may get some warnings&#8212;&#8203;ignore them.)</p>
</li>
<li>
<p>In the <code>/driver_functions_CRNTools/</code> folder, you will now have a program <code>Spawn_DEMs_for_CRN.exe</code>.
You need to give this program two arguments.</p>
</li>
<li>
<p>You need to give <code>Spawn_DEMs_for_CRN.exe</code>, the path to the data files (i.e., <code>_CRNRasters.csv</code> and <code>_CRNData.csv</code>),
and the prefix, so if they are called  <code>YoMa_CRNRaster.csv</code> the prefix is <code>YoMa</code>). In this example the prefix will be <code>SanBern</code>.
Run this with:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX</code></pre>
</div>
</div>
<div class="paragraph">
<p>in windows or:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./Spawn_DEMs_for_CRN.exe PATHNAME DATAPREFIX</code></pre>
</div>
</div>
<div class="paragraph">
<p>in Linux.</p>
</div>
<div class="paragraph">
<p>In our example, you should run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./Spawn_DEMs_for_CRN.exe /home/ExampleDatasets/SanBernardino/ SanBern</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
The PATHNAME <strong>MUST</strong> have a frontslash at the end.
<code>/home/ExampleDatasets/SanBernardino/</code> will work whereas <code>/home/ExampleDatasets/SanBernardino</code> will lead to an error.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once this program has run, you should have subfolders containing small DEMs that contain the basins to be analyzed.
There will be one for every cosmogenic sample that lies within the DEM.</p>
</li>
<li>
<p>You will also have files that contain the same <code>PATHNAME</code> and <code>PREFIX</code> but have <code>_Spawned</code> added to the prefix.
For example, if your original prefix was  <code>CRN_test</code>, the new prefix will be <code>CRN_test_Spawned</code>.</p>
</li>
<li>
<p>In the file <code>PREFIX_Spawned_CRNRasters.csv</code> you will find the paths and prefixes of all the spawned basins.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_the_shielding_computation">12.2.2. The shielding computation</h4>
<div class="paragraph">
<p>The shielding computation is the most computationally expensive step of the CRN data analysis.
Once you have spawned the basins (see above section,
<a href="#_steps_for_preparing_the_rasters_for_shielding_calculations">Steps for preparing the rasters for shielding calculations</a>), you will need to run the shielding calculations.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You will first need to compile the program that calculates shielding. This can be compiled with:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f Shielding_for_CRN.make</code></pre>
</div>
</div>
</li>
<li>
<p>The compiled program (<code>Shielding_for_CRN.exe</code>) takes two arguments: the <code>PATHNAME</code> and the <code>PREFIX</code>.</p>
</li>
<li>
<p>You could simply run this on a single CPU after spawning the basins;
for example if the original data had the prefix <code>CRN_test</code> before spawning, you could run the program with:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./Shielding_for_CRN.exe PATHNAME CRN_test_Spawned</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>PATHNAME</code> is the path to your <code>_CRNRasters.csv</code>, <code>_CRNData.csv</code>, and <code>.CRNParam</code> (<strong>these files need to be in the same path</strong>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you only wanted to do a subset of the basins, you can just delete rows from the <code>*_Spawned_CRNRasters.csv</code> file as needed.
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>This will produce a large number of topographic shielding rasters (with <code>_SH</code> in the filename), for example:</p>
</div>
<div class="listingblock">
<div class="title">A partial list of files generated by spawning operation</div>
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">smudd@burn SanBern $ ls
SpawnedBasin_10.bil  SpawnedBasin_17.bil  SpawnedBasin_7.bil       SpawnedBasin_MHC-13.bil
SpawnedBasin_10.hdr  SpawnedBasin_17.hdr  SpawnedBasin_7.hdr       SpawnedBasin_MHC-13.hdr
SpawnedBasin_11.bil  SpawnedBasin_18.bil  SpawnedBasin_8.bil       SpawnedBasin_MHC-14.bil
SpawnedBasin_11.hdr  SpawnedBasin_18.hdr  SpawnedBasin_8.hdr       SpawnedBasin_MHC-14.hdr
SpawnedBasin_12.bil  SpawnedBasin_19.bil  SpawnedBasin_9.bil       SpawnedBasin_MHC-15.bil
SpawnedBasin_12.hdr  SpawnedBasin_19.hdr  SpawnedBasin_9.hdr       SpawnedBasin_MHC-15.hdr</code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="images/Shielding.jpg" alt="Shielding raster">
</div>
<div class="title">Figure 18. One of the shielding rasters (for sample name <code>18</code>) from the San Bernardino dataset (viewed in QGIS2.2)</div>
</div>
</div>
<div class="sect3">
<h4 id="_embarrassingly_parallel_shielding">12.2.3. Embarrassingly parallel shielding</h4>
<div class="paragraph">
<p>We provide a python script for running multiple basins using an <a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">embarrassingly parallel</a> approach.
It is written for our cluster:
if your cluster uses <code>qsub</code> or equivalent, you will need to write your own script.
However, this will work on systems where you can send jobs directly.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>To set the system up for embarrassingly parallel runs, you need to run the python script <code>ManageShieldingComputation.py</code>,
which can be found here: <a href="https://github.com/LSDtopotools/LSDAutomation" class="bare">https://github.com/LSDtopotools/LSDAutomation</a>.
You can download it with:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/ManageShieldingComputation.py</code></pre>
</div>
</div>
</li>
<li>
<p>In <code>ManageShieldingComputation.py</code>, navigate to the bottom of the script, and enter the <code>path</code>, <code>prefix</code>, and <code>NJobs</code>.
<code>NJobs</code> is the number of jobs into which you want to break up the shielding computation.</p>
</li>
<li>
<p>Once you run this computation, you will get files with the extension <code>_bkNN</code> where <code>NN</code> is a job number.</p>
</li>
<li>
<p>In addition a text file is generated, with the extension <code>_ShieldCommandPrompt.txt</code>,
and from this you can copy and paste job commands into a Linux terminal.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<strong>These commands are designed for the GeoSciences cluster at the University of Edinburgh:
if you use <code>qsub</code> you will need to write your own script</strong>.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Note that the parameters for the shielding calculation are in the <code>.CRNParam</code> files. We recommend:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">theta_step:8
phi_step: 5</code></pre>
</div>
</div>
<div class="paragraph">
<p>These are based on extensive sensitivity analyses and balance computational speed with accuracy.
Errors will be &lt;&lt; 1% even in landscapes with extremely high relief. Our forthcoming paper has details on this.</p>
</div>
</li>
<li>
<p>Again, these computations take a long time. <strong>Don&#8217;t start them a few days before your conference presentation!!</strong></p>
</li>
<li>
<p>Once the computations are finished, there will be a shielding raster for every spawned basin raster.
In addition, the <code>_CRNRasters.csv</code> file will be updated to reflect the new
shielding rasters so that the updated parameter files can be fed directly into the erosion rate calculators.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_once_you_have_finished_with_spawning_and_topographic_shielding_calculations">12.2.4. Once you have finished with spawning and topographic shielding calculations</h4>
<div class="paragraph">
<p>If you are not going to assimilate reported snow shielding values, you can move on to the erosion rate calculations.
If you are going to assimilate reported snow shielding values, please read the section: <a href="#_using_previously_reported_snow_shielding">Using previously reported snow shielding</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_stand_alone_topographic_shielding_calculations">12.2.5. Stand alone topographic shielding calculations</h4>
<div class="paragraph">
<p>We also provide a stand alone program just to calculate topographic shielding. This may be useful for samples collected for
measuring exposure ages or for working in other settings such as active coastlines.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You will first need to compile the program that calculates topographic shielding. This can be compiled with:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f TopoShielding.make</code></pre>
</div>
</div>
</li>
<li>
<p>The compiled program (<code>TopoShielding.out</code>) takes four arguments: the <code>PATHNAME</code>, the <code>PREFIX</code>, the <code>AZIMUTH STEP</code> and the <code>ANGLE STEP</code>.</p>
</li>
<li>
<p>You could simply run this on a single CPU;
for example if the original DEM had the prefix <code>CRN_TEST</code> before spawning, and you wanted to use an <code>AZIMUTH_STEP=5</code> and <code>ANGLE_STEP=5</code>,
you could run the program with:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./TopoShielding.out PATHNAME CRN_TEST 5 5</code></pre>
</div>
</div>
<div class="paragraph">
<p>where <code>PATHNAME</code> is the path to your <code>CRN_TEST</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The DEM must be in ENVI *.bil format. See <a href="#_what_data_does_lsdtopotoolbox_take">What data does LSDTopoToolbox take?</a>
</td>
</tr>
</table>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>This will produce a single topographic shielding raster (with <code>_TopoShield</code> in the filename).</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_snow_shielding_calculations">12.3. Snow shielding calculations</h3>
<div class="paragraph">
<p>Snow absorbs cosmic rays and so CRN concentrations in sediments can be affected
by snow that has been present in the basin during the period that eroded materials were exposed to cosmic rays.</p>
</div>
<div class="paragraph">
<p>Estimating snow shielding is notoriously difficult
(how is one to rigorously determine the thickness of snow averaged over the last few thousand years?),
and our software does not prescribe a method for calculating snow shielding.</p>
</div>
<div class="paragraph">
<p>Rather, our tools allow the user to set snow shielding in 3 ways:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Use a previously reported basinwide average snow shielding factor</p>
</li>
<li>
<p>Assign a single effective average depth of snow over a catchment (in g cm<sup>-2</sup>).</p>
</li>
<li>
<p>Pass a raster of effective average depth of snow over a catchment (in g cm<sup>-2</sup>).</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_using_previously_reported_snow_shielding">12.3.1. Using previously reported snow shielding</h4>
<div class="paragraph">
<p>Some authors report a snow shielding factor in their publications.
The underlying information about snow and ice thickness used to generate the snow shielding factor is usually missing.
Because under typical circumstances the spatial distribution of snow thicknesses is not reported, we use reported snow shielding factors
to calculate an effective snow thickness across the basin.</p>
</div>
<div class="paragraph">
<p>This approach is only compatible with our spawning method (see the section on <a href="#_spawning_the_basins">Spawning the basins</a>),
because this average snow thickness will only apply to the raster containing an individual sample&#8217;s basin.</p>
</div>
<div class="paragraph">
<p>The effective snow thickness is calculated by:</p>
</div>
<div class="stemblock">
<div class="title">Converting snow shielding to an effective depth</div>
<div class="content">
\[d_{eff} = -\Gamma_0*\ln(S_s)\]
</div>
</div>
<div class="paragraph">
<p>where \(d_{eff}\) is the effective depth (g cm<sup>-2</sup>), \(\Gamma_0\) is the attenuation mass (= 160 g cm<sup>-2</sup>) for spallation (we do not consider the blocking of muons by snow), and, \(S_s\) is the reported snow shielding.</p>
</div>
<div class="paragraph">
<p>The reported snow shielding values should be inserted as the 8th column in the <code>CRNData.csv</code> file.</p>
</div>
<div class="paragraph">
<p>For example,</p>
</div>
<div class="listingblock">
<div class="title">A CRNData.csv file with shielding (Note this is not actual data! The snow shielding values are random).</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">Sample_name,Latitude,Longitude,Nuclide,Concentration,Uncertainty,Standardisation,Snow_shield
20,34.3758,-117.09,Be10,215100,9400,07KNSTD,0.661531836
15,34.3967,-117.076,Be10,110600,7200,07KNSTD,0.027374149
19,34.4027,-117.063,Be10,84200,6500,07KNSTD,0.592583113
17,34.2842,-117.056,Be10,127700,5800,07KNSTD,0.158279369
14,34.394,-117.054,Be10,101100,6100,07KNSTD,0.047741051
18,34.2794,-117.044,Be10,180600,10000,07KNSTD,0.559339639
11,34.1703,-117.044,Be10,7700,1300,07KNSTD,0.210018127
16,34.2768,-117.032,Be10,97300,5500,07KNSTD,0.317260607
10,34.2121,-117.015,Be10,74400,5200,07KNSTD,0.253863843</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_steps_to_use_reported_snow_shielding">Steps to use reported snow shielding</h5>
<div class="paragraph">
<p>Reported snow shielding values are done on a basin-by-basin basis, so our snow shielding must have individual shielding calculations for each sample.
This is only possible using our "spawning" routines.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The spawning of basins must be performed: see <a href="#_spawning_the_basins">Spawning the basins</a></p>
</li>
<li>
<p>The <code>*_spawned_CRNData.csv</code> should have snow shielding values in the 8th column.</p>
</li>
<li>
<p>A python script, <code>JoinSnowShielding.py</code>, must be run that translates reported snow shielding values into effective depths.
This script, and a required helper script, <code>LSDOSystemTools.py</code>  can be downloaded from:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/JoinSnowShielding.py
$ wget https://github.com/LSDtopotools/LSDAutomation/raw/master/LSDOSystemTools.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>You will need to scroll to the bottom of the <code>JoinSnowShielding.py</code> program and edit both the path name and the file prefix.
For example, if your spawned data was in <code>/home/ExampleDatasets/SanBernardino/</code> and the files were <code>SanBern_spawned_CRNRasters.csv</code>, <code>SanBern_spawned_CRNData.csv</code>, and <code>SanBern_spawned.CRNParam</code>, then the bottom of the python file should contain:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">if __name__ == "__main__":
    path = "/home/ExampleDatasets/SanBernardino"
    prefix = "SanBern_spawned"
    GetSnowShieldingFromRaster(path,prefix)</code></pre>
</div>
</div>
</li>
<li>
<p>This script will then modify the <code>*spawned_CRNRasters.csv</code> so that the second column will have an effective snow shiedling reflecting the reported snow shielding value
(converted using the equation earlier in this section). It will print a new file, <code>*spawned_SS_CRNRasters.csv</code> and copy the CRNData and CRNParam files to ones with prefixes:
<code>*_spawned_SS_CRNData.csv</code> and <code>*_spawned_SS.CRNParam</code>.</p>
</li>
<li>
<p>These new files (with <code>_SS</code> in the prefix) will then be used by the erosion rate calculator.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_assign_a_single_effective_average_depth">12.3.2. Assign a single effective average depth</h4>
<div class="paragraph">
<p>This option assumes that there is a uniform layer of time-averaged snow thickness over the entire basin.
The thickness reported is in effective depth (g cm<sup>-2</sup>).</p>
</div>
<div class="paragraph">
<p>To assign a constant thickness, one simply must set the section column of <code>*_CRNRasters.csv</code> file to the appropriate effective depth.</p>
</div>
<div class="paragraph">
<p>For example, a file might look like:</p>
</div>
<div class="listingblock">
<div class="title">An example CRNRasters.csv file with constant snow shielding</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">/home/topodata/SanBern,15
/home/topodata/Sierra,15,0
/home/topodata/Ganga,15,0,/home/topodata/Ganga_shielded</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the above example the first row just sets a constant effective depth of 15  g cm<sup>-2</sup>,
The second also assigns a self shielding value of 0 g cm<sup>-2</sup> (which happens to be the default),
and the third row additionally identifies a topographic shielding raster.</p>
</div>
<div class="paragraph">
<p>In general, assigning a constant snow thickness over the entire DEM is not particularly realistic,
and it is mainly used to approximate the snow shielding reported by other authors when they have not made the spatially distributed data about snow thicknesses available
see <a href="#_using_previously_reported_snow_shielding">Using previously reported snow shielding</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_pass_a_raster_of_effective_average_depth_of_snow_over_a_catchment">12.3.3. Pass a raster of effective average depth of snow over a catchment</h4>
<div class="paragraph">
<p>Our software also allows users to pass a raster of effective snow thicknesses (g cm<sup>-2</sup>).
This is the time-averaged effective thickness of snow which can be spatially heterogeneous.</p>
</div>
<div class="paragraph">
<p>The raster is given in the second column of the <code>*_CRNRasters.csv</code>, so, for example in the below file the 4th and 6th rows point to snow shielding rasters.</p>
</div>
<div class="listingblock">
<div class="title">An example CRNRasters.csv file</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">/home//basin_data/Site01/Site01_DEM,0,0,/home/basin_data/Site01/Site01_DEM_TopoShield
/home/basin_data/Site02/Site02_DEM,5,10
/home/basin_data/Site03/Site03_DEM,5,/home/basin_data/Site03/Site03_DEM_SelfShield
/home/basin_data/Site04/Site04_DEM,/home/basin_data/Site04/Site04_DEM_SnowShield,/home/basin_data/Site04/Site04_DEM_SelfShield
/home/basin_data/Site05/Site05_DEM
/home/basin_data/Site06/Site06_DEM,/home/basin_data/Site06/Site06_DEM_SnowShield</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The snow shielding raster must be the same size and shape as the underlying DEM
(i.e. they must have the same number of rows and columns, same coordinate system and same data resolution).
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
These rasters need to be assigned <strong>BEFORE</strong> spawning since the spawning process will clip the snow rasters to be the same size as the clipped topography for each basin.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_calculating_denudation_rates">12.4. Calculating denudation rates</h3>
<div class="paragraph">
<p>Okay, now you are ready to get the denudation rates.
You&#8217;ll need to run the function from the directory where the compiled code is located
(in our example, <code>/home/LSDTT_repositories/LSDTopoTools_CRNBasinwide/</code>), but it can work on data in some arbitrary location.</p>
</div>
<div class="sect3">
<h4 id="_compiling_the_code_3">12.4.1. Compiling the code</h4>
<div class="paragraph">
<p>To compile the code, go to the driver function folder
(in the example, <code>/home/LSDTT_repositories/LSDTopoTools_CRNBasinwide/driver_functions_CRNBasinwide</code>)
and type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ make -f Basinwide_CRN.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will result in a program called <strong>Basinwide_CRN.exe</strong>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_running_the_basin_averaged_denudation_rate_calculator">12.4.2. Running the basin averaged denudation rate calculator</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./Basinwide_CRN.exe pathname_of_data file_prefix method_flag</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The pathname_of_data is just the path to where your data is stored, in this example that is
<code>/home/ExampleDatasets/SanBernardino/</code>.</p>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You <strong>MUST</strong> remember to put a <code>/</code> at the end of your pathname.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>The filename is the <strong>PREFIX</strong> of the files you need for the analysis (that is, without the extension).
In the example this prefix is <code>SanBern</code> (or <code>SanBern_Spawned</code> if you spawned separate shielding basins)</p>
</li>
<li>
<p>The <code>method_flag</code> tells the program what method you want to use to calculate erosion rates. The options are:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 25. Method flag options</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 80%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Flag</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A basic analysis that does not include any shielding (i.e., no topographic, snow or self shielding).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An analysis that includes shielding, but does not account for spawning (see <a href="#_spawning_the_basins">Spawning the basins</a> for details on spawning).
<strong>If this option is used on spawned basins it is likely to result in errors</strong>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">An analyis that includes shielding, to be used on spawned basins (see <a href="#_spawning_the_basins">Spawning the basins</a> for details on spawning). This is the default.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_the_output_files">12.4.3. The output files</h4>
<div class="paragraph">
<p>There are two output files. Both of these files will end up in the <code>pathname</code> that you designated when calling the program.</p>
</div>
<div class="paragraph">
<p>The first is called <code>file_prefix_CRNResults.csv</code> and the second is called <code>file_prefix_CRONUSInput.txt</code>
where file_prefix is the prefix you gave when you called the program.</p>
</div>
<div class="paragraph">
<p>So, for example, if you called the program with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./basinwide_CRN.exe /home/ExampleDatasets/SanBernardino/ SanBern</code></pre>
</div>
</div>
<div class="paragraph">
<p>The outfiles will be called:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">SanBern_CRNResults.csv
SanBern_CRONUSInput.txt</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>_CRONUSInput.txt</code> is formatted to be cut and pasted directly into the CRONUS calculator.
The file has some notes (which are pasted into the top of the file):</p>
</div>
<div class="listingblock">
<div class="title">Header of the *_CRONUSInput.txt file</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile">-&gt;IMPORTANT nuclide concentrations are not original!
      They are scaled to the 07KNSTD!!
-&gt;Scaling is averaged over the basin for snow, self and topographic shielding.
-&gt;Snow and self shielding are considered by neutron spallation only.
-&gt;Pressure is an effective pressure that reproduces Stone scaled production
      that is calculated on a pixel by pixel basis.
-&gt;Self shielding is embedded in the shielding calculation and so
      sample thickness is set to 0.</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You should only paste the contents of the file below the header into the CRONUS calculator, which can be found here:
<a href="http://hess.ess.washington.edu/math/al_be_v22/al_be_erosion_multiple_v22.php" class="bare">http://hess.ess.washington.edu/math/al_be_v22/al_be_erosion_multiple_v22.php</a>
A new version of the CRONUS caluclator should be available late 2016 but should be backward compatible with the prior version. See here:
<a href="http://hess.ess.washington.edu/math/index_dev.html" class="bare">http://hess.ess.washington.edu/math/index_dev.html</a>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The <code>_CRNResults.csv</code> is rather long.
It contains the following data in comma separated columns:</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 26. Columns in the <code>_CRNResults.csv</code> file</caption>
<colgroup>
<col style="width: 9%;">
<col style="width: 9%;">
<col style="width: 9%;">
<col style="width: 72%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Column</th>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Units</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">basinID</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Integer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A unique identifier for each CRN sample.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">sample_name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name of the sample</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nuclide</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The name of the nuclide. Must be either <code>10Be</code> or <code>26Al</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">latitude</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">decimal degrees</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The latitude.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">longitude</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">decimal degrees</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The longitude.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">concentration</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">atoms/g</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The concentration of the nuclide. This is adjusted for the recent standard (e.g., 07KNSTD),
so it may not be the same as in the original dataset.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">concentration_uncert</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">atoms/g</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The concentration uncertainty of the nuclide.
Most authors report this as only the AMS uncertainty.
The concentration is adjusted for the recent standard (e.g., 07KNSTD),
so it may not be the same as in the original dataset.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">erosion rate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">g cm<sup>-2</sup> yr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate in mass per unit area: this is from the full spatially distributed
erosion rate calculator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">9</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">erosion rate AMS_uncert</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">g cm<sup>-2</sup> yr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate uncertainty in mass per unit area: this is from the full spatially distributed
erosion rate calculator. The uncertainty is only that derived from AMS uncertainty.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">10</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">muon_uncert</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">g cm<sup>-2</sup> yr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate uncertainty in mass per unit area derived from muon uncertainty.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">11</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">production_uncert</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">g cm<sup>-2</sup> yr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate uncertainty in mass per unit area derived from uncertainty in the production rate.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">12</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">total_uncert</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">g cm<sup>-2</sup> yr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate uncertainty in mass per unit area that combines all uncertainties.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">13</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AvgProdScaling</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float (dimensionless)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The average production scaling correction for the basin.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">14</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AverageTopoShielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float (dimensionless)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The average topographic shielding correction for the basin.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">15</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AverageSelfShielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float (dimensionless)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The average self shielding correction for the basin.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">16</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AverageSnowShielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float (dimensionless)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The average snow shielding correction for the basin.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">17</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AverageShielding</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float (dimensionless)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The average of combined shielding. Used to emulate basinwide erosion for CRONUS. CRONUS takes separate topographic, snow and self shielding values, but our code calculates these using a fully depth integrated approach so to convert our shielding numbers for use in CRONUS we lump these together to be input as a single shielding value in CRONUS.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">18</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AvgShield_times_AvgProd</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float (dimensionless)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The average of combined shielding times production. This is for use in emulating the way CRONUS assimilates data, since it CRONUS calculates shielding and production separately.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">19</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">AverageCombinedScaling</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float (dimensionless)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The average combined shielding and scaling correction for the basin.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">20</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">outlet_latitude</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">decimal degrees</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The latitude of the basin outlet. This can be assumed to be in <a href="http://spatialreference.org/ref/epsg/wgs-84/">WGS84 geographic coordinate system</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">21</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">OutletPressure</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">hPa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The pressure of the basin outlet (calculated based on NCEP2 data after CRONUS).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">22</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">OutletEffPressure</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">hPa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The pressure of the basin outlet (calculated based on NCEP2 data after CRONUS) needed to get the production scaling at the outlet.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">23</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">centroid_latitude</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">decimal degrees</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The latitude of the basin centroid. This can be assumed to be in <a href="http://spatialreference.org/ref/epsg/wgs-84/">WGS84 geographic coordinate system</a>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">24</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">centroidPressure</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">hPa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The pressure of the basin centroid (calculated based on NCEP2 data after CRONUS).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">25</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">CentroidEffPressure</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">hPa</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is the pressure needed to get basin averaged production scaling:
it is a means of translating the spatially distributed production data into a single value for the CRONUS calculator.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">26</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">eff_erate_COSMOCALC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">g cm<sup>-2</sup> yr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate you would get if you took production weighted scaling and used
cosmocalc.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">27</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">erate_COSMOCALC_mmperkyr_rho2650</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mm kyr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate you would get if you took production weighted scaling and used
cosmocalc. Assumes \(/rho\) = 2650 kg m<sup>-3</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">28</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">eff_erate_COSMOCALC_emulating_CRONUS</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">g cm<sup>-2</sup> yr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The erosion rate if you calcualte the average shielding and scaling separately (as done in CRONUS) but erosion rate is caluclated using COSMOCALC. Assumes \(/rho\) = 2650 kg m<sup>-3</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">29</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">erate_COSMOCALC_emulating_CRONUS_mmperkyr_rho2650</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mm kyr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uncertainty in the erosion rate. Assumes 2650 kg m<sup>-2</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">30</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">erate_mmperkyr_rho2650</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mm kyr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is the erosion rate calculated by our full calculator in mm kyr<sup>-1</sup> assuming \(/rho\) = 2650 kg m<sup>-3</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">31</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">erate_totalerror_mmperkyr_rho2650</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mm kyr<sup>-1</sup></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uncertainty in the erosion rate using the full calculator. Assumes \(/rho\) = 2650 kg m<sup>-3</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">32</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">basin_relief</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">m</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The relief of the basin. Because production scales nonlinearly with elevation,
it is likeley that errors in erosion rates arising from not calculating production on a pixel-by-pixel basis will correlate with relief.
In addition, higher relief areas will have greater topographic shielding,
so prior reported results that used either no topographic shielding or low resoltion topographic shielding are likeley to have greater errors.</p></td>
</tr>
</tbody>
</table>
<div class="sect4">
<h5 id="_reducing_the_output_data">Reducing the output data</h5>
<div class="paragraph">
<p>Users may wish to reduce the data contained within <code>_CRNResults.csv</code> file, so we provide python scripts for doing so.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_summary_10">12.5. Summary</h3>
<div class="paragraph">
<p>You should now be able to take concentrations from detrital cosmogenics and convert these into basin averaged denudation rates.</p>
</div>
<div class="paragraph">
<p>: numbered :</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_swath_profiling_tools">13. Swath Profiling Tools</h2>
<div class="sectionbody">
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
These tools have extra dependencies in addition to a standard installation of LSDTopoTools. Make sure you have read the <a href="#_requirements_for_swaths_and_point_clouds">requirements overview</a> section and installed the libraries needed to run these tools. Detailed installation information is also found in the <a href="#_the_swath_and_point_cloud_tools">appendix</a>.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_generalised_swath_profile">13.1. Generalised Swath Profile</h3>
<div class="paragraph">
<p>Here we expain how to generate a generalised swath profile following the same algorithm described by <a href="http://www.earth-surf-dynam-discuss.net/1/387/2013/esurfd-1-387-2013.html">Hergarten et al. (2014)</a>.</p>
</div>
<div class="paragraph">
<p>The outputs from the function are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A raster showing the extent of the swath profile, indicating the perpendicular distance of each point from the baseline (i.e. a transverse swath)</p>
</li>
<li>
<p>A raster showing the extent of the swath profile, indicating the projected distance along the baseline (i.e. a longitudinal swath)</p>
</li>
<li>
<p>A <code>.txt</code> file containing the results of the transverse swath profile.  The table includes the distance of the centre of each bin across the profile, the mean and standard deviation of each bin, and the 0, 25, 50, 75 and 100 percentiles.</p>
</li>
<li>
<p>A <code>.txt</code> file containing the results of the longitudinal swath profile.  The table includes the distance of the centre of each bin along the profile, projected onto the baseline, the mean and standard deviation of each bin, and the 0, 25, 50, 75 and 100 percentiles.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In order to do so, there are a few preprocessing steps that need to be done to generate the profile baseline.  These can easily be done in ArcMap, but the experienced LSDTopotools user can also write a more complex driver function to do more specialised tasks.</p>
</div>
<div class="sect3">
<h4 id="_preprocessing_step_1_getting_your_raster_into_the_correct_format">13.1.1. Preprocessing step 1: Getting your raster into the correct format</h4>
<div class="paragraph">
<p>You will need to get data that you have downloaded into a format LSDTopoToolbox can understand, namely the <code>.flt</code> format.</p>
</div>
</div>
<div class="sect3">
<h4 id="_preprocessing_step_2_creating_the_baseline">13.1.2. Preprocessing step 2: Creating the baseline</h4>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
This step can be done automatically by tweaking the driver file to extract the baseline using the LSDTopoTools package. See <a href="#_channel_long_profile_swaths">Channel Long Profile Swaths</a> a few sections below for an example of this, which avoids using the pesky ArcMap software.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The baseline is the centre line of the swath profile.  At present the SwathProfile tool uses a shapefile <code>*.shp</code> consisting of a series of points that define the profile.  A suitable baseline can be produced in two easy steps.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>First, create a new shapefile, setting the feature class to <code>polyline</code>, and create a single line feature, which will form the baseline.  This can be linear, or curved, depending on what your requirements are.  Next create another shapefile, this time make the feature class <code>point</code>.</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SwathTools1.png" alt="SwathTools1">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Start editing in ArcMap.  Make the target class the new, empty <code>point</code> shapefile.  Using the edit tool on the Editor Toolbar, select the polyline that you drew in the previous step; it should be highlighted in a light blue colour.  Go to the drop-down menu on the Editor toolbar, and select "Construct Points&#8230;&#8203;".  Set the template as the empty <code>point</code> shapefile.  Set the construction option to Distance, and make the point spacing equal to the resolution of your DEM.  Make sure "Create additional points at start and end" <strong>is</strong> checked.  Click ok, then <strong>save your edits</strong>&#8230;&#8203; you have now created the baseline file.  Give yourself a pat on the back, take a deep breath and move onto the next stage&#8230;&#8203;</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SwathTools2.png" alt="SwathTools2">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compiling_the_driver_function">13.1.3. Compiling the driver function</h4>
<div class="paragraph">
<p>You will need to download all of the code. This will have a directory with the objects (their names start with LSD). Note that this tool utilises the PCL library: www.pointclouds.org[PCL homepage].  Hopefully this is already installed on your University server (it is on the University of Edinburgh server).  It probably won&#8217;t be installed on your laptop, unless you have installed it yourself at some point.  This tool <strong>will not work</strong> if the PCL library is not installed!</p>
</div>
<div class="paragraph">
<p>Within the directory with the objects, there will be two additional directories:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>driver_functions</p>
</li>
<li>
<p>TNT</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>TNT</code> folder contains routines for linear algebra, and it is made by NIST, you can happily do everything in
LSDTopoToolbox without ever knowing anything about it, but if you want you can read what it is here: <a href="http://math.nist.gov/tnt/">TNT homepage</a>.</p>
</div>
<div class="paragraph">
<p>In order to compile this function, it is necessary to use cmake (version 2.8 or later).  The compilation procedure is as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>First, go into the driver function folder</p>
</li>
<li>
<p>Make a new directory in this folder named <code>build</code>; in your terminal type:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">mkdir build</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Move the <code>CMakeLists_SwathProfile.txt</code> file into the <code>build</code> directory.  At the same time, rename this file <code>CMakeLists.txt</code>, so the compiler will find it.  Type::</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">mv CMakeLists_SwathProfile.txt build/CMakeLists.txt</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Go into the <code>build</code> directory. Type:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">cmake28 .</code></pre>
</div>
</div>
<div class="paragraph">
<p>in the terminal.  Note that the name of this directory isn&#8217;t important.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Next type:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">make</code></pre>
</div>
</div>
<div class="paragraph">
<p>in the terminal.  This compiles the code.  You will get a bunch of messages but at the end your code will have compiled.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>All that is left to do is to move the compiled function back up into the driver_functions directory.  Type:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">mv swath_profile_driver.out ..</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_running_the_driver_function">13.1.4. Running the driver function</h4>
<div class="paragraph">
<p>Okay, now you are ready to run the driver function. You&#8217;ll need to run the function from the directory where the compiled code is located (i.e. the <code>driver_functions</code> folder), but it can work on data that is located in any location.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>You run the code with the command <code>./swath_profile_driver.out name_of_basline_file name_of_raster half_width_of_profile bin_width_of_profile</code></p>
</li>
<li>
<p>The <code>name_of_baseline_file</code> is just the name of the shapefile created in the preprocessing step that contains the points defining the baseline.</p>
</li>
<li>
<p>The <code>name_of_raster</code> is the <strong>PREFIX</strong> of the raster, so if your raster is called <code>lat_26p5_flt.flt</code> then the <code>name_of_raster</code> is <code>lat_26p5_flt</code> (that is, without the <code>.flt</code> at the end).</p>
</li>
<li>
<p>Note that if your data is stored in a <code>different</code> directory, then you will need to inlude the full path name in <code>name_of_raster</code> and <code>name_of_baseline_file</code>.  The output files will be saved in the same directory as the DEM.</p>
</li>
<li>
<p>The <code>half_width_of_profile</code> is the half width of the swath (i.e. the distance from the baseline to the swath edge).</p>
</li>
<li>
<p>The <code>bin_width_of_profile</code> is the resolution at which the profile data is condensed into a single profile.  This is not the same as the raster resolution!</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_program_outputs">13.1.5. Program outputs</h4>
<div class="paragraph">
<p>The <code>swath_profile_driver</code> tool creates two raster datasets, so you can check the swath templates yourself to better understand how the profiles are constructed</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>*_swath_long.flt</code> is the longitudinal swath profile template</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SwathTools3.png" alt="SwathTools3">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><code>*_swath_trans.flt</code> is the transverse swath profile template</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/SwathTools4.png" alt="SwathTools4">
</div>
</div>
<div class="paragraph">
<p>There are also two <code>.txt</code> files, which contain the profile data &#8594; these include the mean, standard deviation, and percentiles for each.  These can be plotted using the python script <code>plot_swath_profile.py</code>, located in the <code>LSDVisualisation/trunk/</code> directory.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_channel_long_profile_swaths">13.2. Channel Long Profile Swaths</h3>
<div class="paragraph">
<p>Here another use of the swath tools feature is exploited. You can use it to automatically create long profiles along a channel using a value other than elevation, for example. (This usage is hinted at in the <a href="http://www.earth-surf-dynam-discuss.net/1/387/2013/esurfd-1-387-2013.html" class="bare">http://www.earth-surf-dynam-discuss.net/1/387/2013/esurfd-1-387-2013.html</a> [Hergarten et al. (2014) paper]. This application is mainly suited to where there is:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Expected to be some variation along channel of a certain value or other metric</p>
</li>
<li>
<p>The DEM resolution is high enough to capture lateral variations across the channel, but you are interested in the average of these metrics along the long profile.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_example_applications">13.2.1. Example Applications</h4>
<div class="ulist">
<ul>
<li>
<p>Channel width variation using high resolution lidar DEMs</p>
</li>
<li>
<p>Sediment size distribution along channel from model output</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/LongSwath2.png" alt="LongSwath2">
</div>
<div class="title">Figure 19. Distribution of median grain size along channel long profile. Upper(Q75) and Lower(Q25) quartiles shown in dashed line.</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Erosion/deposition distribution along channel from model output</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/LongSwath1.png" alt="LongSwath1">
</div>
<div class="title">Figure 20. Average channel elevation change for two different model simulations using LSDCatchmentModel</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Basin hydrology applications (water depth, velocity etc.)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You will need the driver file: <code>longitudinal_channel_erosion_swath_profiler.cpp</code> along with the corresponding CMake file.</p>
</div>
<div class="paragraph">
<p>There are effectively 3 supplementary files you need to perform this analysis.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Parameter file. This takes the form of a simple text file with a column of values:</p>
<div class="ulist">
<ul>
<li>
<p>Terrain DEM Name (The base topography)</p>
</li>
<li>
<p>Secondary Raster/DEM file name. (This is the raster file that contains the property that varies along channel.)</p>
</li>
<li>
<p>Raster extension for the above two files (currently, both must be the same format)</p>
</li>
<li>
<p>Minslope (use 0.00001 for starters)</p>
</li>
<li>
<p>Contributing pixel threshold (for calculating the drainage network</p>
</li>
<li>
<p>Swath Half Width (see above)</p>
</li>
<li>
<p>Swath Bin Width (see above)</p>
</li>
<li>
<p>Starting Junction Number</p>
</li>
</ul>
</div>
</li>
<li>
<p>Terrain Raster</p>
</li>
<li>
<p>Secondary Raster</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These two rasters should be in the same spatial extent.</p>
</div>
</div>
<div class="sect3">
<h4 id="_example_usage">13.2.2. Example Usage</h4>
<div class="paragraph">
<p>Compile the driver file using CMake. To do this, create a <code>build</code> folder in the driver_functions folder. Copy the file <code>CMakeLists_Swath_long_profile_erosion.txt</code> file into the new folder, and rename it <code>CMakeLists.txt</code>, as described above. Then:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">cmake .
make</code></pre>
</div>
</div>
<div class="paragraph">
<p>You now have the executable <code>long_swath_profile_erosion.exe</code>. It is run by giving it two arguments: the path to the parameter file and raster file (in the same directory as each other, but can be separate from the executable) and the name of the parameter file.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./long_swath_profile_erosion.exe ./ swath_profiler_long.param</code></pre>
</div>
</div>
<div class="paragraph">
<p>The driver file is designed to perform the whole operation in one go: <code>Fill DEM &gt; Extract Channel Network &gt; Produce Channel File &gt; Convert Channel file to X,Y Points for Swath &gt; Create Swath Template &gt; Perform Swath Analysis</code>, but you may want to split it up into stages if you do not know the starting junction number where you want the profile to begin.</p>
</div>
<div class="paragraph">
<p>The driver file currently uses the longest channel in the basin (the mainstem) so check that this is what you expected. An option may become available to look at tributaries later on.</p>
</div>
<div class="paragraph">
<p>The output files are the Profile (txt) and the Swath template that was used to profile the channel. (Check that it was the spatial extent that you expected).</p>
</div>
<div class="paragraph">
<p>You can use the same visualisation script as above: <code>plot_swath_profile.py</code>, located in the <code>LSDVisualisation/trunk/</code> directory.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_hydrological_and_erosion_modelling">14. Hydrological and Erosion Modelling</h2>
<div class="sectionbody">
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<strong>LSDCatchmentModel</strong> is a 2.5D 'hydrodynamic' landscape evolution model that simulates flooding and erosional processes at the catchment scale, on the order of hours to 100s of years.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>image::images/flood_depth_fig_crop.png</p>
</div>
<div class="paragraph">
<p>Numerical models are useful tools for testing hypotheses of geomorphic processes and landscape evolution. Long term landscape evolution takes place over extensive geological time periods, but is controlled by the dynamics of water flow, and sediment transport within river catchments on much shorter, day-to-day time scales. The LSDTopoTools package provides a model for simulating catchment processes at short-term scales, with the <strong>LSDCatchmentModel</strong> package.</p>
</div>
<div class="paragraph">
<p>This chapter documents how to use the LSDCatchmentModel to set up and run simulations of hydrology and catchment-scale erosion and evolution. LSDCatchmentModel is a 2.5D numerical model of landscape evolution based on the CAESAR-Lisflood model <a href="http://onlinelibrary.wiley.com/doi/10.1002/esp.3478/abstract">(Coulthard et al., 2013)</a>. The model is a <a href="http://natureofcode.com/book/chapter-7-cellular-automata/">Cellular Automaton</a> model, whereby the grid cells in the model domain each have their own parameters associated with them (such as elevation, water depth, water velocity, sediment load, etc.) and the change in these parameters is determined by the state of the neighbouring grid cells.</p>
</div>
<div class="paragraph">
<p>Unlike many models of landscape evolution, this model features an explicit calculation of water flow through the landscape based on a highly simplified form of the shallow water equations <a href="http://www.sciencedirect.com/science/article/pii/S0022169410001538">(Bates et al., 2010)</a>. Most other models, in order to simulate long term evolution, rely on approximations for water discharge based on drainage area, and assume instantaneous run-off of water under hydrological steady-state conditions. The LSDCatchmentModel is therefore suited to modelling both flooding and erosional processes. It can be run as a standalone hydrological model (no erosion) if so desired.</p>
</div>
<div class="paragraph">
<p>The model is also developed to run on parallel computing architectures (Multi-core/cluster computers).</p>
</div>
<div class="sect2">
<h3 id="_origins_relation_to_caesar_lisflood">14.1. Origins: relation to CAESAR-Lisflood</h3>
<div class="paragraph">
<p>The model is essentially a stripped down translation of the CAESAR-Lisflood model, but without the GUI, and it runs on Linux unlike CAESAR-Lisflood, which is Windows only. If you are happy to run on Windows, and would prefer to use a model in GUI-mode then CAESAR-Lisflood is a good choice for this. This branch of the model is designed to be faster and cross platform, scales up to running on a supercomputer if the resources are available to you. One of the drawbacks to the original model is that you need a dedicated Windows box to do your simulations, you can&#8217;t send them off to a cluster computer-type facility, which typically run unix. (Unless you have a bunch of spare Windows PCs&#8230;&#8203;)</p>
</div>
<div class="paragraph">
<p>With this version you can also perform topographic analysis within the same LSDTopoTools environment, switching easily between modelling and topographic analysis.</p>
</div>
</div>
<div class="sect2">
<h3 id="_compilation">14.2. Compilation</h3>
<div class="paragraph">
<p>Several versions of the make file are provided, for different situations. It is planned in the future to make a single proper makefile with different options that cover the separate versions at present. For now, you will have to select from one of the following:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>CatchmentModel.make</p>
</li>
<li>
<p>CatchmentModel_Optimised.make</p>
</li>
<li>
<p>CatchmentModel_OpenMP_Optimised.make</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The plain makefile (Option 1) contains all the compiler flags for debugging and profiling. (The program will run slower if you use this version - only use it for development or if trying to trace a bug). The optimised version (Option 2) runs with the -O2 flags and no profiler or debugger information. The OpenMP version (Option 3) is for running the code in parallel on multiple cores. This applies to desktop PCs with multiple cores as well as compiling for single compute nodes on supercomputers (cluster computers).</p>
</div>
<div class="paragraph">
<p>To compile, run make as follows with the makefile of your choice:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">make -f CatchmentModel.make</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you want to start again and remove the object and executable files, there is also a clean command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">make -f CatchmentModel.make clean</code></pre>
</div>
</div>
<div class="paragraph">
<p>You will get an executable called <code>CatchmentModel.out</code> or similar, depending on which makefile you used.</p>
</div>
<div class="sect3">
<h4 id="_dependencies">14.2.1. Dependencies</h4>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<strong>Your compiler must support C++11.</strong> Almost all compilers do as of 2016, as long as you are running a fairly recent version. Currently, support is not usually enabled by default, buy the C++11 flag to turn it on is included in the makefile. (The code uses some features of the C++11 language standard, but you don&#8217;t need to worry about them if you don&#8217;t want.)
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The parallel version of the code uses the OpenMP libraries, which are powerful (and somewhat magical&#8230;&#8203;) libraries for compiling the code to run in parallel. These are widely supported libraries and many systems will come with them pre-installed. <strong>But you may need to install the <code>gcc-devel</code> package on linux, if using gcc</strong>. Again, the compiler flag is taken care of in the makefile. The code has been tested on the <code>gcc</code> (versions 4.8 and above) and <code>icc</code> (intel) compilers.</p>
</div>
<div class="paragraph">
<p>All other libraries are supplied with the source code (The TNT and FFT libraries, which provide various mathematical functions). You do not need to install them separately.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_running_the_model">14.3. Running the Model</h3>
<div class="paragraph">
<p>The model runs from the command line/terminal/console. You specify the model executable name (CatchmentModel.out) followed by the path name to the parameter file and the parameter file itself. The model will print out updates to the terminal window regularly, keeping you updated to the stage it is at and if there are any errors. The DEM of your catchment must be present in the same folder as your parameter file and must be correctly formatted.</p>
</div>
<div class="paragraph">
<p>You need a minimum of three input files:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Parameter file</p>
</li>
<li>
<p>DEM file of your catchment (currently only ASCII format is supported, sorry <code>.bil</code> fans!)</p>
</li>
<li>
<p>Rainfall time series text file</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The model is run like so:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./CatchmentModel.out [PATH-TO-FOLDER-WITH-INPUT-FILES] ParameterFile.txt</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that the names of the input DEM and rainfall file are specified in the parameter file.</p>
</div>
<div class="paragraph">
<p>When the model runs, it will print to screen the parameters that have been read from the parameter file, for a sanity check. It will update you at certain stages of the data ingestion point. (This usually only takes a few seconds). When the model runs, a counter displays the number of elapsed minutes in model-time.</p>
</div>
<div class="sect3">
<h4 id="_dem_preparation">14.3.1. DEM preparation</h4>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You will need to check your DEM is correctly formatted before use. LSDCatchmentModel has specific requirements about DEM layout.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Currently, you will have to prepare your own DEM as a separate stage in the workflow. (Using whichever GIS tool you like, or preferably our own software!). The DEM should be set up so that one side of the catchment will act as the flow exit point. If you do not have the intended catchment outlet point touching one of the DEM edges, you will get unrealistic pooling of water and flood the entire catchment, as water will not be able to leave the model domain. <strong>In other words: There should be no 'NODATA' values between the intended outlet cell(s) and the edge the DEM file.</strong> This is very important for the model to work correctly.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The model will actually route water off <strong>all</strong> edges of the catchment, if the geometry of your catchment allows it. This might be fine for your intended use, but note that the discharge timeseries file will report total water discharge and sediment output as a total from ALL edge cells, not just the ones you think are the main catchment outlet point. As a side effect, you can use the model to simulate range scale runoff and multiple catchments, just be aware that you will get one value for total discharge.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Technically, the DEM doesn&#8217;t need to be pit-filled, but it may be worthwhile to do so as parts of the model can be sped up when the catchment is in a low-flow or steady-flow state. Again, it depends on your intended usage of the model.</p>
</div>
</div>
<div class="sect3">
<h4 id="_model_run_time_controls">14.3.2. Model run time controls</h4>
<div class="paragraph">
<p>A sample parameter file is provided for the Boscastle floods simulation. This is a 48-hour simulation using a 5m DEM, over a catchment 3km x 5.5km (about 700000 grid cells). It will take about 2-3 hours to run on a mid-range Desktop machine. (You can dramatically speed this up by using a coarser DEM.) Number of domain grid cells is the main control on compute time.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
If using the OpenMP makefile, you can get this down to around 11 minutes using a 48-core machine. Use it if you have the hardware!
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_parameter_file_overview">14.3.3. Parameter File Overview</h4>
<div class="paragraph">
<p>In the Parameter file, you&#8217;ll notice that you can use comments by starting the line with a hash (\#) sign. Parameters themselves take the form:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">parameter_name:     VALUE</code></pre>
</div>
</div>
<div class="paragraph">
<p>Make sure not to change the parameter_name, otherwise the parser will not recognise the name and not load the value. Instead you will get the default value in the header file. <strong>(Yes, I know this is not the best way of ingesting a parameter file, and leaves a lot of chance to human error - I will come up with a better way soon&#8230;&#8203;)</strong></p>
</div>
</div>
<div class="sect3">
<h4 id="_input_files">14.3.4. Input files</h4>
<div class="paragraph">
<p>As a minimum, you need a <strong>DEM input</strong> file, <strong>paramter file</strong>, and <strong>rainfall data</strong> input file.</p>
</div>
<div class="paragraph">
<p>Once you are happy with the paramter file, you must run the model with two command line arguments:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./CatchmentModel.out [PATH TO INPUT FILES] [PARAMETER FILE NAME]</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_parameter_guide">14.4. Parameter Guide</h3>
<div class="sect3">
<h4 id="_file_information">14.4.1. File Information</h4>
<div class="sect4">
<h5 id="_dem_name">dem_name</h5>
<div class="paragraph">
<p>The base name of your dem input file.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
This is the topmost 'surface' in the model, i.e. the sediment layer. Bedrock DEM is specificed under the <code>bedrock_data_file</code> parameter.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_dem_read_extension">dem_read_extension</h5>
<div class="paragraph">
<p>The file extension of your DEMs (currently has to be same for all DEM supplementary files, and only supports <code>.asc</code> format for now, sorry!)</p>
</div>
</div>
<div class="sect4">
<h5 id="_timeseries_save_interval">timeseries_save_interval</h5>
<div class="paragraph">
<p>The model generates a timeseries file that contains data on the total catchment water and sediment discharges. This timestep (in <strong>minutes</strong> of simulated time) determines how often the timeseries data is generated. More on this file later.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_supplementary_files">14.4.2. Supplementary Files</h4>
<div class="paragraph">
<p>Supplementary files for other features of the model.</p>
</div>
<div class="sect4">
<h5 id="_hydroindex_file">hydroindex_file</h5>
<div class="paragraph">
<p>This file determines the different areas of rainfall input when using spatially variable rainfall input options.</p>
</div>
</div>
<div class="sect4">
<h5 id="_rainfall_data_file">rainfall_data_file</h5>
<div class="paragraph">
<p>This should be a text file with some rainfall values (for input into the catchment). For uniform rainfall, the file would contain a value for rainfall in mm/time step on each line. Typically mm/hr is used, but any time step can be set. Make sure to set the <code>rain_data_time_step</code> paramter below as well!</p>
</div>
</div>
<div class="sect4">
<h5 id="_grain_data_file">grain_data_file</h5>
<div class="paragraph">
<p>(not yet implemented - it would be used to set the starting distribution of grainsizes)</p>
</div>
</div>
<div class="sect4">
<h5 id="_bedrock_data_file">bedrock_data_file</h5>

</div>
</div>
<div class="sect3">
<h4 id="_numerical">14.4.3. Numerical</h4>
<div class="paragraph">
<p>Parameters that control the numerical model time-stepping etc, and the model run time.</p>
</div>
<div class="sect4">
<h5 id="_min_time_step">min_time_step</h5>
<div class="paragraph">
<p>Leave at 0.</p>
</div>
</div>
<div class="sect4">
<h5 id="_max_time_step">max_time_step</h5>
<div class="paragraph">
<p>Probably leave at 3600 (seconds), i.e. one hour. You could potentially get model speed up if your increased it, and your rainfall data was at larger intervals than hourly.</p>
</div>
</div>
<div class="sect4">
<h5 id="_run_time_start">run_time_start</h5>
<div class="paragraph">
<p>Leave 0 for now, would be used for restarting runs.</p>
</div>
</div>
<div class="sect4">
<h5 id="_max_run_duration">max_run_duration</h5>
<div class="paragraph">
<p>This is the length of the simulation in hours, MINUS 1. I.e. If you are doing a 48hour simulation, this number should be 47&#8230;&#8203;This is because C-programmers start counting at zero. <strong>(Yes, I know this is daft, and I will get round to fixing it at some point)</strong></p>
</div>
</div>
<div class="sect4">
<h5 id="_memory_limit">memory_limit</h5>
<div class="paragraph">
<p>(ignore this)</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_sediment">14.4.4. Sediment</h4>
<div class="sect4">
<h5 id="_transport_law">transport_law</h5>
<div class="paragraph">
<p>Type either <strong>einstein</strong> or <strong>wilcock</strong> to select your favourite sediment transport law.</p>
</div>
<div class="paragraph">
<p><em>Einstein, H. A. (1950). The bed-load function for sediment transportation in open channel flows (No. 1026). US Department of Agriculture.</em></p>
</div>
<div class="paragraph">
<p><em>Wilcock, P. R., &amp; Crowe, J. C. (2003). Surface-based transport model for mixed-size sediment. Journal of Hydraulic Engineering, 129(2), 120-128.</em></p>
</div>
</div>
<div class="sect4">
<h5 id="_max_tau_velocity">max_tau_velocity</h5>

</div>
<div class="sect4">
<h5 id="_active_layer_thickness">active_layer_thickness</h5>

</div>
<div class="sect4">
<h5 id="_recirculate_proportion">recirculate_proportion</h5>

</div>
<div class="sect4">
<h5 id="_lateral_erosion_on">lateral_erosion_on</h5>

</div>
<div class="sect4">
<h5 id="_lateral_ero_rate">lateral_ero_rate</h5>

</div>
<div class="sect4">
<h5 id="_edge_filter_passes">edge_filter_passes</h5>

</div>
<div class="sect4">
<h5 id="_cells_shift_lat">cells_shift_lat</h5>

</div>
<div class="sect4">
<h5 id="_max_diff_cross_chan">max_diff_cross_chan</h5>

</div>
<div class="sect4">
<h5 id="_erode_limit">erode_limit</h5>

</div>
</div>
<div class="sect3">
<h4 id="_hydrology">14.4.5. Hydrology</h4>
<div class="paragraph">
<p>Parameters for the hydrological part of the model.</p>
</div>
<div class="sect4">
<h5 id="_topmodel_m_value">TOPMODEL_m_value</h5>
<div class="paragraph">
<p>As well as the water routing sub-model, LSDCatchmentModel also calculates the discharge based on Beven&#8217;s TOPMODEL (i.e. discharge approximation based on drainage area and topography. The model contains the infamous <strong>m</strong> parameter, which varies depending on environment. You should consult the literature for appropriate values. Unless you aren&#8217;t bothered about the TOPMODEL output, in which case leave it at 0.01.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
For catchment mode this is an important variable as it controls the peak and duration of the hydrograph generated by a rain event. It is the same as the 'm' value in TOPMODEL, that CAESAR-lisfloods hydrological model is based on. Typical values for m are from 0.02 (low - meaning low flood peaks and long duration hydrographs) to 0.005 (higher, flashier peaks) and examples of values used can be found in the CAESAR and TOPMODEL literature.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_rainfall_data_on">rainfall_data_on</h5>
<div class="paragraph">
<p>Leave set to 'yes' for now.</p>
</div>
</div>
<div class="sect4">
<h5 id="_rain_data_time_step">rain_data_time_step</h5>
<div class="paragraph">
<p>The time step in minutes. This must match the rainfall input data file timestep!</p>
</div>
</div>
<div class="sect4">
<h5 id="_spatial_var_rain">spatial_var_rain</h5>
<div class="paragraph">
<p>No for uniform rainfall input, yes to use the spatially variable option.</p>
</div>
</div>
<div class="sect4">
<h5 id="_in_out_difference">in_out_difference</h5>
<div class="paragraph">
<p>Speeds up the model running, during periods of approximate steady state (in terms of water in vs water out of the outlet point). Set to zero to disallow this feature. Otherwise, give the maximum allowed difference in cumecs.</p>
</div>
</div>
<div class="sect4">
<h5 id="_min_q_for_depth_calc">min_Q_for_depth_calc</h5>
<div class="paragraph">
<p>This is a threshold above which the model will calculate a flow depth. If this is not set, then it wastes time calculating flow depths of fractions of a mm which will not cause any erosion or deposition. This variable dependent upon grid cell size, and as a guide set this parameter to 0.1 per meter cell size For example a DEM with 10m cell size will have a Min Q of 0.1, and a DTM with 50m cell size will have a Min Q of 0.5.</p>
</div>
</div>
<div class="sect4">
<h5 id="_max_q_for_depth_calc">max_Q_for_depth_calc</h5>
<div class="paragraph">
<p>This can be important for the hydrological model - which will add water for every cell greater than Min Q - but less than the limit set here. In other words, reducing this value will force water to be added more in the headwaters rather than progressively down through the catchment.</p>
</div>
</div>
<div class="sect4">
<h5 id="_water_depth_erosion_threshold">water_depth_erosion_threshold</h5>
<div class="paragraph">
<p>The model will only calculate erosion above water depths of this value in <strong>metres</strong>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_slope_on_edge_cell">slope_on_edge_cell</h5>
<div class="paragraph">
<p>The slope for the exit cells on the edges of the model domain. Lisflood-FP requires a slope for these cells in order to calculate a water depth and thus flow out from the model. This is actually quite important in controlling the erosion and deposition that occurs along the far right hand side of the DEM. Set too low and you will get deposition, too high and scour heading back upstream. To set this value, calculate the mean valley floor (near channel) slope for the channel near where it exits.</p>
</div>
</div>
<div class="sect4">
<h5 id="_evaporation_rate">evaporation_rate</h5>
<div class="paragraph">
<p>(ignore for now)</p>
</div>
</div>
<div class="sect4">
<h5 id="_courant_number">courant_number</h5>
<div class="paragraph">
<p>Courant number' is a value that controls the numerical stability and speed of operation of the flow model. More details can be found in Bates et al (2009). It should only range between 0.2 and 0.7. Higher values increase the model time step but are more unstable. Stability and thus values also depends upon the grid cell size. Larger cells (e.g. 20m, 50m+) can take values of 0.7, smaller cells (e.g. 2m) may need the smallest value (0.2). Stability is also linked to the erodelimit value (sediment tab) which controls the amount of sediment that can be eroded or deposited from a cell. Reccomended values are 0.5 for 50m dem, 0.2 for 10m or less.</p>
</div>
</div>
<div class="sect4">
<h5 id="_froude_num_limit">froude_num_limit</h5>
<div class="paragraph">
<p>If too much flow is allowed between cells per time step, then this can lead to checkerboarding effects - which can also be controlled by lowering the Courant number above. In addition the model can be set to prevent flows exceeding a froude number (specified in this box) passing between cells. The default value is 0.8 resulting in sub-critical flow - it can be set higher if you like and in many circumstances works fine at 1. You may want to use lower values (e.g the default or possibly even lower) if working with deep flows (including lakes) at fine grid cell resolutions.</p>
</div>
<div class="paragraph">
<p>Of course restricting the flow according to froude number has the knock on effect of reducing the speed of a flood wave moving through a reach - can also cause raised water depths and can reduce erosion rates.</p>
</div>
</div>
<div class="sect4">
<h5 id="_mannings_n">mannings_n</h5>
<div class="paragraph">
<p>The Roughness co-efficient used by the water flow model. Look up suitable values here: <a href="http://www.fsl.orst.edu/geowater/FX3/help/8_Hydraulic_Reference/Mannings_n_Tables.htm" class="bare">http://www.fsl.orst.edu/geowater/FX3/help/8_Hydraulic_Reference/Mannings_n_Tables.htm</a></p>
</div>
</div>
<div class="sect4">
<h5 id="_hflow_threshold">hflow_threshold</h5>
<div class="paragraph">
<p>This is a parameter in the Lisflood FP flow model. It relates directly to the hflow parameter in papers describing the Lisflood FP model. hflow is the water surface elevation between two cells. A threshold (this value) is usually used to prevent the flow model from trying to move water when there are very small gradients between cells. A good default value is 0.00001 (the units are in m).</p>
</div>
</div>
<div class="sect4">
<h5 id="_num_unique_rain_cells">num_unique_rain_cells</h5>
<div class="paragraph">
<p>For spatially variable rainfall mode. The number of different areas of rainfall you are using.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_vegetation">14.4.6. Vegetation</h4>
<div class="paragraph">
<p>(Not yet tested!)</p>
</div>
<div class="sect4">
<h5 id="_vegetation_on">vegetation_on</h5>

</div>
<div class="sect4">
<h5 id="_grass_grow_rate">grass_grow_rate</h5>

</div>
<div class="sect4">
<h5 id="_vegetation_crit_shear">vegetation_crit_shear</h5>

</div>
<div class="sect4">
<h5 id="_veg_erosion_prop">veg_erosion_prop</h5>

</div>
</div>
<div class="sect3">
<h4 id="_hillslope">14.4.7. Hillslope</h4>
<div class="paragraph">
<p>The hillslope model in LSDCatchment model is very rudimentary at present. Stay tuned for more updates.</p>
</div>
<div class="sect4">
<h5 id="_creep_rate">creep_rate</h5>

</div>
<div class="sect4">
<h5 id="_slope_failure_thresh">slope_failure_thresh</h5>
<div class="paragraph">
<p>Landsliding is also very rudimentary. Slopes at this given angle in degrees will fail.</p>
</div>
</div>
<div class="sect4">
<h5 id="_soil_erosion_rate">soil_erosion_rate</h5>

</div>
<div class="sect4">
<h5 id="_soil_j_mean_depends">soil_j_mean_depends</h5>

</div>
<div class="sect4">
<h5 id="_call_muddpile_model">call_muddpile_model</h5>

</div>
</div>
<div class="sect3">
<h4 id="_write_output_rasters">14.4.8. Write Output Rasters</h4>
<div class="sect4">
<h5 id="_raster_output_interval">raster_output_interval</h5>
<div class="paragraph">
<p>In minutes of simulated time</p>
</div>
</div>
<div class="sect4">
<h5 id="_write_waterdepth_file">write_waterdepth_file</h5>
<div class="paragraph">
<p>Writes the current water depths (in metres). NoData is written where the water depth is zero, allowing you to overlay this raster onto a hillshade or similar.</p>
</div>
</div>
<div class="sect4">
<h5 id="_waterdepth_outfile_name">waterdepth_outfile_name</h5>

</div>
<div class="sect4">
<h5 id="_write_elev_file">write_elev_file</h5>
<div class="paragraph">
<p>Writes the current elevation of the terrain</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_running_the_code_in_parallel">14.5. Running the code in Parallel</h3>
<div class="paragraph">
<p>Some notes on how the code runs in parallel.</p>
</div>
</div>
<div class="sect2">
<h3 id="_notes_for_hpc_use">14.6. Notes for HPC use</h3>
<div class="paragraph">
<p>Notes on using the code on HPC clusters.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_landscape_evolution_modelling_with_lsdtopotools">15. Landscape Evolution Modelling with LSDTopoTools</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The LSD Topo Toolbox contains a landscape evolution model. The model implementation is contained in the LSDRasterModel files. The driver file is <code>model_driver.cpp</code>. The landscape model is partly based on the FastScape algorithm <a href="http://www.sciencedirect.com/science/article/pii/S0169555X12004618">(Braun 2013)</a>, an efficient method for solving the stream power law for fluvial incision, as well as the MUDDPile algorithms for hillslope evolution. It contains both hillslope and fluvial components, which can be run individually, simulating a single hillside for example, or together, to simulate whole landscape evolution. The model will run from default parameters if none are supplied, but the user can also specify their own choice of parameters for the model run, which are detailed below.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Parameter File</div>
<div class="paragraph">
<p>The parameter file is just a plain text file with the following layout:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console"># Template for parameter file
Run Name:		default_name
NRows:			100
NCols:			100
Resolution:		1
Boundary code:		bnbn 	North, east, south, west
# b = base level, p = periodic, n = no flow (default)
Time step:		50
End time:		2000
End time mode:		1	 (if 1, wait for steady state to set the time to count down)
Uplift mode:		0	 Block uplift
Max uplift:		0.001
Tolerance:		0.0001
Print interval:		5
#Periodicity:		1000

#####################
Fluvial:		on
K:			0.01
m:			0.5
n:			1
K mode:			0	constant
#K amplitude:		0.005

#####################
Hillslope:		on
Non-linear:		off
Threshold drainage:	-1	(if negative, ignored)
D:			0.05
S_c:			30	degrees
D mode:			0	Constant
#D amplitude:		0.005

#####################
Isostasy:		off
Flexure:		off
Rigidity:		1000000</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_model_parameters_and_components">15.1. Model Parameters and Components</h3>
<div class="sect3">
<h4 id="_model_domain">15.1.1. Model Domain</h4>
<div class="paragraph">
<div class="title">Run Name</div>
<p>This is the name that will be appened to all output files generated during the model run. The model will check to see if this name has already been used before overwriting existing output files.</p>
</div>
<div class="paragraph">
<div class="title">NRows</div>
<p>This is the number of rows in the model domain. You can also think of it as the <em>y</em> dimension of the model grid.</p>
</div>
<div class="paragraph">
<div class="title">NCols</div>
<p>This is the number of columns in the model domain. You can also think of it as thee <em>x</em> dimension of the model grid.</p>
</div>
<div class="paragraph">
<div class="title">Resolution</div>
<p>The resolution of the model grid. The size in metres that a single grid cell represents.</p>
</div>
<div class="paragraph">
<p>Boundary code
This code determines the output sides of the model grid. I.e. which sides are for sediment output and which are not. The <em>b</em> represents base level, <em>n</em> represents no flow, and <em>p</em> represents periodic boundary conditions.</p>
</div>
<div class="paragraph">
<div class="title">Time step</div>
<p>The model timestep, <em>dt</em></p>
</div>
<div class="paragraph">
<div class="title">End time</div>
<p>The end time for the model run</p>
</div>
<div class="paragraph">
<div class="title">End time mode</div>
<p>This sets the model to either run until it reaches steady state (=1), or until a specified time (=0).</p>
</div>
<div class="paragraph">
<div class="title">Uplift mode</div>
<p>Instructs the model to use block, uniform uplift, or an uplift field.</p>
</div>
<div class="paragraph">
<div class="title">Max uplift</div>
<p>The uplift rate (m/yr)</p>
</div>
<div class="paragraph">
<div class="title">Tolerance</div>
<p>This parameter sets the iteration tolerance value in the LSDRasterModel object. The value is related to the implicit solver and when the solution is considered to be 'converged upon' and the numerical soultion solved. (DAV - needs more explanation?)</p>
</div>
<div class="paragraph">
<div class="title">Print interval</div>
<p>The output file interval.</p>
</div>
</div>
<div class="sect3">
<h4 id="_fluvial_component">15.1.2. Fluvial Component</h4>
<div class="paragraph">
<div class="title">Fluvial</div>
<p>Turns the fluvial component <strong>on</strong> or <strong>off</strong>, with these respective keywords.</p>
</div>
<div class="paragraph">
<div class="title">K</div>
<p>The <em>K</em> paramter used in the many forms of the stream power equation and its derivatives. <em>K</em> can also be thought of as the erodibility. Typical values for K are something like 0.0001 to 0.002, but these can vary significantly between different lithologies/environments etc. The default is 0.0002.</p>
</div>
<div class="paragraph">
<div class="title">m</div>
<p>The <em>m</em> exponent of the stream power law. Typical values of the m/n ratio are between 0.3 and 0.7, but consult the literature if it is availble for your study area. The ratio is related to the concavity of the idealised river profile. The default value of <em>m</em> is 0.5.</p>
</div>
<div class="paragraph">
<div class="title">n</div>
<p>The <em>n</em> exponent of the stream power law. Typical values are around 1.0. (Which is the default value). The above parameters are related to each other in the stream power equation as below:</p>
</div>
<div class="paragraph">
<p>\(I = KA^mS^n\)</p>
</div>
<div class="paragraph">
<p>where <em>I</em> is the incision rate, <em>A</em> is the drainage area, and <em>S</em> is the slope of the channel. The fluvial component of the model is based on this equation, which is a good approximation in many bedrock mountainous landscapes, though your mileage may vary.</p>
</div>
<div class="paragraph">
<div class="title">K mode</div>
<p>Sets the K value to be constant (0 is default, meaning constant).</p>
</div>
</div>
<div class="sect3">
<h4 id="_hillslope_component">15.1.3. Hillslope Component</h4>
<div class="paragraph">
<p>The hillslope component comes in two flavours, a linear model and a non-linear one.</p>
</div>
<div class="paragraph">
<div class="title">Hillslope</div>
<p>Turns the hillslope component <strong>on</strong> or <strong>off</strong></p>
</div>
<div class="paragraph">
<div class="title">Non-linear</div>
<p>Sets the hillslope law to linear or non-linear. (<strong>on</strong> or <strong>off</strong>)</p>
</div>
<div class="paragraph">
<div class="title">D</div>
<p>The soil transport coefficient. The <em>D</em> value is used in calculating the soil creep functions in the model.</p>
</div>
<div class="paragraph">
<div class="title">S_c</div>
<p>The critical slope angle. The default is 30 degrees.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_running_the_model_2">15.2. Running the Model</h3>
<div class="paragraph">
<p>Once compiled, the model is run using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./model.out [parameter.file] [run_name]</code></pre>
</div>
</div>
<div class="paragraph">
<p>Screen output should help the user see if the components/parameters have run as expected.</p>
</div>
</div>
<div class="sect2">
<h3 id="_model_output">15.3. Model Output</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="_software">Appendix A: Software</h2>
<div class="sectionbody">
<div class="paragraph">
<p>There are quite a few different components you need to get working on your system to perform the examples in this book (sorry!).
Some of these are essential, and some are optional and included for completeness.
In the following appendices, instructions for getting them installed on <a href="#_setting_up_on_windows">Windows</a>
or <a href="#_setting_up_on_linux">Linux</a> are included. Since the author of this book does not have any computers running on friut-based operating system,
I&#8217;m afraid instructions for getting the software working on such systems will require a bit of homework,
but in theory installation on such systems should be similar to installation on Linux systems.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">BEFORE YOU READ ANY OF THIS</div>
<div class="paragraph">
<p>These sections are for information only: if you just want to get LSDTopoTools working all you need to read is the section on <a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_essentials">A.1. Essentials</h3>
<div class="paragraph">
<p>The following tools are core to the contents of this book,
and will need to be installed before you can work on the exercises in the book.</p>
</div>
<div class="sect3">
<h4 id="_git_2">A.1.1. Git</h4>
<div class="paragraph">
<p><a href="https://git-scm.com/">Git</a> is version control software. It helps you keep track of changes to your scripts, notes, papers, etc.
It also facilitates communication and collaboration through the online communities <a href="https://github.com/">github</a> and <a href="https://bitbucket.org/">bitbucket</a>.
The source code for LSDTopoTools is on <a href="https://github.com/">github</a> so by using <a href="https://git-scm.com/">Git</a> you can make sure you always have the latest version of the software.</p>
</div>
</div>
<div class="sect3">
<h4 id="_c_tools">A.1.2. C++ tools</h4>
<div class="paragraph">
<p>A number of scientific programs are written in these languages so information on how to get them working on your windows machine is incluided here for completeness.</p>
</div>
<div class="paragraph">
<p>To get these working you will need</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The compiler. This is what translates the program into something the computer can understand.</p>
</li>
<li>
<p>The tool <code>make</code>, which automates building programs.</p>
</li>
<li>
<p>The tool <code>gdb</code>. which stands for gnu debugger, a tool for debugging code.</p>
</li>
<li>
<p>The tool <code>gprof</code>, which is a profiler: it allows you to see which parts of your code are using the most computational resources.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_python_2">A.1.3. Python</h4>
<div class="paragraph">
<p>Python is a programming language used by many scientists to visualize data and crunch numbers. You can also use it to automate data management.</p>
</div>
<div class="paragraph">
<p>You will need:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The <a href="https://www.python.org/">python programming language</a></p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><a href="http://www.scipy.org/">Scipy</a>, for scientific python. It includes lots of useful packages like</p>
<div class="olist lowerroman">
<ol class="lowerroman" type="i">
<li>
<p><a href="http://www.numpy.org/">Numpy</a> for fast numerics.</p>
</li>
<li>
<p><a href="http://matplotlib.org/">Matplotlib</a> for plotting.</p>
</li>
<li>
<p><a href="http://pandas.pydata.org/">Pandas</a> for data analysis.</p>
</li>
</ol>
</div>
</li>
<li>
<p><a href="https://pypi.python.org/pypi/pip">pip</a> for python package management.</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_gdal_3">A.1.4. GDAL</h4>
<div class="paragraph">
<p><a href="http://www.gdal.org/">GDAL (the Geospatial Data Abstraction Library)</a> is used to manipulate topographic data so that it can be fed into LSDTopoTools.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_useful_extras">A.2. Useful extras</h3>
<div class="paragraph">
<p>You could find these tools useful. In particular, my documentation is written using something called <a href="http://asciidoctor.org/">asciidoctor</a>, which is implemented in a programming language called Ruby.</p>
</div>
<div class="sect3">
<h4 id="_a_virtual_machine">A.2.1. A virtual machine</h4>
<div class="paragraph">
<p>This is essential if you are going to follow our instructions for <a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a>,
which is propbably what you will want to do if you do not have a Linux machine.</p>
</div>
<div class="paragraph">
<p>To do this you will need to intall <a href="https://www.vagrantup.com/">Vagrant</a> and <a href="https://www.virtualbox.org/">VirtualBox</a>.</p>
</div>
</div>
<div class="sect3">
<h4 id="_geographic_information_software">A.2.2. Geographic Information Software</h4>
<div class="paragraph">
<p>If you want to look at the data produced by LSDTopoTools, you could use our lightweight python tools,
but in many cases you will want to use a GIS.</p>
</div>
<div class="paragraph">
<p>The common options are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.esri.com/software/arcgis">ArcGIS</a> The GIS most frequently used by commercial enterprise and government.
It is commercial software and rather expensive. If your organisation has a licence, fantastic.
However not all users of our software will have a licence so all tutorials in this book will be based on open source software.</p>
</li>
<li>
<p><a href="http://www.qgis.org/en/site/">QGIS</a> A GIS that behaves much like ArcGIS, but is open source.</p>
</li>
<li>
<p><a href="http://www.uoguelph.ca/~hydrogeo/Whitebox/">Whitebox</a> A very lightweight, open source GIS written in java. This is handy since it is quite portable:
there is nothing to install, just copy the <code>.jar</code> file on your computer and away you go!</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_ruby">A.2.3. Ruby</h4>
<div class="paragraph">
<p>Ruby is a programming language used frequently by web developers and has many package for building documentation and automating collection of data over the internet.
In this book we will really only use it for documentation, but there is a large ecosystem of open source tools available in Ruby.
It hasn&#8217;t been adopted to a great extent by the scientific community but you may still find useful tools, particularly if you are gathering online information.</p>
</div>
<div class="paragraph">
<p>The main reason we use Ruby is to generate our documentation using <a href="http://asciidoctor.org/">Asciidoctor</a>,
so if you fancy contributing to the documentation of getting the latest version, you will need to get Ruby and some associated tools.</p>
</div>
<div class="paragraph">
<p>You will need:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The <a href="https://www.ruby-lang.org/en/">Ruby</a> programming language</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p><a href="https://rubygems.org/">Rubygems</a> for updating ruby.</p>
</li>
<li>
<p><a href="http://bundler.io/">bumdler</a> for managing updates and making sure scripts are up to date.</p>
</li>
<li>
<p><a href="http://rubyinstaller.org/add-ons/devkit/">RubyDev kit</a> which is needed for some other Ruby packages.</p>
</li>
<li>
<p><a href="http://asciidoctor.org/">asciidoctor</a> for making notes, documentation and books.</p>
</li>
<li>
<p><a href="https://github.com/oneclick/rubyinstaller/wiki/Development-Kit">Ruby DevKit</a> which is used by some Ruby extensions.</p>
</li>
</ol>
</div>
</li>
<li>
<p>In addition you will need <a href="https://nodejs.org/">Node.js</a> for some of the Ruby tools to work.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_setting_up_on_windows">Appendix B: Setting up on Windows</h2>
<div class="sectionbody">
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You should only do this if you are some kind of Windows purist (does such a thing exist?). LSDTopoTools works best in Linux and at the moment the best way to get a linux server working within your Windows machine is to use Vagrant. Instructions can be found here: <a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>For the kind of scientific tools we will be using, Windows can sometimes be a bit difficult,
since many scientific developers work in Linux and so installation for their software is easiest in a Linux environment.
However, you can get Windows to behave a bit like Linux which will make your life easier for the purposes of installing the required software for the examples here.</p>
</div>
<div class="paragraph">
<p>Alternatively, you can <a href="#_turning_your_windows_machine_into_a_linux_machine">get a "virtual" Linux machine running on your Windows machine</a>.</p>
</div>
<div class="paragraph">
<p><strong>Let me type that in bold text: it will be far easier to do things in a Linux environment than in a Windows environment.
I strongly encourage you to <a href="#_turning_your_windows_machine_into_a_linux_machine">build a virtual machine</a>.</strong></p>
</div>
<div class="sect2">
<h3 id="_working_with_the_powershell">B.1. Working with the powershell</h3>
<div class="paragraph">
<p>Much of what we do will be through a powershell window.
This is a text-based interface into your windows system that allows you to install software and run scripts and code.
It functions like a linux terminal.</p>
</div>
<div class="paragraph">
<p>First of all, you need to get a powershell running. On my windows version, you just type <strong>powershell</strong> into the bit of Windows where you searh for files or programs (it varies based on what windows system you are using).
You should be able to find a way to get a powershell on your version of windows through the power of the internet.</p>
</div>
<div class="sect3">
<h4 id="_starting_a_powershell_session">B.1.1. Starting a powershell session</h4>
<div class="paragraph">
<p>First, you will need to open an administrator powershell.
In your powershell window, type</p>
</div>
<div class="literalblock">
<div class="content">
<pre>PS&gt; Start-Process powershell -Verb runAs</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>PS&gt;</code> denotes the powershell propmpt.
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
You might not have administrator priviliges on your computer.
In that case you will need to convince the administrator to install everything for you,
or you can ask them to install a linux virtual machine, which is described in the section <a href="#Turning-your-windows-machine-into-a-linux-machine">[Turning-your-windows-machine-into-a-linux-machine]</a>.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_windows_installation_programs">B.2. Windows installation programs</h3>
<div class="paragraph">
<p>Take a deep breath. I am afraid this is going to take a while.
It can be done, but you may need psychological treatment before the end.
You might consider following our instructions for <a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a> instead of trying to get the software installed within a Windows environment.</p>
</div>
<div class="sect3">
<h4 id="_package_management">B.2.1. Package management</h4>
<div class="paragraph">
<p>If you are a windows user, you are probably used to installing software on windows the traditional way using installation files.
The tools we are using involve many linked programs, and installing them by downloading windows installers from their respective websites can be tiresome.
An alternative is to use something called a <a href="https://en.wikipedia.org/wiki/Package_manager">machine package manager</a>, which makes installing software a bit less of a hassle.</p>
</div>
<div class="sect4">
<h5 id="_chocolatey_package_manager">Chocolatey package manager</h5>
<div class="paragraph">
<p>Here we will use a machine package manager built specifically for windows called <a href="https://chocolatey.org/">chocolatey</a>.</p>
</div>
<div class="paragraph">
<p>To install <strong>chocolatey</strong>, type in the following in your <strong>administrative</strong> powershell:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>PS&gt; iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))</pre>
</div>
</div>
<div class="paragraph">
<p>You then just have to sit back and wait while it installs.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
To test if chocolatey is working after the installation, type <code>choco -v</code>. If you get an error saying it is not a recognized name of a cmdlet or path, then simply close your powershell windows and open new ones.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Once you have chocolatey installed, you can get the additional packages that are required for the tools we use in this book by using the <code>choco</code> command.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_git_3">B.2.2. Git</h4>
<div class="paragraph">
<p>You can install git by downloading the installation package from the <a href="https://desktop.github.com/">Github desktop</a> website.
Alternatively, you can use chocolatey:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; choco install git</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can check if it works in the command line by calling</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; git --version</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you install git desktop, you will get a <a href="https://git-scm.com/book/en/v2/Git-in-Other-Environments-Git-in-Powershell">git powershell</a> link on your desktop.
This powershell is quite useful when using git since it does things like highlights files in different colours depending on status
(e.g., if they have been modified or not or of they are being tracked).</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_tools_for_c">B.3. Tools for C++</h3>
<div class="paragraph">
<p>There are several options for installing C++ and fortran compilers on your Windows machine.
Two popular options, <a href="http://www.mingw.org/">Mingw</a> and <a href="https://www.cygwin.com/Cygwin" class="bare">https://www.cygwin.com/Cygwin</a>] install something that behaves a bit like a Linux operating system
(<a href="#_turning_your_windows_machine_into_a_linux_machine">but perhaps it is easier just to set up Linux within your Windows computer?</a>).</p>
</div>
<div class="paragraph">
<p>Another option for C++ is to install the developer toolkit from Microsoft, <a href="https://www.visualstudio.com/en-us/products/visual-studio-express-vs.aspx">Visual Studio express</a>.
You can install the 2013 version using chocolatey:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; choco install visualstudioexpress2013windowsdesktop</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also install the software by downloading from the <a href="https://www.visualstudio.com/en-us/products/visual-studio-express-vs.aspx">Visual Studio website</a>.</p>
</div>
<div class="sect3">
<h4 id="_cygwin">B.3.1. Cygwin</h4>
<div class="paragraph">
<p>To install <a href="https://www.cygwin.com/">Cygwin</a>, you must first install the program
<a href="https://www.cygwin.com/setup-x86.exe">setup-x86.exe</a> for a 32 bit system or
<a href="https://www.cygwin.com/setup-x86_64.exe">setup-x86_64</a> for a 64 bit system.</p>
</div>
<div class="paragraph">
<p>When you run <code>setup-*.exe</code>, you will get a window that looks like this:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/cygwin_setup.jpg" alt="Cygwin setup window">
</div>
<div class="title">Figure 21. Cygwin setup.</div>
</div>
<div class="paragraph">
<p>Scroll down the the <code>devel</code> menu and select the following packages:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>binutuls
gcc core
g++
gfortran
gdb
make</pre>
</div>
</div>
<div class="paragraph">
<p>You can also install all sorts of other things from cygwin like <strong>Ruby</strong>, <strong>Git</strong> and <strong>Python</strong>, but you don&#8217;t need to do that if you&#8217;ve already installed them.
In fact, you might want to make sure <strong>git</strong> is not selected if you have installed the Git powershell from the github desktop application.</p>
</div>
<div class="paragraph">
<p>Once you have selected the things you need, select <strong>next</strong>.
You might need to install a bunch of additional packages because your selected packages depend on them.
If this is your first time installing cygwin go and get a drink or have lunch since installation will take some time.</p>
</div>
</div>
<div class="sect3">
<h4 id="_c_libraries">B.3.2. C++ libraries</h4>
<div class="paragraph">
<p>Some of our more specialized components require libraries.
These are very difficult to install on Windows, and you will possibly self harm if you attempt to do so.
Why don&#8217;t you <a href="#_turning_your_windows_machine_into_a_linux_machine">make a virtual Linux machine instead</a>?</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_python_3">B.4. Python</h3>
<div class="paragraph">
<p>Python in Windows can be a little bit more difficult to manage than python in Linux.
You can get python through chocolatey, but it makes installing extra packages a bit of a pain.</p>
</div>
<div class="paragraph">
<p>Instead, you probably want to install python as part of a package that includes all the handy python libraries and associated programs.</p>
</div>
<div class="paragraph">
<p>The popular ones are:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="http://python-xy.github.io/">Python(x,y)</a> contains all manner of useful packages for scientists.
I have found, however, that updating this is not so straightforward;
if you have a look at the <a href="http://python-xy.github.io/downloads.html">Python(x,y) downlaods page</a> you will see that the updates have dependencies that dead end,
so if you are on, say, Python(x,y) 2.6.X you will need to reinstall Python(x,y) 2.7.X if you want continued updates.
Python(x,y) is also huge: it includes <strong>many</strong> python packages, most of which you will never use.</p>
</li>
<li>
<p><a href="http://winpython.sourceforge.net/">Winpython</a> is another python package that has a nice updating interface.</p>
</li>
<li>
<p><a href="https://store.continuum.io/cshop/anaconda/">Anaconda</a> is another scientific package that includes all sorts of smaller packages.
It seems to be able to handle updates better than Python(x,y) through its <code>conda</code> updating interface.</p>
</li>
<li>
<p><a href="http://conda.pydata.org/miniconda.html">miniconda</a> uses the same <code>conda</code> updating interface as <code>anaconda</code>, the difference is that with <code>miniconda</code> things arene&#8217;t installed automatically,
so you will have to figure out what you want and then use <code>conda</code> to install new packages (e.g., pandas, scipy, gdal, etc.)</p>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_gdal_windows_installation">B.5. GDAL windows installation</h3>
<div class="paragraph">
<p>You can download GDAL for windows from this website: <a href="https://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries" class="bare">https://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries</a>.
If you are on Windows, however, you might want to just use the GDAL bindings in python.
Or, you can skip all of this and build a virtual linux machine on your windows computer.</p>
</div>
</div>
<div class="sect2">
<h3 id="_ruby_2">B.6. Ruby</h3>
<div class="paragraph">
<p>You can check to see if Ruby is installed on your system by typing</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; ruby -v</code></pre>
</div>
</div>
<div class="paragraph">
<p>and you can check the Rubygems version with</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; gem -v</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="_install_ruby_version_1">B.6.1. Install Ruby (version 1)</h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Download and install Ruby: <a href="https://www.ruby-lang.org/en/documentation/installation/#rubyinstaller" class="bare">https://www.ruby-lang.org/en/documentation/installation/#rubyinstaller</a>. We have used version 2.2.</p>
</li>
<li>
<p>Download and install Ruby Gems: <a href="https://rubygems.org/pages/download" class="bare">https://rubygems.org/pages/download</a>. To install this, you need to download it and then open a powershell window, navigate to the folder with gems in it, and run:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; \folder\with\rubygems\&gt; ruby setup.rb</code></pre>
</div>
</div>
</li>
<li>
<p>Download the Ruby devtools: <a href="http://rubyinstaller.org/downloads/" class="bare">http://rubyinstaller.org/downloads/</a>. You need to unzip this and run two things:</p>
<div class="listingblock">
<div class="content">
<pre>PS&gt; \folder\with\DevKit\&gt; ruby dk.rb init
PS&gt; \folder\with\DevKit\&gt; ruby dk.rb install</pre>
</div>
</div>
</li>
<li>
<p>Now install bundler. In a powershell, you can, from anywhere, type <code>gem install bundler</code>.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_install_ruby_using_choco">B.6.2. Install Ruby using choco</h4>
<div class="paragraph">
<p>If these are not installed, install them using <a href="#_chocolatey_package_manager">chocolatey</a>
(in an <a href="#_starting_a_powershell_session">administrator powershell</a>).
While you are at it, install the RubyDev and Node.js package:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; choco install ruby
PS&gt; choco install rubygems
PS&gt; choco install ruby2.devkit
PS&gt; choco install node.js</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_fix_rubygems_on_windows">B.6.3. Fix rubygems on Windows</h4>
<div class="paragraph">
<p>At the time of this writing, rubygems is "broken" on Windows:
if you try to install a gem file you will get an error that says you cannot make an SSL connection.
You will need to fix this problem by <a href="https://gist.github.com/luislavena/f064211759ee0f806c88">copying a trust certificate into you rubygems folder</a>.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>First download the file <a href="https://raw.githubusercontent.com/rubygems/rubygems/master/lib/rubygems/ssl_certs/AddTrustExternalCARoot-2048.pem">AddTrustExternalCARoot-2048.pem</a>.</p>
</li>
</ol>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
It seems some browsers add formatting to this file when downloaded (Chrome does this, for example).
I only managed to get this fix to work after downloading the file using Internet Explorer.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic" start="2">
<li>
<p>Next, find the location of your gems installation:</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; gem which rubygems
C:/Ruby21/lib/ruby/2.1.0/rubygems.rb</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Go to the folder and then go into the SLL_certs subfolder.
In this case it is at: <code>C:/Ruby21/lib/ruby/2.1.0/rubygems/SSL_certs</code>.
Copy the <code>.pem</code> file into this folder. Rubygems should now work.</p>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_fix_rubydevkit_on_windows">B.6.4. Fix RubyDevKit on Windows</h4>
<div class="paragraph">
<p>The devkit sometimes does not work the first time around.
If you get error messages about the devkit, you should go to the devkit folder (you need to find it on your system)
and run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; ruby dk.rb init</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will generate a file called <code>config.yml</code>. Sometimes, the devkit installer will not find your Ruby installation, so you will need to add the path to your Ruby installation to this file.
For example, if your Ruby instalation is sitting in C:/Ruby21/, then you should modify the <code>config.yml</code> file to look like:</p>
</div>
<div class="listingblock">
<div class="title">The config.yml file:</div>
<div class="content">
<pre class="highlight"><code class="language-paramfile" data-lang="paramfile"># This configuration file contains the absolute path locations of all
# installed Rubies to be enhanced to work with the DevKit. This config
# file is generated by the 'ruby dk.rb init' step and may be modified
# before running the 'ruby dk.rb install' step. To include any installed
# Rubies that were not automagically discovered, simply add a line below
# the triple hyphens with the absolute path to the Ruby root directory.
#
# Example:
#
# ---
# - C:/ruby19trunk
# - C:/ruby192dev
#
---
- C:/Ruby21/</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_install_some_gems">B.6.5. Install some gems</h4>
<div class="paragraph">
<p>From here we can install some useful ruby gems.
<a href="http://asciidoctor.org/">Asciidoctor</a> is really great for writing documentation.
<a href="http://bundler.io/">Bundler</a> is useful for keeping Ruby packages up to date.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-consol" data-lang="consol">PS&gt; gem install asciidoctor
PS&gt; gem install bundler</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_if_you_use_ruby_with_java_you_will_probably_not_need_this">B.6.6. If you use Ruby with Java (you will probably not need this)</h4>
<div class="paragraph">
<p>This is for users who are trying to get a Ruby extension that uses Java installed.
If you use an extension that need a java link, you will need the gem</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; gem install rjb -v '1.4.9'</code></pre>
</div>
</div>
<div class="paragraph">
<p>But on my system this failed because you need to define the java runtime home.
To do this, you need to figure out where your java installation is, and then
define an environemnt variable $JAVA_HOME to point to this directory.</p>
</div>
<div class="paragraph">
<p>To do so, you should do this (in an administrator Powershell):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; [Environment]::SetEnvironmentVariable("JAVA_HOME", "C:\Progra~2\Java\jre_7_55", "Machine")</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that the powershell abbreviates <code>Program files (x86)</code> as Progra~2 and <code>Program Files</code> as Progra~1.</p>
</div>
<div class="paragraph">
<p>You can check to see if the appropriate path has been set with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PS&gt; Get-ChildItem Env:</code></pre>
</div>
</div>
<div class="paragraph">
<p>Unfortuately this only works in an administrator window.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_windows_installation_summary">B.7. Windows installation summary</h3>
<div class="paragraph">
<p>If you actually managed to install things on Windows without permanent emotional scarring, I offer my sincerest congratulations.
However, if you are just skipping ahead, why don&#8217;t you make your life easier and <a href="#_turning_your_windows_machine_into_a_linux_machine">make a virtual Linux machine inside your Windows computer</a>?</p>
</div>
</div>
<div class="sect2">
<h3 id="_turning_your_windows_machine_into_a_linux_machine">B.8. Turning your windows machine into a Linux machine</h3>
<div class="paragraph">
<p>The header of this section is a bit misleading,
what you are really going to do is use software to create a <a href="https://en.wikipedia.org/wiki/Virtual_machine">virtual</a> version of Linux within your Windows computer.</p>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Only do this if you want total control of your Linux enviroment. If you want us to do everything for you, read the instructions on <a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>There are a number of options, popular ones include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="http://www.parallels.com/uk/">Parallels</a> This software is proprietary.</p>
</li>
<li>
<p><a href="http://www.vmware.com/">VMWare</a> There are several flavours of this. The free version is VMware Player.</p>
</li>
<li>
<p><a href="https://www.virtualbox.org">VirtualBox</a> This is open source.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Here I&#8217;ll walk you through setting up Linux using VMware.
It just happened to be the one I tried first and it works, please do not take this as an endorsement.
One disadvantage is it doesn&#8217;t seem to have an Apple version. If you use Apple you&#8217;ll need to try to go through a similar process using <a href="https://www.virtualbox.org/">VirtualBox</a>,
which does have a version for Mac operating systems.</p>
</div>
<div class="paragraph">
<p>But, here is how you set up the VMware player.
You will need a reasonable amount of storage (say at least 30GB: you will not be able to get this back!)
and RAM (say at least 4 GB, but 8GB is better&#8230;&#8203;note that this is only used when the virtual machine is on)
A very old computer probably won&#8217;t work.
If you&#8217;ve got a computer purchased in the last few years things will probably be fine.
Note that the virtual machine permanently takes up some portion of your hard disk (you can release this protion back to your windows machine if you uninstall the virtual machine).</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>First, download VMware player. The download is currently here: <a href="https://my.vmware.com/web/vmware/free#desktop_end_user_computing/vmware_player/7_0" class="bare">https://my.vmware.com/web/vmware/free#desktop_end_user_computing/vmware_player/7_0</a>.</p>
</li>
<li>
<p>Run the installation package. Brew a cup of tea while you wait for it to install. <a href="http://www.bbc.co.uk/sport/football/teams/hibernian">Maybe surf the internet a bit</a>.</p>
</li>
<li>
<p><strong>BEFORE</strong> you set up a virtual machine, you will need to download a linux operating system!</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>We are going to use <a href="http://www.ubuntu.com/">Ubuntu</a>, just because it is stable, popular and has good documentation.
WARNING: I first attempted an installation with 64-bit Ubuntu, but it turns out my computer doesn&#8217;t allow guest 64 bit operating systems.
To fix this I just downloaded the 32 bit version of Ubuntu, which worked. However, many of my students have sucessfully installed 65 bit Ubuntu.</p>
</li>
<li>
<p>Find the downloads link and download the latest version. It will be an <code>iso</code> disk image. This will take a while. Put that time to <a href="https://www.youtube.com/user/HibernianTV">good use</a>.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Once that finishes downloading, you can set up your virtual box. First, open VMware Player.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
These menus seem to change with new releases, so just try to pick the most sensible menu options if they don&#8217;t match the instructions.
</td>
</tr>
</table>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Now click on the "Create a New Virtual Machine" option.</p>
</li>
</ol>
</div>
</li>
<li>
<p>It will ask you how you want to install the operating system. Tell it you want to use the Ubuntu disk image you just downloaded:</p>
</li>
<li>
<p>You will need to add some username information, and then you will have to pick a location for the Virtual Machine. I made a folder called <code>c:\Ubuntu</code> for it:</p>
</li>
<li>
<p>Now allocate disk space to the virtual machine. <strong>This disk space cannot be used by your windows operating system!!</strong>.
I decided to use a single file to store the disk since it should be faster.</p>
</li>
<li>
<p>The next page will say it is ready to create the virtual machine, but it has a default Memory (in my case 1 GB) allocated.
I wanted more memory so I clicked on the customize hardware button:
This allowed me to increase the memory to 2GB.</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Memory will be used when the virtual  machine is on, but when not in use the memory will revert to your original operating system.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You can change the amount of memory allocated to your virtual machine by changing the virtual machine settings from the VMware start page.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The size of the DEM you can analyse will be limited by your memory. Give the virtual machine as much memory as you can spare if you are running analysis on big DEMs.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>You might be asked to install some VMware Linux tools. You should do this, as some things won&#8217;t work if it isn&#8217;t installed.</p>
</li>
<li>
<p>Installing the operating system within the virtual machine will take ages. You might schedule this task for your lunch hour, which is what I did.
My chicken shawarma wrap was delicious, thank you for asking.</p>
</li>
<li>
<p>When Ubuntu has installed, it will look for software updates. You should install these. This will also take ages. Maybe you have a <a href="http://www.iain-banks.net/science-fiction/">book to read</a>?</p>
</li>
<li>
<p>Finally, you should be aware that the default keyboard layout is US. Getting UBUNTU to recognize a different keyboard is a bit of a pain.</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>First go to system settings.</p>
</li>
<li>
<p>Then click on language support.</p>
</li>
<li>
<p>It will need to install some stuff.</p>
</li>
<li>
<p>Go to text entry.</p>
</li>
<li>
<p>In the lower left corner click on the <code>+</code> button.</p>
</li>
<li>
<p>Add your country&#8217;s input source.</p>
</li>
</ol>
</div>
</li>
</ol>
</div>
</div>
<div class="sect2">
<h3 id="_summary_11">B.9. Summary</h3>
<div class="paragraph">
<p>By now you should be able to pull up a powershell and call the essential programs we will be working with in this course.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_setting_up_on_linux">Appendix C: Setting up on Linux</h2>
<div class="sectionbody">
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
These instructions involve building your own operating system with a virtual machine. You can do this if you want more control, but most users should follow the simpler process of creating an lSDTopoTools server using Vagrant. Instructions can be found here: <a href="#_installing_lsdtopotools_on_a_windows_machine_using_virtualbox_and_vagrant">Installing LSDTopoTools on a Windows machine using VirtualBox and Vagrant</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Setting up your system on Linux is considerably easier than setting up on Windows.
Before doing anything, open a terminal window. The <code>$</code> symbol below indicates commands typed into the terminal window.</p>
</div>
<div class="paragraph">
<p>In Ubuntu, the terminal window is opened with <code>ctrl</code>+<code>alt</code>+<code>T</code>. You can also find it in the applications menu under accessories.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
These commands are for <strong>Ubuntu</strong> and <strong>Debian</strong> flavors of Linux. Other flavors of Linux use different package managers, such as <a href="http://yum.baseurl.org/">yum</a>.
If you don&#8217;t use Debian of Ubuntu, you will need to look up the installation guidelines for the programs below.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_git_4">C.1. Git</h3>
<div class="paragraph">
<p>To check if git is working, type</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git --version</code></pre>
</div>
</div>
<div class="paragraph">
<p>If it isn&#8217;t installed, install it with</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get install git</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_c_tools_2">C.2. C++ tools</h3>
<div class="paragraph">
<p>You can check if these are working by typing (this assumes you are using the <a href="https://gcc.gnu.org/">GNU compilers</a>)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ g++</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can install these with</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get install g++</code></pre>
</div>
</div>
<div class="paragraph">
<p>These seem to install <code>gdb</code> and <code>make</code>, which is convenient.</p>
</div>
<div class="sect3">
<h4 id="_c_libraries_2">C.2.1. C++ libraries</h4>
<div class="paragraph">
<p>For more specialized versions of the code, you will need some libraries. Installing these can sometimes be tedious,
sou you might want to wait until you actually need them before you install.</p>
</div>
<div class="sect4">
<h5 id="_spectral_analysis">Spectral analysis</h5>
<div class="paragraph">
<p>Any analyses that use the RasterSpectral objects, which includes the LSDRasterModel, require the <a href="http://www.fftw.org/"><strong>fast fourier transform libraries</strong></a>. In the source code, you will find <code>#include</code> statements for these libraries, and corresponding library flags in the makefile: <code>-lfftw3</code>. In the RasterSpectral source files, we assume that you will have a fast fourier transform folder in your toplevel LSDTopoTools directory.</p>
</div>
<div class="paragraph">
<p>You can download FFTWv3 here: <a href="http://www.fftw.org/download.html" class="bare">http://www.fftw.org/download.html</a></p>
</div>
<div class="paragraph">
<p>Installation should be fairly easy. Go to the FFTW download folder and run</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ./configure
$ make
$ make install</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_the_landscape_evolution_model">The landscape evolution model</h5>
<div class="paragraph">
<p>Our landscape evolution model (LSDRasterModel) requires <a href="http://www.fftw.org/">FFTW</a>, <a href="http://www.boost.org/">Boost</a> and <a href="http://www.simunova.com/mtl4">MTL</a>.</p>
</div>
<div class="paragraph">
<p><a href="http://www.boost.org/"><strong>Boost</strong></a>. Boost contains a large number of header only libraries.
You will need to know where you have unzipped them! But the good news is that you don&#8217;t need to install anything.</p>
</div>
<div class="paragraph">
<p>More information is here: <a href="http://www.boost.org/doc/libs/1_59_0/more/getting_started/unix-variants.html" class="bare">http://www.boost.org/doc/libs/1_59_0/more/getting_started/unix-variants.html</a></p>
</div>
<div class="paragraph">
<p>The <a href="http://www.simunova.com/home">Matrix Template Library version 4</a> is also requires:
this does some heavy duty computation on sparse matrices that is required for the landscape evolution model.</p>
</div>
<div class="paragraph">
<p>You can get download and installation instructions here: <a href="http://www.simunova.com/node/189" class="bare">http://www.simunova.com/node/189</a></p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_the_swath_and_point_cloud_tools">C.3. The Swath and Point Cloud tools</h3>
<div class="paragraph">
<p>As mentioned in previous sections, these tools require the use of the following libraries and tools, which themselves come with further dependencies.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The <code>cmake</code> utility. This is like <code>make</code> but is required for our tools that examine point clouds,
since it is required by something called the <a href="http://pointclouds.org/">point cloud library</a>.</p>
</li>
<li>
<p><a href="http://pointclouds.org/">pcl</a>: The Point Cloud Library.</p>
</li>
<li>
<p><a href="http://www.liblas.org/">libLAS</a>: a library for working with LAS format data.</p>
</li>
</ol>
</div>
<div class="sect3">
<h4 id="_pcl">C.3.1. PCL</h4>
<div class="paragraph">
<p>Before you can install PCL however, it itself is dependent on some other things&#8230;&#8203;</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>blas (blas-devel)</p>
</li>
<li>
<p>eigen3 (eigen-devel)</p>
</li>
<li>
<p>flann</p>
</li>
<li>
<p>libLAS</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>PCL, blas-devel, flann, eigen3 etc. can be installed in linux using the yum or apt-get commands in many distributions:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">yum install blas-devel flann-devel eigen3-devel pcl-devel</code></pre>
</div>
</div>
<div class="paragraph">
<p>You will need to check the exact names of these packages in your package repository manager first.</p>
</div>
<div class="paragraph">
<p>If you can&#8217;t install using the above method, you will have to do a manual install following the instruction on the relevant websites. The PCL website is a good place to start for guidance.</p>
</div>
<div class="paragraph">
<p>After installing these, you may run into the further problem that the location of the libraries on your system are not where the compiler thinks they are, because the installation folders are named by the version number, e.g. <code>/pcl-1.7.2</code> rather than just <code>/pcl</code>. You can get around this by creating symbolic links to these folders. From the include directory on your system, (mine was /usr/include/), type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">ln -s /usr/include/pcl-x.x.x /usr/include/pcl</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">and the same goes for the <code>eigen</code> library</dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">ln -s /usr/include/eigen3 /usr/include/Eigen</code></pre>
</div>
</div>
<div class="paragraph">
<p>Right, we are nearly ready to go!</p>
</div>
<div class="paragraph">
<p>Except for the last library dependency&#8230;&#8203;</p>
</div>
</div>
<div class="sect3">
<h4 id="_liblas">C.3.2. libLAS</h4>
<div class="paragraph">
<p><a href="http://www.liblas.org/" class="bare">http://www.liblas.org/</a></p>
</div>
<div class="paragraph">
<p>If you thought installing <strong>pcl</strong> was a faff, <strong>libLAS</strong> takes things to a new level. It isn&#8217;t included in most linux distribution package repositories, so you have to install it manually. Do not confuse it with the similarly named <code>Blas</code> or <code>libblas</code>, which ARE in the linux pacakge repositories but have nothing to do with the libLAS that we want (BLAS is a basic linear algebra library).</p>
</div>
<div class="paragraph">
<p>First of all, it is dependent on the <code>libgeotiff-devel</code> library, so go ahead and install that using yum or apt-get:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">yum install libgeotiff-devel</code></pre>
</div>
</div>
<div class="paragraph">
<p>It can be a good idea to update the library paths in linux at this point:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">sudo ldconfig</code></pre>
</div>
</div>
<div class="paragraph">
<p>Great. Now libLAS is also dependent on another package called <strong>laszip</strong>. The developers thought it would be too easy to simply include this as one package/download, so you first have to install this as well before we can even get started on the actual libLAS package.</p>
</div>
<div class="paragraph">
<p>Get it here:  <a href="http://www.laszip.org/">laszip download</a></p>
</div>
<div class="paragraph">
<p>Once you&#8217;ve unzipped it, in the top level directory run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">./configure
make
sudo make install</code></pre>
</div>
</div>
<div class="paragraph">
<p>They should be installed in the <code>/usr/local/include/</code> directory. Which is bad, because they need to be in their own directory. So you have to root into the <code>/usr/local/include/</code>, create a <code>laszip</code> directory, and copy the laszip header files into this directory.</p>
</div>
<div class="paragraph">
<p>Magic. Now, we can install libLAS. It uses cmake to install itself. So in the libLAS directory, <code>mkdir</code> a <code>build</code> folder, <code>cd</code> into that, and run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">ccmake -G "Unix Makefiles" ../</code></pre>
</div>
</div>
<div class="paragraph">
<p>A terminal dialogue opens. Make sure it has found the GEOTIFF directory. If not, you will need to find where the geotiff (see above) stuff was installed to, and enter the full path in the GEOTIFF box.</p>
</div>
<div class="paragraph">
<p>Now look at the options below (we are still running ccmake here). Turn all the optional settings to <code>OFF</code>, it just makes things easier and less likely to go wrong during compilation. Hit configure. Save and exit.</p>
</div>
<div class="paragraph">
<p>Now run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">make
sudo make install</code></pre>
</div>
</div>
<div class="paragraph">
<p>Hopefully, cmake should do its thing and install libLAS for you. If not, open a large bottle of whisky and repeat the above steps to check you haven&#8217;t missed anything. I find a peaty single malt works best here.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_python_4">C.4. Python</h3>
<div class="paragraph">
<p>To check if it is working, just type</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python</code></pre>
</div>
</div>
<div class="paragraph">
<p>If it is working, it will tell you the version and you will get a command prompt that looks like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">&gt;&gt;&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should have version 2.7 or above.</p>
</div>
<div class="sect3">
<h4 id="_installing_python">C.4.1. Installing python</h4>
<div class="paragraph">
<p>If you don&#8217;t have python, you should install both <strong>python</strong> and <strong>pip</strong>, which manages python packages.
To do that type:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get install python2.7
$ sudo apt-get install python-pip</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_installing_python_packages">C.4.2. Installing python packages</h4>
<div class="paragraph">
<p>To check if python packages are there, just try to import them. First start a python session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ python</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, try to import a package. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">&gt;&gt;&gt; import matplotlib</code></pre>
</div>
</div>
<div class="paragraph">
<p>If the package does not exist, you will get an error message like this:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
ImportError: No module named matplotlib</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can install all the packages at once with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get install python-numpy python-scipy python-matplotlib ipython ipython-notebook python-pandas python-sympy python-nose</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can upgrade packages with the pip command:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ pip install PackageNameHere --upgrade</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ruby_3">C.5. Ruby</h3>
<div class="paragraph">
<p>As mentioned in the main section of the book, the ruby programming language is used to build the documentation of our software. You can skip this part if you are viewing the documentation from the pdf or webpages and aren&#8217;t planning on contributing to the documentation. (Though you if you are contributing new features to the software you are encouraged to!)</p>
</div>
<div class="paragraph">
<p>You can see if Ruby is on your system by typing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ ruby -v</code></pre>
</div>
</div>
<div class="paragraph">
<p>If it isn&#8217;t there, install with (this should seem routine by now):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get  install ruby-full</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you already have ruby installed, you might need to check you have the development packages too, along with rubygems, which is a package installer for ruby libraries and add-ons (similar to pip for Python):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo apt-get install ruby-dev
$ sudo apt-get install rubygems</code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that in newer versions of Ruby, rubygems seems to install with ruby-full.</p>
</div>
<div class="sect3">
<h4 id="_installing_the_asciidoctor_documentation_software">C.5.1. Installing the asciidoctor documentation software</h4>
<div class="paragraph">
<p>After you have installed ruby, ruby-devel, and rubygems you can now proceed to getting the actual ruby packages that make the documentation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo gem install asciidoctor
$ sudo gem install bundler</code></pre>
</div>
</div>
<div class="paragraph">
<p>If bundler fails to install, you may be missing the ttfunk package.:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ sudo gem install ttfunk</code></pre>
</div>
</div>
<div class="paragraph">
<p>Thankfully, the gem installer is quite helpful at telling you which packages are missing and how to quickly install them. That&#8217;s it now, you can proceed to cloning the documentation from github.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cloning_or_forking_the_documentation">C.6. Cloning or forking the documentation</h3>
<div class="paragraph">
<p>The documentation is under version control on github, just like the actual software source code. If you&#8217;re a developer, you can clone it direct from the original repository, otherwise you will need to fork it first into your own repo, and then clone from there to your local machine. You do this by visiting <a href="http://github.com/LSDtopotools/LSDTT_book" class="bare">http://github.com/LSDtopotools/LSDTT_book</a> and clicking 'fork' (assuming you have a github account of course). Then, on your local machine, you can do:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ git clone https://github.com/LSDTopoTools/LSDTT_book.git</code></pre>
</div>
</div>
<div class="paragraph">
<p>and the documentation will be cloned into a directory called LSDTT_book from where you ran the command.</p>
</div>
<div class="paragraph">
<p>cd into the LSDTT_book directory, and run bundler install:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ bundler install</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then, to build the documentation in full from the source files, run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ bundler exec rake book:build</code></pre>
</div>
</div>
<div class="paragraph">
<p>or to just build html:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">$ bundler exec rake book:build_html</code></pre>
</div>
</div>
<div class="paragraph">
<p>In a few seconds bundler will have completed and you will have a smart looking copy of the documentation in both pdf and html form. Any time you make changes to the documentation source files, run the bundler exec command again to update your local copy. Remember to commit and push your changes regularly to the remote repository on your githb account.</p>
</div>
</div>
<div class="sect2">
<h3 id="_summary_12">C.7. Summary</h3>
<div class="paragraph">
<p>Well, you have probably spent some time installing all of these software packages so relax for a bit and enjoy the beverage of your choice!</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_code_structure">Appendix D: Code Structure</h2>
<div class="sectionbody">
<div class="paragraph">
<p>You can happily use LSDTopoTools oblivious to the inner-workings of the code and how it all connects together to produce a suite of topographic analyses at your disposal. Ignorance is, as they say, bliss. No knowledge of Classes, Drivers, Objects, and so on, is needed to run the basic analyses supplied in the distribution of this software. However, you might wish to write your own driver functions, and may even be considering contributing to the core parts of the code. This way you can make your topographic techniques and algorithmic awesomeness available to like-minded geoscientists. Earlier, we mentioned breifly how the code is structured in the main body of this documentation. For those intrepid interrogators of empirical inquisition who have made it four levels down into the Appendix section, first of all, we salute you, and we reward you with a deeper look into how the code is structured, should you wish to contribute your own additions to the repository.</p>
</div>
<div class="sect2">
<h3 id="_source_files_drivers_headers_and_implementaions">D.1. Source Files: Drivers, Headers, and Implementaions.</h3>
<div class="paragraph">
<p>There are two main parts of the LSDTopoTools source code: the driver functions and the core component source files. The core files contain the implementations of topographic analyses, and many other functions for creating rasters, sorting data, performin file operations, writing output, and so on.  All the core source files are name like <code>LSDSomeFile. pp</code>. They also come in pairs: a <code>LSDSomeClass.cpp</code> source file comes with a <code>LSDSomeClass.hpp</code> header file. The header file describes the interface to a parituclar source file. In other words, <code>LSDSomeClass.hpp</code> tells us what all the methods and data structures of a particular source file (<code>LSD.cpp</code>) are. For functions (or class methods to be precise&#8230;&#8203;) the header file tells us what type of parameters the functions take as arguments, and what data types (if any) these functions return. They also describe how data structures are stored. For example, we could look in <code>LSDRaster.hpp</code> to see how the data members of a Raster are defined. We would see that an <code>LSDRaster</code> object has some meta-data telling us about the extent and coordinates of the the raster data, and an array that stores each pixel value in the raster. It would also tell us which functions (methods) would return information about the <code>LSDRaster</code> object. If we wanted to know the number of rows in a raster object we would see in the header file there is a <code>getNRows()</code> function, and so on. The <code>.cpp</code> files tell us <em>how</em> these functions are implemented, e.g. what exactly each function does when parameters are passed to it, and how it maniplulates the data stored with the object.</p>
</div>
<div class="paragraph">
<p>In general, although it is not required, we have kept one <code>Class</code> to one pair of header and implementation files. (Although there are a couple of exceptions to this). So in the <code>LSDRaster.hpp</code> and <code>LSDRaster.cpp</code> core files, you will find the declaration and implementation of the <code>LSDRaster</code> class, respectively. In short, <code>hpp</code> tells us what is there and how to use it, <code>cpp</code> tells us how it works. For a full description of all the LSDTopoTools objects and classes you can visit the automatically generated doxygen documentation.</p>
</div>
<div class="paragraph">
<p>The driver files are separated off into their own folder(s) and as their name suggests, they are responsible for driving a particular analysis by calling on different objects and functions defined in the core source files. The core <code>LSDFooBar</code>-type files we talked about previously don&#8217;t actually do much on their own&#8201;&#8212;&#8201;they are just a bunch of class data structures and methods. This is where the driver files come in: driver files are written to perform a certain kind of topographic analysis or model simulation using some form of input data created by you, the user. Driver files call upon different parts of the object files to perform topographic analyses. An example driver file may call upon <code>LSDRaster</code> to create a Raster object to store data from an input DEM, then it might pass this <code>LSDRaster</code> object to <code>LSDFlowInfo</code> to calculate the flow routing paths in the raster, and so on, until we have completed a useful analysis and written some output data to analyse.</p>
</div>
<div class="paragraph">
<p>Since there is such a variety of functions defined in the source code, there are potentially hundreds if not thousands of possible analyses that could be performed with the code. The driver files provided with the TopoTools distribution are designed to accomplish some of the more common topographic analysis tasks, e.g. extracting basins from a raster, calculating the location of channel heads in a landscape, running a chi-analysis on river channels, or extracting swath profiles, and so on. However, you are free to write your own driver files of course! What&#8217;s more, they provide an exact record of the analysis you have just done, and so are inherrently reproducible if you want to share your findings with others.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Another way to think of drivers, if you are familiar with C or C++ programming, is that they contain the <code>int main() { }</code> bit of a typical program. I.e. the main workflow of a program.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_a_closer_look_at_the_source_files">D.2. A closer look at the source files</h3>
<div class="sect3">
<h4 id="_lsdraster">D.2.1. LSDRaster</h4>
<div class="paragraph">
<p>LSDRaster is the class that contains methods for mainipulating arrays of raster data loaded from a DEM file. There are also data members that store metadata about the raster, such as the typical header data you would find in a DEM file. It can perform typical analyses such as creating a hillshade raster, calculating curvature of ridgetops, calculating the location of channel heads in a landscape, filling sinks and pits in a DEM and so on&#8201;&#8212;&#8201;mainly analyses that are performed on the entire raster dataset. It also does the basic reading and writing to DEM files.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdindexraster">D.2.2. LSDIndexRaster</h4>
<div class="paragraph">
<p>A simple and fairly short class that stores rasters data as integers, used for indexing of raster data, calculating bounding boxes for rasters with lots of <code>NoData</code> values around the edge (or surounding basins). Very similar to LSDRaster class except is only used for when an index or mask of a given raster is needed.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdflowinfo">D.2.3. LSDFlowInfo</h4>
<div class="paragraph">
<p>This class performs operations such as calculating flow direction, calculating upstream contributing pixels in a raster, calculating sources based on threshold pixel methods, and other flow related information (based on <strong>topographic</strong> analysis&#8201;&#8212;&#8201;not based on any particular hydrological fluid flow calculations). Note how this object has include statements for LSDRaster and LSDIndexRaster&#8201;&#8212;&#8201;it returns these type of objects from many of its methods. It uses the FastScape algorithm of Braun and Willet (2014).</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdindexchannel">D.2.4. LSDIndexChannel</h4>
<div class="paragraph">
<p>This object contains the node indexes as well as the row and col indices for individual channel segments.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdchannel">D.2.5. LSDChannel</h4>
<div class="paragraph">
<p>LSDChannel is our first class that inherits the public methods and data members of another, namely LSDIndexChannel. This means we have direct access to the public members of that class. Note, in the source code:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-cpp" data-lang="cpp">class LSDChannel: public LSDIndexChannel
{
    public:
        // Some method declarations</code></pre>
</div>
</div>
<div class="paragraph">
<p>Indicates this class inherits from LSDIndexChannel. LSDChannel stores information about the actual channel characteristics, e.g. elevation etc.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdjunctionnetwork">D.2.6. LSDJunctionNetwork</h4>
<div class="paragraph">
<p>JunctionNetwork contains the main parts of the implemented FastScape algorithm for creating channel junction networks that can be searched for network connectivity. The main inputs are a FlowInfo object and list of source nodes. It also contains functions for returning IndexChannel objects after calculating the layout of channel networks.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdindexchanneltree">D.2.7. LSDIndexChannelTree</h4>
<div class="paragraph">
<p>This object spawns vectors of LSDIndexChannels. They can be indexed by the LSDChannel network, but can also be independent of the channel network, storing longest channels from sources, for example. The class is designed to be flexible, it can be used either with the LSDFlowInfo or LSDJunctionNetwork classes.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdchinetwork">D.2.8. LSDChiNetwork</h4>
<div class="paragraph">
<p>This is used to perform chi-related analyses on channels.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdmostlikelypartitionsfinder">D.2.9. LSDMostLikelyPartitionsFinder</h4>
<div class="paragraph">
<p>This object is principally used to identify segments of differing channel steepness in chi-zeta space. It contains the implementation of the segment fitting algorithm, including the statistical model that determines the most likely partitionining combination of channels.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lsdstatstools">D.2.10. LSDStatsTools</h4>
<div class="paragraph">
<p>The StatsTools files contain a number of classes and standalone functions that perform statistical analyses. A number of other utility functions are implemented here, such as file name parsing and formatting.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_analysis_driver_options">Appendix E: Analysis Driver Options</h2>
<div class="sectionbody">
<div class="paragraph">
<p>LSDTopoTools is composed of a number of objects (e.g., LSDRaster, LSDChannel, LSDFlowInfo, etc.) which are then called from programs we call driver functions.
For more information, see the appendix <a href="#_code_structure">Code Structure</a>.</p>
</div>
<div class="paragraph">
<p>Most of these functions drive specific kinds of analysis,
but we do have a general program capable of a number of different analyses.
This program is called the <strong>AnalysisDriver</strong> and is available here: <a href="https://github.com/LSDtopotools/LSDTopoTools_AnalysisDriver" class="bare">https://github.com/LSDtopotools/LSDTopoTools_AnalysisDriver</a>.</p>
</div>
<div class="paragraph">
<p>The analysis driver runs from parameter files.
In this appendix we document the options for running the AnalysisDriver from a parameter file.</p>
</div>
<div class="paragraph">
<p>The format of <strong>AnalysisDriver</strong> parameter files is a keyword followed by a value.
The value can be a string, an integer, a boolean or a floating point number depending on the keyword.
The order of the keywords does not matter.
Comments can be inserted into the parameter file using the hash symbol (<code>#</code>).</p>
</div>
<div class="sect2">
<h3 id="_analysisdriver_file_input_and_output_options">E.1. AnalysisDriver file input and output options</h3>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 27. File input and output options</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">dem read extension</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The type of data format used in reading rasters. Options are <code>bil</code>, <code>asc</code> and <code>flt</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">dem write extension</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The type of data format used in reading rasters. Options are <code>bil</code>, <code>asc</code> and <code>flt</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write path</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The path to which data is written.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">read path</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The path from which data is read.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write fname</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The prefix of rasters to be written <strong>without extension</strong>.
For example if this is <code>Test</code> and you have selected <code>bil</code> format then a fill operation will result in a file called <code>Test_Fill.bil</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">read fname</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The filename of the raster to be read without extension. For example if the raster is <code>MyRaster.bil</code>, read fname will be <code>MyRaster</code>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_analysisdriver_files_to_write">E.2. AnalysisDriver files to write</h3>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
These require booleans,
but in in the <strong>AnalysisDriver</strong> parameter file booleans must be <strong>true</strong>--anything else is considered false.
<code>true</code> is case sensitive, so <strong>DO NOT</strong> write <code>True</code>: it will be interpreted as false!!
</td>
</tr>
</table>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 28. Options of files to write or analyses to perform</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write fill</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a filled raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write write trimmed and nodata filled</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This is for data with nodata around the edges and holes of nodata in the middle.
The holes are filled and the nodata around the edges is trimmed.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write hillshade</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a hillshade raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write slope</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a slope raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write curvature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a curvature raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write planform curvature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a planform curvature raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write tangential curvature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a tangential curvature raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write profile curvature</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a profile curvature raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write aspect</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write an aspect raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write topographic classification</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a raster where convex, concave and planar regions are classified by an integer.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write drainage area</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a drainage area raster.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write channel net</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Write a channel network. This will print a raster of stream orders and a raster of junctions.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write nodeindex</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Writes a nodeindex raster. Used by developers for debugging.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write write single thread channel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This extracts a single tread channel from a starting and ending node, and prints to csv.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write chi map</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This calculates the chi coordinate (a coordinate that integrates drainage area along channel length) from all base level nodes.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">write factor of safety at saturation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">boolean</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Calculates the factor of safety using an infinite slope analysis (similar to <a href="http://hydrology.usu.edu/sinmap2/">Sinmap</a>
or <a href="http://calm.geo.berkeley.edu/geomorph//shalstab/theory.htm">Shalstab</a>).</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_analysisdriver_parameter_values">E.3. AnalysisDriver parameter values</h3>
<div class="sect3">
<h4 id="_parameters_for_the_fill_function">E.3.1. Parameters for the fill function</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 29. Parameters for the fill function</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">min_slope_for_fill</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0001</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The minimum slope between nodes in a DEM: this is for filling flats</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fill_method</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">new_fill</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The method to be used for the fill function. Options are <code>new_fill</code>, <code>old_fill</code>, and <code>remove_seas</code>.
The <code>old_fill</code> method is legacy code and is only used by developers in recreating pre-2012 analyses.
It is <strong>MUCH</strong> slower than <code>new_fill</code>.
<code>remove_seas</code> uses <code>new_fill</code> but it additionally sets any data point where the elevation is 0 to <code>nodata</code>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_hillshading">E.3.2. Parameters for hillshading</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 30. Parameters for hillshading</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hs_altitude</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">45</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The altitude of the sun in degrees</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hs_azimuth</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">315</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The azimuth of the "sun" in degrees</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hs_z_factor</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The vertical exaggeration factor as a ratio</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_flow_info_calculations">E.3.3. Parameters for flow info calculations</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 31. Parameters for flow info calculations</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boundary conditions</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A four element list of strings</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">n n n n</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">This gives the boundary conditions at the north, east, south and west boundaries, respectively.
The options are <code>n</code> for no flux, <code>p</code> for periodic and <code>b</code> for base level.
These are NOT case sensitive.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_chi_calculations">E.3.4. Parameters for chi calculations</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 32. Parameters for chi calculations</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">A_0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1000</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A normalizing area for chi calculations in m<sup>2</sup>.
This will affect absolute values of chi but not relative values of chi.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">m_over_n</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The m/n ratio.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">threshold_area_for_chi</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Threshold area for chi calculations in m<sup>2</sup>.
Pixels with area lower than this threshold will be assigned nodata.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_polyfit_and_slope_calculations">E.3.5. Parameters for polyfit and slope calculations</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 33. Parameters for polyfit and slope calculations</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">polyfit_window_radius</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2*sqrt(2)*data_resolution</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The radius of nodes over which to fit the polynomial window in m.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">slope_method</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">d8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The method for calculating slope. Options are <code>d8</code> (steepest descent) and <code>polyfit</code>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_drainage_area_extraction">E.3.6. Parameters for drainage area extraction</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 34. Parameters for drainage area extraction</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">drainage_area_method</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dinf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The method for calculating drainage area. The options are: <code>d8</code>, <code>dinf</code>, <code>QuinnMD</code>, <code>FreemanMD</code>, and <code>M2D</code>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_single_thread_channel_extraction">E.3.7. Parameters for single thread channel extraction</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 35. Parameters for extra cting single thread channels</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">single_thread_channel_method</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">string</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">start_and_end_node</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The method for calculating drainage area. So far there is only one option: <code>start_and_end_node</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">starting_channel_node</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">if none give you will get a user prompt</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The nodeindex of the starting node.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ending_channel_node</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">if none give you will get a user prompt</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The nodeindex of the ending node.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_area_threshold_channel_extraction">E.3.8. Parameters for area threshold channel extraction</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 36. Parameters for area threshold channel extraction</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pixel_threshold_for_channel_net</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int (but in program seems to be float&#8230;&#8203;need to check)</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The number of pixels that are needed to initiate a channel.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_parameters_for_hydrology_and_slope_stability">E.3.9. Parameters for hydrology and slope stability</h4>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 37. Parameters for chi calculations</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Keyword</th>
<th class="tableblock halign-left valign-top">Input type</th>
<th class="tableblock halign-left valign-top">Default</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">root_cohesion</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The root cohesion in N m<sup>-2</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">soil_density</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The soil density in kg m<sup>-3</sup></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hydraulic_conductivity</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The hydraulic conductivity in m day<sup>-1</sup>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">soil_thickness</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Soil thickness m (assumed to be the same everywhere).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tan_phi</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">The friction angle (dimensionless).</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_appendix_f_tools_for_viewing_data">Appendix F: Appendix F: Tools for viewing data</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The many analyses provided by LSDTopoTools produce geographic data
(that is data that is attached to some location in space).
In this section we provide some basic instruction on how to view this
data, using either Geographic Information Sysems (GISs) or
using our own visualisation scripts, which are written in python.</p>
</div>
<div class="sect2">
<h3 id="_arcmap">F.1. ArcMap</h3>
<div class="paragraph">
<p>ArcMap is commercial software written by ESRI.
Many companies, goverment agencies and universities have liscences to this sofotware.</p>
</div>
</div>
<div class="sect2">
<h3 id="_qgis">F.2. QGIS</h3>
<div class="paragraph">
<p>QGIS is an open source GIS that has functionality similar to ArcMap.</p>
</div>
</div>
<div class="sect2">
<h3 id="_lsdtopotools_python_mapping_functions">F.3. LSDTopoTools python mapping functions</h3>
<div class="paragraph">
<p>We have written a series of lightweight mapping tools in python for
visualising data.
These tool are for times when you cannot be bothered waiting for a GIS
to load, or when you want a perfectly reproducable, code-driven visualisation.</p>
</div>
<div class="paragraph">
<p>To make these work, you will need matplotlib and the gdal python packages
installed on your system.</p>
</div>
</div>
<div class="sect2">
<h3 id="_summary_13">F.4. Summary</h3>
<div class="paragraph">
<p>You should now be able to perform basic operations such as loading and exploring data in QGIS, ArcMap or our own python tools.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_appendix_g_automation_and_supercomputing_for_lsdtopotools">Appendix G: Appendix G: Automation and Supercomputing for LSDTopoTools</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Perhaps you have a lot of basins that you want to perform some analysis on, or you want to re-run a previous analysis with slightly different paramters, different m/n values, and so on. This section will explain some of the scripting tools, supercomputer applications, and other utilities to help speed up this process.</p>
</div>
<div class="sect2">
<h3 id="_embarassingly_parallel_topographic_analysis">G.1. Embarassingly Parallel Topographic Analysis</h3>
<div class="paragraph">
<p>The LSD software is written to run completely in serial. (i.e. there is no built in parallelisation). However, if you are running the same analyses on a large number of basins, the problem becomes easy to set up in a parallel-like fashion, if you have access to some form of multiple cpu computing facility. (This is termed <strong>embarassingly/trivially parallel</strong>, since it isn&#8217;t really written in parallel code).</p>
</div>
<div class="paragraph">
<p>This doesn&#8217;t necessarily require a supercomputing cluster; most laptops are at least dual core (as of 2014), and some will have as many as 8 seperate cpu threads to run tasks on. That means you could be running analysis on 8 basins at a time, rather than waiting for each one to finish separately, in serial.</p>
</div>
<div class="sect3">
<h4 id="_the_simple_case_a_single_cpu_multi_core_laptop">G.1.1. The Simple Case - A single cpu, multi-core laptop</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">You can find out how many cpus/cores/threads you have to play with by typing</dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">nproc</code></pre>
</div>
</div>
<div class="paragraph">
<p>at the terminal in linux/cygwin. On a Intel i5 laptop, for example, it would probably return <code>2</code> or <code>4</code> 'cpus' as the result. Without going into the details, a 'cpu' in this case is the smallest processing 'unit' (or a 'thread'). Also, by means of some clever electronics, some Intel cpus have twice as many threads as they do physical cores. Hooray!</p>
</div>
<div class="paragraph">
<p>Now suppose you have 16 basins that you want to do the chi analysis on. Should you run them all one-by-one on a single thread/cpu and let the other 3 threads sit there idle-ing? No! Use a utility such as <code>xjobs</code> or <code>GNU Parallel</code>. This example uses GNU parallel:</p>
</div>
<div class="paragraph">
<p>Prepare your numbered driver files as required. This example uses 50 driver files named: <code>test1.driver</code>, <code>test2.driver</code>, etc. (See below for how to do this with a Python Script). The job-queuer used is GNU parallel, which is installed by default on many linux distributions:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">seq 50 | parallel --gnu -j 4 ../driver_functions ./ 'test{}.driver' &amp;</code></pre>
</div>
</div>
<div class="paragraph">
<p>or,</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">parallel --gnu -j 4 ../driver_functions/chi_get_profiles.exe ./ test{}.driver {1..50} &amp;</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will queue up you 50 separate jobs to run on 4 threads at a time (the <code>-j 4</code> argument)</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_topographic_analysis_on_a_supercomputer">G.2. Topographic Analysis on a Supercomputer</h3>
<div class="paragraph">
<p>If you have access to a suitable cluster computer or other supercomputer (HPC - high performance computing) service (ARCHER, HECToR, Eddie, or your local department&#8217;s cluster) it will probably have some type of job submission service. SGE and PBS are two of the most commonly used ones. You use the job scheduler to submit your by providing a simple script that requests cpu and memory resources from the supercomputer. By running the script, the job(s) are then placed in a queue to be distributed across the nodes and cpus.</p>
</div>
<div class="paragraph">
<p>It is also possible to run jobs in 'interactive' mode, which skips the script writing part and just starts the jobs from the commmand line once you are logged in. This is ok for testing, but not advised when running large, numerous, or memory-intensive jobs as it tends to hog the resources. Consult your HPC service&#8217;s documentation for best practice.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="title">Creating multiple driver files for a list of basins</div>
<div class="paragraph">
<p>Scripts (located in the LSD_Visualisation folder):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">channel_extraction_driver_gen.py
forced_mn_driver_gen.py
chi_multidriver_gen_qsub_ver.py</code></pre>
</div>
</div>
<div class="paragraph">
<p>You will need a text file containing a list of your basins with their junction index numbers (JI). The text file can take the following format: (note, the header is not actually included in the file.)</p>
</div>
<table class="tableblock frame-all grid-all spread">
<caption class="title">Table 38. Example basin list for scripting purposes</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Basin Name</th>
<th class="tableblock halign-left valign-top">Starting JI</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">turnpike</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1468</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">reginald</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5167</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">tubadore</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6422</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">marmaduke</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">13994</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Make sure you do not include a blank line at the end of the file, otherwise the script will return an error about the list index being out of range.</p>
</div>
<div class="paragraph">
<p>The standard version of this script spawns driver files that include the junction index to hel identfy which driver runs with which input data file/dem.</p>
</div>
<div class="paragraph">
<p>The qsub_ver version of the script spawns files that have driver names increasing linearly from 1 upwards to the maximum number of basins in your basin list. This is useful if you want to run the analysis on a system that has a job queuing utility such as PBS, SGE, xjobs, GNU Parallel, etc.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_launching_jobs_with_the_batch_system">G.2.1. Launching jobs with the batch system</h4>
<div class="sect4">
<h5 id="_pbs_example">PBS Example</h5>
<div class="paragraph">
<p>PBS (Portable batch system) is the name of the job submission scheduler used on the UK&#8217;s ARCHER supercomuting service, housed in Edinburgh.</p>
</div>
<div class="paragraph">
<p>Here is an example of a batch of channel file extractions. 50 channel files were extracted in a few minutes, compared to several hours on a desktop/laptop computer.</p>
</div>
<div class="paragraph">
<p>#. First, set up your driver files using the python script described above. Upload them to the filesystem on the HPC service.</p>
</div>
<div class="paragraph">
<p>#. Upload (using <code>scp</code>) and compile the LSD Topo Tools software directly on the HPC system. I.e. do not upload it ready-compiled from your own computer, it will probably not work - unless you have compiled it with static libraries. (This is not the default option)</p>
</div>
<div class="paragraph">
<p>#. Upload any raster files required for whichever part of the LSD ToolBox you are using. You would normally do this using the linux <code>scp</code> command. Type <code>man scp</code> at the terminal for help on using this.</p>
</div>
<div class="paragraph">
<p>#. Now write the job submission script. The example below is for the <strong>PBS job submisison utility</strong>, but SGE has a very similar layout. See specific documentation for the one you are using.:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">#!/bin/bash --login
#
#PBS -N chan_extrac
#PBS -A n02-ncas
#PBS -l walltime=2:0:0
#PBS -l select=serial=true:ncpus=1
#PBS -J 1-50
#PBS -r y

# Switch to current working directory
cd $HOME/wasatch_chi/channel_extraction_legacy/new_dense_chans/

# Run the serial program
../driver_functions/chi2_write_channel_file.exe ./ wasatch_$PBS_ARRAY_INDEX.driver</code></pre>
</div>
</div>
<div class="paragraph">
<p>This is an array job: the array switch is specified by <code>#PBS -J {RANGE OF VALUES}</code>. The range will increment the variable <code>$PBS_ARRAY_INDEX</code> by 1 each time. In this example, the driver files used will be wasatch_1.driver, wasatch_2.driver, &#8230;&#8203;, and so on.</p>
</div>
<div class="paragraph">
<p>Since the job (jobs) are all written in serial code, there is no need to run this on parallel nodes, should they be available to you. This is specified here with <code>#PBS -l select=serial=true:ncpus=1</code>, since we only need one cpu for each individual job in the array. (Altough they will all run concurrently on multiple cpus).</p>
</div>
<div class="paragraph">
<p>There is no need to specifiy an output pipe. Screen output and any errors/aborts will be written to log files automatically.</p>
</div>
<div class="paragraph">
<p>Submit the array job using:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">qsub my_array_script.pbs</code></pre>
</div>
</div>
<div class="paragraph">
<p>The status of the jobs can be checked using qstat. (See the separate documentation for this, or just type 'man qstat')</p>
</div>
</div>
<div class="sect4">
<h5 id="_sge_script_example">SGE Script Example</h5>
<div class="paragraph">
<p>SGE (Sun grid engine) is used on the Eddie cluster (Edinburgh) and Redqueen (Manchester). It works much the same way as PBS does. Here is an example script used to perform the chi analysis on the 50 channels we extracted in the previous example.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">#!/bin/bash
#$ -S /bin/bash   # Inform SGE we are using the bash shell
#$ -cwd           # Job will run in the current directory (where you ran qsub)
#$ -V             # Inherit current environment (e.g., any loaded modulefiles)
#$ -q atmos-b.q   # tell qsub to use the atmosci-b queue
#$ -t 1-50        # TASK GRID ARRAY with 50 jobs
../bin/chi_analysis.exe ../data_dir/ inputfile.${SGE_TASK_ID}.parameters</code></pre>
</div>
</div>
<div class="paragraph">
<p>The <code>${SGE_TASK_ARRAY}</code> part will increment by 1 across the sequence specified, so make sure your inputfiles conform to this format. e.g.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">inputfile.1.parameters
inputfile.2.parameters
inputfile.3.parameters
{etc...}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The job is submitted using <code>qsub my_batch_job.sh</code>. In similar fashion to the previous example, we are submitting a task grid array job, which is useful for carrying out sensitivity analysis (such as with the chi-analysis tools). The chi software is not written with any parallelisation, but we can simulate the effect here using multiple cpu threads on the cluster computer with the task-grid-array job.</p>
</div>
<div class="paragraph">
<p>In this example, we specified a particular queue to use: <code>-q atmos-b.q</code>. This is not necessary on some systems, so check the documentation first.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_checking_your_jobs">G.2.2. Checking your jobs</h4>
<div class="paragraph">
<p><code>qstat</code> on its own should display a list of all your running jobs by default. To delete a job, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">qdel -j {JOB_ID_NUMBER}</code></pre>
</div>
</div>
<div class="paragraph">
<p>The job ID number is found from qstat. To delete all your jobs, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">qdel -u {USERNAME}</code></pre>
</div>
</div>
<div class="paragraph">
<p>To delete specific tasks from an array of jobs (like in the above examples, use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">qdel -j {JOB_ID_NUMBER} -t {TASK_NUMBER(S)}</code></pre>
</div>
</div>
<div class="paragraph">
<p>So if you want to delete the tasks 23 through 64 from job ID 1300. Use:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">qdel -j 1300 -t 23-64</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_module_issues">G.3. Module issues</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">On certain HPC services, different modules or libraries need to be loaded or switched to create the right environment to run your software. Normally this is not an issue and nothing needs to be changed. By convention, the LSD Topo Tools software is compiled using the gcc compilers. (A set of free compilers released under the GNU licence). Some supercomputer clusters will come with a range of compilers such as Intel, Cray, etc&#8230;&#8203; One of them will be loaded by default. If gcc is not the default, you may wish to swap it before compiling.</dt>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">module list</code></pre>
</div>
</div>
<div class="paragraph">
<p>Will list all the currently loaded modules:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">module avail</code></pre>
</div>
</div>
<div class="paragraph">
<p>Will list the available modules. You can narrow down your search by doing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">module avail gcc</code></pre>
</div>
</div>
<div class="paragraph">
<p>for example, to find the gcc-releated modules. To load, type <code>module load gcc</code>. If you are swapping modules, for example the Intel compiler for the gcc one, then do:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">module swap intel gcc</code></pre>
</div>
</div>
<div class="paragraph">
<p>Sometimes, you may find that there is a ready-to-use compiler suite/environment set up on your HPC. Such as:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">PrgEnv-intel
PrgEnv-gnu
PrgEnv-cray</code></pre>
</div>
</div>
<div class="paragraph">
<p>Loading or swapping one of these is the equivalent of the above, but loads a whole suite of other modules and libraries that match the compiler suite. <strong>It is probably best to use these if they are available.</strong></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The compiler suite you use has nothing to do with the type of CPU or supercomputer manufacturer. So you don&#8217;t have to use the Cray compilers with a Cray supercomputer, for example. You may also find that the LSD Topo Tools compile perfectly fine using the Intel/Cray/whatever compilers, though we have only tested the code using the GNU/gcc ones.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Other modules that may of interest to LSDers include python (though not all HPCs will have an implementation installed.) netCDF (a data format for large data arrays).</p>
</div>
</div>
<div class="sect2">
<h3 id="_compilation_and_library_issues">G.4. Compilation and library issues</h3>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
This may not be an issue on certain cluster systems. I include it here in case anyone is having similar issues.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Users of certain libraries (some of the fast fourier libraries, very new compiler features, etc.) may find that the libraries they have on their personal systems are not availble on the cluster computer. This can lead to errors when trying to recompile on the cluster service. As you won&#8217;t have any admin rights when using the HPC service, you can&#8217;t simply install the libraries yourself. (Though you could try asking the admin).</p>
</div>
<div class="paragraph">
<p>As an example, the <code>gcc</code> version on a the Redqueen (Manchester) cluster computing service is only maintained up to ver. 4.4. (The latest version as of 2014 is 4.8.x!). This rather antiquated version of <code>gcc</code> lacks a lot of the library features of the newer <code>gcc</code> compilers. For example, I had issues with out of date <code>libstdc++</code> and <code>libc</code> shared libraries. Trying to boilerplate newer versions of the libraries into my home directory and link them to the existing binaries didn&#8217;t seem to work (the system would always seem to default to the older libraries).</p>
</div>
<div class="paragraph">
<p>A workaround for this, if your code is only dependent on a few (but recent versions) of certain libraries, is to compile your program on your desktop workstation with <strong>static-linked</strong> libraries, using the <code>-static</code> complier tag (for gcc/g++). By default, compilation is done with <strong>dynamically-linked</strong> libraries, which are stored somewhere on the local machine at compilation time, and so they don&#8217;t get transferred with the <code>.exe</code> file if you upload the program to a different machine.</p>
</div>
<div class="paragraph">
<p>Using static-linked libraries effectively combines any library functions into your <code>.exe</code> binary file, so there is no need to worry about library dependencies in an environment that you don&#8217;t have the admin rights to modify. (Such as on the supercomputer) The size of the executable file will be larger, but this should only be an issue if your program is dependent on (numerous) very large library files. Experiment with caution.</p>
</div>
<div class="paragraph">
<p>In the Makefile:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">CC= g++ -static
...rest of makefile</code></pre>
</div>
</div>
<div class="paragraph">
<p>When you are compiling this for the first time, you may get errors about certain libraries not being found. (In my case it was <code>-lstdc++</code>, <code>-lm</code>, and <code>-lc</code>. These libraries will probably be present on your computer, but only the dynamic versions. You will need to download and install the static counterparts of such libraries. In my case this was done on linux with:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">yum install lstdc++-static
yum install glib-static</code></pre>
</div>
</div>
<div class="paragraph">
<p>Again, this will vary depending on what flavour of linux you are using (or Cygwin).</p>
</div>
<div class="paragraph">
<p>Once you have compiled your static library binary, you can check if there are any linked dependencies by doing:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-console" data-lang="console">ldd ./&lt;NAME_OF_EXECUTABLE&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>It should say something along the lines of <code>"This is not a dynamic executable"</code> or suchlike. Provided the file was compiled in a similar linux distribution and bit-version (32/64-bit), the static executable should run without issues by uploading it to your supercomputer of choice.</p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2016-05-05 21:00:44 BST
</div>
</div>
</body>
</html>